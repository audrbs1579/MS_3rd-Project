{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0d0da7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# azcopy copy \"https://storageteam5.blob.core.windows.net/raw/gharchive?sp=rl&st=2025-09-08T06:04:21Z&se=2025-09-09T14:19:21Z&spr=https&sv=2024-11-04&sr=c&sig=9IbcC%2BuwLoGFvulHM4AubhdsBFviqhPIHk3xnYINaHk%3D\" `\n",
    "#  \"C:\\gharchive_202401\\01\" --recursive --include-pattern \"2024-01*.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c09ba18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for ($d = 1; $d -le 31; $d++) {\n",
    "# >>   $dd = \"{0:00}\" -f $d\n",
    "# >>   for ($h = 0; $h -le 23; $h++) {\n",
    "# >>     $hh = \"{0:00}\" -f $h\n",
    "# >>     $url = \"https://data.gharchive.org/2024-01-$dd-$hh.json.gz\"\n",
    "# >>     $out = \"2024-01-$dd-$hh.json.gz\"\n",
    "# >>     try {\n",
    "# >>       Invoke-WebRequest -Uri $url -OutFile $out -ErrorAction Stop\n",
    "# >>     } catch {\n",
    "# >>       Write-Host \"skip $url\"\n",
    "# >>     }\n",
    "# >>   }\n",
    "# >> }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9125033b",
   "metadata": {},
   "source": [
    "# 단일 파일 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23e1e7d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(158214, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>type</th>\n",
       "      <th>actor</th>\n",
       "      <th>repo</th>\n",
       "      <th>payload</th>\n",
       "      <th>public</th>\n",
       "      <th>created_at</th>\n",
       "      <th>org</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34499804532</td>\n",
       "      <td>PushEvent</td>\n",
       "      <td>{'id': 155086563, 'login': 'appref5555ix63', '...</td>\n",
       "      <td>{'id': 737072655, 'name': 'appref5555ix63/Repo...</td>\n",
       "      <td>{'repository_id': 737072655, 'push_id': 164644...</td>\n",
       "      <td>True</td>\n",
       "      <td>2024-01-01 10:00:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34499804536</td>\n",
       "      <td>PushEvent</td>\n",
       "      <td>{'id': 148035012, 'login': 'RITIK-coder-1', 'd...</td>\n",
       "      <td>{'id': 721691955, 'name': 'RITIK-coder-1/Web-D...</td>\n",
       "      <td>{'repository_id': 721691955, 'push_id': 164644...</td>\n",
       "      <td>True</td>\n",
       "      <td>2024-01-01 10:00:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34499804537</td>\n",
       "      <td>PushEvent</td>\n",
       "      <td>{'id': 40938902, 'login': 'Cezary924', 'displa...</td>\n",
       "      <td>{'id': 722578722, 'name': 'Cezary924/Homebridg...</td>\n",
       "      <td>{'repository_id': 722578722, 'push_id': 164644...</td>\n",
       "      <td>True</td>\n",
       "      <td>2024-01-01 10:00:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34499804549</td>\n",
       "      <td>PushEvent</td>\n",
       "      <td>{'id': 155086649, 'login': 'dim12512a', 'displ...</td>\n",
       "      <td>{'id': 737073790, 'name': 'dim12512a/Repo7', '...</td>\n",
       "      <td>{'repository_id': 737073790, 'push_id': 164644...</td>\n",
       "      <td>True</td>\n",
       "      <td>2024-01-01 10:00:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34499804550</td>\n",
       "      <td>PushEvent</td>\n",
       "      <td>{'id': 155086563, 'login': 'appref5555ix63', '...</td>\n",
       "      <td>{'id': 737072686, 'name': 'appref5555ix63/Repo...</td>\n",
       "      <td>{'repository_id': 737072686, 'push_id': 164644...</td>\n",
       "      <td>True</td>\n",
       "      <td>2024-01-01 10:00:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id       type                                              actor  \\\n",
       "0  34499804532  PushEvent  {'id': 155086563, 'login': 'appref5555ix63', '...   \n",
       "1  34499804536  PushEvent  {'id': 148035012, 'login': 'RITIK-coder-1', 'd...   \n",
       "2  34499804537  PushEvent  {'id': 40938902, 'login': 'Cezary924', 'displa...   \n",
       "3  34499804549  PushEvent  {'id': 155086649, 'login': 'dim12512a', 'displ...   \n",
       "4  34499804550  PushEvent  {'id': 155086563, 'login': 'appref5555ix63', '...   \n",
       "\n",
       "                                                repo  \\\n",
       "0  {'id': 737072655, 'name': 'appref5555ix63/Repo...   \n",
       "1  {'id': 721691955, 'name': 'RITIK-coder-1/Web-D...   \n",
       "2  {'id': 722578722, 'name': 'Cezary924/Homebridg...   \n",
       "3  {'id': 737073790, 'name': 'dim12512a/Repo7', '...   \n",
       "4  {'id': 737072686, 'name': 'appref5555ix63/Repo...   \n",
       "\n",
       "                                             payload  public  \\\n",
       "0  {'repository_id': 737072655, 'push_id': 164644...    True   \n",
       "1  {'repository_id': 721691955, 'push_id': 164644...    True   \n",
       "2  {'repository_id': 722578722, 'push_id': 164644...    True   \n",
       "3  {'repository_id': 737073790, 'push_id': 164644...    True   \n",
       "4  {'repository_id': 737072686, 'push_id': 164644...    True   \n",
       "\n",
       "                 created_at  org  \n",
       "0 2024-01-01 10:00:00+00:00  NaN  \n",
       "1 2024-01-01 10:00:00+00:00  NaN  \n",
       "2 2024-01-01 10:00:00+00:00  NaN  \n",
       "3 2024-01-01 10:00:00+00:00  NaN  \n",
       "4 2024-01-01 10:00:00+00:00  NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 확장자가 .json.gz든 .json이든 상관없이, gzip으로 압축되어 있으면 compression='gzip'을 주면 됨\n",
    "original_df = pd.read_json(\n",
    "    r\"C:\\Users\\EL044\\Documents\\MS DS\\03차 프로젝트\\gharchive_2024_01\\2024-01-01-10.json.gz\",\n",
    "    lines=True,\n",
    "    compression=\"gzip\"\n",
    ")\n",
    "\n",
    "print(original_df.shape)\n",
    "display(original_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ef4ef74",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\2701286172.py:32: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  flat['hour']  = flat['created_at'].dt.floor('H')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(158214, 879)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_id</th>\n",
       "      <th>type</th>\n",
       "      <th>created_at</th>\n",
       "      <th>org</th>\n",
       "      <th>actor.id</th>\n",
       "      <th>actor.login</th>\n",
       "      <th>actor.display_login</th>\n",
       "      <th>actor.gravatar_id</th>\n",
       "      <th>actor.url</th>\n",
       "      <th>actor.avatar_url</th>\n",
       "      <th>...</th>\n",
       "      <th>payload.comment.performed_via_github_app.permissions.organization_dependabot_secrets</th>\n",
       "      <th>payload.comment.performed_via_github_app.permissions.starring</th>\n",
       "      <th>payload.comment.performed_via_github_app.permissions.watching</th>\n",
       "      <th>payload.comment.performed_via_github_app.permissions.codespaces_lifecycle_admin</th>\n",
       "      <th>payload.comment.performed_via_github_app.permissions.codespaces_secrets</th>\n",
       "      <th>payload.comment.performed_via_github_app.permissions.repository_advisories</th>\n",
       "      <th>date</th>\n",
       "      <th>hour</th>\n",
       "      <th>repo.owner</th>\n",
       "      <th>repo.repo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34499804532</td>\n",
       "      <td>PushEvent</td>\n",
       "      <td>2024-01-01 10:00:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>155086563</td>\n",
       "      <td>appref5555ix63</td>\n",
       "      <td>appref5555ix63</td>\n",
       "      <td></td>\n",
       "      <td>https://api.github.com/users/appref5555ix63</td>\n",
       "      <td>https://avatars.githubusercontent.com/u/155086...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>2024-01-01 10:00:00+00:00</td>\n",
       "      <td>appref5555ix63</td>\n",
       "      <td>Repo1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34499804536</td>\n",
       "      <td>PushEvent</td>\n",
       "      <td>2024-01-01 10:00:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>148035012</td>\n",
       "      <td>RITIK-coder-1</td>\n",
       "      <td>RITIK-coder-1</td>\n",
       "      <td></td>\n",
       "      <td>https://api.github.com/users/RITIK-coder-1</td>\n",
       "      <td>https://avatars.githubusercontent.com/u/148035...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>2024-01-01 10:00:00+00:00</td>\n",
       "      <td>RITIK-coder-1</td>\n",
       "      <td>Web-Development</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34499804537</td>\n",
       "      <td>PushEvent</td>\n",
       "      <td>2024-01-01 10:00:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40938902</td>\n",
       "      <td>Cezary924</td>\n",
       "      <td>Cezary924</td>\n",
       "      <td></td>\n",
       "      <td>https://api.github.com/users/Cezary924</td>\n",
       "      <td>https://avatars.githubusercontent.com/u/40938902?</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>2024-01-01 10:00:00+00:00</td>\n",
       "      <td>Cezary924</td>\n",
       "      <td>Homebridge-Automation-Bot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34499804549</td>\n",
       "      <td>PushEvent</td>\n",
       "      <td>2024-01-01 10:00:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>155086649</td>\n",
       "      <td>dim12512a</td>\n",
       "      <td>dim12512a</td>\n",
       "      <td></td>\n",
       "      <td>https://api.github.com/users/dim12512a</td>\n",
       "      <td>https://avatars.githubusercontent.com/u/155086...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>2024-01-01 10:00:00+00:00</td>\n",
       "      <td>dim12512a</td>\n",
       "      <td>Repo7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34499804550</td>\n",
       "      <td>PushEvent</td>\n",
       "      <td>2024-01-01 10:00:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>155086563</td>\n",
       "      <td>appref5555ix63</td>\n",
       "      <td>appref5555ix63</td>\n",
       "      <td></td>\n",
       "      <td>https://api.github.com/users/appref5555ix63</td>\n",
       "      <td>https://avatars.githubusercontent.com/u/155086...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>2024-01-01 10:00:00+00:00</td>\n",
       "      <td>appref5555ix63</td>\n",
       "      <td>Repo2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 879 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      event_id       type                created_at  org   actor.id  \\\n",
       "0  34499804532  PushEvent 2024-01-01 10:00:00+00:00  NaN  155086563   \n",
       "1  34499804536  PushEvent 2024-01-01 10:00:00+00:00  NaN  148035012   \n",
       "2  34499804537  PushEvent 2024-01-01 10:00:00+00:00  NaN   40938902   \n",
       "3  34499804549  PushEvent 2024-01-01 10:00:00+00:00  NaN  155086649   \n",
       "4  34499804550  PushEvent 2024-01-01 10:00:00+00:00  NaN  155086563   \n",
       "\n",
       "      actor.login actor.display_login actor.gravatar_id  \\\n",
       "0  appref5555ix63      appref5555ix63                     \n",
       "1   RITIK-coder-1       RITIK-coder-1                     \n",
       "2       Cezary924           Cezary924                     \n",
       "3       dim12512a           dim12512a                     \n",
       "4  appref5555ix63      appref5555ix63                     \n",
       "\n",
       "                                     actor.url  \\\n",
       "0  https://api.github.com/users/appref5555ix63   \n",
       "1   https://api.github.com/users/RITIK-coder-1   \n",
       "2       https://api.github.com/users/Cezary924   \n",
       "3       https://api.github.com/users/dim12512a   \n",
       "4  https://api.github.com/users/appref5555ix63   \n",
       "\n",
       "                                    actor.avatar_url  ...  \\\n",
       "0  https://avatars.githubusercontent.com/u/155086...  ...   \n",
       "1  https://avatars.githubusercontent.com/u/148035...  ...   \n",
       "2  https://avatars.githubusercontent.com/u/40938902?  ...   \n",
       "3  https://avatars.githubusercontent.com/u/155086...  ...   \n",
       "4  https://avatars.githubusercontent.com/u/155086...  ...   \n",
       "\n",
       "   payload.comment.performed_via_github_app.permissions.organization_dependabot_secrets  \\\n",
       "0                                                NaN                                      \n",
       "1                                                NaN                                      \n",
       "2                                                NaN                                      \n",
       "3                                                NaN                                      \n",
       "4                                                NaN                                      \n",
       "\n",
       "  payload.comment.performed_via_github_app.permissions.starring  \\\n",
       "0                                                NaN              \n",
       "1                                                NaN              \n",
       "2                                                NaN              \n",
       "3                                                NaN              \n",
       "4                                                NaN              \n",
       "\n",
       "  payload.comment.performed_via_github_app.permissions.watching  \\\n",
       "0                                                NaN              \n",
       "1                                                NaN              \n",
       "2                                                NaN              \n",
       "3                                                NaN              \n",
       "4                                                NaN              \n",
       "\n",
       "   payload.comment.performed_via_github_app.permissions.codespaces_lifecycle_admin  \\\n",
       "0                                                NaN                                 \n",
       "1                                                NaN                                 \n",
       "2                                                NaN                                 \n",
       "3                                                NaN                                 \n",
       "4                                                NaN                                 \n",
       "\n",
       "   payload.comment.performed_via_github_app.permissions.codespaces_secrets  \\\n",
       "0                                                NaN                         \n",
       "1                                                NaN                         \n",
       "2                                                NaN                         \n",
       "3                                                NaN                         \n",
       "4                                                NaN                         \n",
       "\n",
       "   payload.comment.performed_via_github_app.permissions.repository_advisories  \\\n",
       "0                                                NaN                            \n",
       "1                                                NaN                            \n",
       "2                                                NaN                            \n",
       "3                                                NaN                            \n",
       "4                                                NaN                            \n",
       "\n",
       "         date                      hour      repo.owner  \\\n",
       "0  2024-01-01 2024-01-01 10:00:00+00:00  appref5555ix63   \n",
       "1  2024-01-01 2024-01-01 10:00:00+00:00   RITIK-coder-1   \n",
       "2  2024-01-01 2024-01-01 10:00:00+00:00       Cezary924   \n",
       "3  2024-01-01 2024-01-01 10:00:00+00:00       dim12512a   \n",
       "4  2024-01-01 2024-01-01 10:00:00+00:00  appref5555ix63   \n",
       "\n",
       "                   repo.repo  \n",
       "0                      Repo1  \n",
       "1            Web-Development  \n",
       "2  Homebridge-Automation-Bot  \n",
       "3                      Repo7  \n",
       "4                      Repo2  \n",
       "\n",
       "[5 rows x 879 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pandas import json_normalize\n",
    "from collections.abc import Sequence\n",
    "import numpy as np\n",
    "\n",
    "# df: 이미 읽어둔 GH Archive DataFrame (NDJSON -> df)\n",
    "# 예: df = pd.read_json(\"2024-01-01-10.json.gz\", lines=True, compression=\"gzip\")\n",
    "\n",
    "def flatten_lists_to_len(rec: dict):\n",
    "    \"\"\"dict 안의 list들은 길이(len)로 요약하여 메모리 폭주 방지\"\"\"\n",
    "    out = {}\n",
    "    for k, v in rec.items():\n",
    "        if isinstance(v, list):\n",
    "            out[k] = len(v)\n",
    "        elif isinstance(v, dict):\n",
    "            out[k] = v  # dict는 그대로 두고 json_normalize가 펼치게 함\n",
    "        else:\n",
    "            out[k] = v\n",
    "    return out\n",
    "\n",
    "\n",
    "# 1) 레코드(행) 단위로 리스트를 길이로 바꿔 주고\n",
    "records = [flatten_lists_to_len(r) for r in original_df.to_dict(orient=\"records\")]\n",
    "\n",
    "# 2) json_normalize로 딕셔너리 중첩을 '.' 컬럼으로 평탄화\n",
    "flat = json_normalize(records, sep='.')\n",
    "\n",
    "# 3) 자주 쓰는 타입 캐스팅/파생 컬럼\n",
    "if 'created_at' in flat.columns:\n",
    "    flat['created_at'] = pd.to_datetime(flat['created_at'], utc=True, errors='coerce')\n",
    "    flat['date']  = flat['created_at'].dt.date\n",
    "    flat['hour']  = flat['created_at'].dt.floor('H')\n",
    "if 'repo.name' in flat.columns:\n",
    "    # owner / repo 분리\n",
    "    split = flat['repo.name'].astype('string').str.split('/', n=1, expand=True)\n",
    "    flat['repo.owner'] = split[0]\n",
    "    flat['repo.repo']  = split[1]\n",
    "\n",
    "# 4) 완전 상수/식별자 성 컬럼은 옵션으로 제거\n",
    "drop_candidates = []\n",
    "if 'public' in flat.columns and flat['public'].notna().mean() > 0 and flat['public'].value_counts(normalize=True, dropna=False).iloc[0] > 0.99:\n",
    "    drop_candidates.append('public')\n",
    "# 이벤트 id는 보통 식별자 → 모델 입력에선 제외 권장(보관은 가능)\n",
    "if 'id' in flat.columns:\n",
    "    flat = flat.rename(columns={'id':'event_id'})  # 이름만 바꿔두기\n",
    "    # drop_candidates.append('event_id')\n",
    "\n",
    "flat = flat.drop(columns=drop_candidates, errors='ignore')\n",
    "\n",
    "print(flat.shape)\n",
    "display(flat.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5f07452f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "379\n",
      "['type', 'created_at', 'org', 'payload.size', 'payload.distinct_size', 'payload.ref', 'payload.head', 'payload.before', 'payload.commits', 'payload.action', 'payload.issue.number', 'payload.issue.title', 'payload.issue.user.login', 'payload.issue.user.type', 'payload.issue.user.site_admin', 'payload.issue.labels', 'payload.issue.state', 'payload.issue.locked', 'payload.issue.assignee', 'payload.issue.assignees', 'payload.issue.milestone', 'payload.issue.comments', 'payload.issue.created_at', 'payload.issue.updated_at', 'payload.issue.closed_at', 'payload.issue.author_association', 'payload.issue.active_lock_reason', 'payload.issue.draft', 'payload.issue.pull_request.merged_at', 'payload.issue.body', 'payload.issue.reactions.total_count', 'payload.issue.reactions.+1', 'payload.issue.reactions.-1', 'payload.issue.reactions.laugh', 'payload.issue.reactions.hooray', 'payload.issue.reactions.confused', 'payload.issue.reactions.heart', 'payload.issue.reactions.rocket', 'payload.issue.reactions.eyes', 'payload.issue.performed_via_github_app', 'payload.issue.state_reason', 'payload.comment.user.login', 'payload.comment.user.type', 'payload.comment.user.site_admin', 'payload.comment.created_at', 'payload.comment.updated_at', 'payload.comment.author_association', 'payload.comment.body', 'payload.comment.reactions.total_count', 'payload.comment.reactions.+1', 'payload.comment.reactions.-1', 'payload.comment.reactions.laugh', 'payload.comment.reactions.hooray', 'payload.comment.reactions.confused', 'payload.comment.reactions.heart', 'payload.comment.reactions.rocket', 'payload.comment.reactions.eyes', 'payload.comment.performed_via_github_app.slug', 'payload.comment.performed_via_github_app.owner.login', 'payload.comment.performed_via_github_app.owner.type', 'payload.comment.performed_via_github_app.owner.site_admin', 'payload.comment.performed_via_github_app.name', 'payload.comment.performed_via_github_app.description', 'payload.comment.performed_via_github_app.created_at', 'payload.comment.performed_via_github_app.updated_at', 'payload.comment.performed_via_github_app.permissions.checks', 'payload.comment.performed_via_github_app.permissions.contents', 'payload.comment.performed_via_github_app.permissions.issues', 'payload.comment.performed_via_github_app.permissions.members', 'payload.comment.performed_via_github_app.permissions.metadata', 'payload.comment.performed_via_github_app.permissions.pull_requests', 'payload.comment.performed_via_github_app.permissions.statuses', 'payload.comment.performed_via_github_app.permissions.vulnerability_alerts', 'payload.comment.performed_via_github_app.permissions.workflows', 'payload.comment.performed_via_github_app.events', 'payload.number', 'payload.pull_request.number', 'payload.pull_request.state', 'payload.pull_request.locked', 'payload.pull_request.title', 'payload.pull_request.user.login', 'payload.pull_request.user.type', 'payload.pull_request.user.site_admin', 'payload.pull_request.body', 'payload.pull_request.created_at', 'payload.pull_request.updated_at', 'payload.pull_request.closed_at', 'payload.pull_request.merged_at', 'payload.pull_request.assignee', 'payload.pull_request.assignees', 'payload.pull_request.requested_reviewers', 'payload.pull_request.requested_teams', 'payload.pull_request.labels', 'payload.pull_request.milestone', 'payload.pull_request.draft', 'payload.pull_request.head.label', 'payload.pull_request.head.ref', 'payload.pull_request.head.user.login', 'payload.pull_request.head.user.type', 'payload.pull_request.head.user.site_admin', 'payload.pull_request.head.repo.name', 'payload.pull_request.head.repo.full_name', 'payload.pull_request.head.repo.private', 'payload.pull_request.head.repo.owner.login', 'payload.pull_request.head.repo.owner.type', 'payload.pull_request.head.repo.owner.site_admin', 'payload.pull_request.head.repo.description', 'payload.pull_request.head.repo.fork', 'payload.pull_request.head.repo.created_at', 'payload.pull_request.head.repo.updated_at', 'payload.pull_request.head.repo.pushed_at', 'payload.pull_request.head.repo.homepage', 'payload.pull_request.head.repo.size', 'payload.pull_request.head.repo.stargazers_count', 'payload.pull_request.head.repo.watchers_count', 'payload.pull_request.head.repo.language', 'payload.pull_request.head.repo.has_issues', 'payload.pull_request.head.repo.has_projects', 'payload.pull_request.head.repo.has_downloads', 'payload.pull_request.head.repo.has_wiki', 'payload.pull_request.head.repo.has_pages', 'payload.pull_request.head.repo.has_discussions', 'payload.pull_request.head.repo.forks_count', 'payload.pull_request.head.repo.archived', 'payload.pull_request.head.repo.disabled', 'payload.pull_request.head.repo.open_issues_count', 'payload.pull_request.head.repo.license.key', 'payload.pull_request.head.repo.license.name', 'payload.pull_request.head.repo.allow_forking', 'payload.pull_request.head.repo.is_template', 'payload.pull_request.head.repo.web_commit_signoff_required', 'payload.pull_request.head.repo.topics', 'payload.pull_request.head.repo.visibility', 'payload.pull_request.head.repo.forks', 'payload.pull_request.head.repo.open_issues', 'payload.pull_request.head.repo.watchers', 'payload.pull_request.head.repo.default_branch', 'payload.pull_request.base.label', 'payload.pull_request.base.ref', 'payload.pull_request.base.user.login', 'payload.pull_request.base.user.type', 'payload.pull_request.base.user.site_admin', 'payload.pull_request.base.repo.name', 'payload.pull_request.base.repo.full_name', 'payload.pull_request.base.repo.private', 'payload.pull_request.base.repo.owner.login', 'payload.pull_request.base.repo.owner.type', 'payload.pull_request.base.repo.owner.site_admin', 'payload.pull_request.base.repo.description', 'payload.pull_request.base.repo.fork', 'payload.pull_request.base.repo.created_at', 'payload.pull_request.base.repo.updated_at', 'payload.pull_request.base.repo.pushed_at', 'payload.pull_request.base.repo.homepage', 'payload.pull_request.base.repo.size', 'payload.pull_request.base.repo.stargazers_count', 'payload.pull_request.base.repo.watchers_count', 'payload.pull_request.base.repo.language', 'payload.pull_request.base.repo.has_issues', 'payload.pull_request.base.repo.has_projects', 'payload.pull_request.base.repo.has_downloads', 'payload.pull_request.base.repo.has_wiki', 'payload.pull_request.base.repo.has_pages', 'payload.pull_request.base.repo.has_discussions', 'payload.pull_request.base.repo.forks_count', 'payload.pull_request.base.repo.archived', 'payload.pull_request.base.repo.disabled', 'payload.pull_request.base.repo.open_issues_count', 'payload.pull_request.base.repo.license.key', 'payload.pull_request.base.repo.license.name', 'payload.pull_request.base.repo.allow_forking', 'payload.pull_request.base.repo.is_template', 'payload.pull_request.base.repo.web_commit_signoff_required', 'payload.pull_request.base.repo.topics', 'payload.pull_request.base.repo.visibility', 'payload.pull_request.base.repo.forks', 'payload.pull_request.base.repo.open_issues', 'payload.pull_request.base.repo.watchers', 'payload.pull_request.base.repo.default_branch', 'payload.pull_request._links.self.href', 'payload.pull_request._links.html.href', 'payload.pull_request._links.issue.href', 'payload.pull_request._links.comments.href', 'payload.pull_request._links.review_comments.href', 'payload.pull_request._links.review_comment.href', 'payload.pull_request._links.commits.href', 'payload.pull_request._links.statuses.href', 'payload.pull_request.author_association', 'payload.pull_request.auto_merge', 'payload.pull_request.active_lock_reason', 'payload.pull_request.merged', 'payload.pull_request.mergeable', 'payload.pull_request.rebaseable', 'payload.pull_request.mergeable_state', 'payload.pull_request.merged_by', 'payload.pull_request.comments', 'payload.pull_request.review_comments', 'payload.pull_request.maintainer_can_modify', 'payload.pull_request.commits', 'payload.pull_request.additions', 'payload.pull_request.deletions', 'payload.pull_request.changed_files', 'payload.pull_request.assignee.login', 'payload.pull_request.assignee.type', 'payload.pull_request.assignee.site_admin', 'payload.pull_request.merged_by.login', 'payload.pull_request.merged_by.type', 'payload.pull_request.merged_by.site_admin', 'org.login', 'payload.ref_type', 'payload.pusher_type', 'payload.pull_request.head.repo.license', 'payload.pull_request.base.repo.license', 'payload.review.user.login', 'payload.review.user.type', 'payload.review.user.site_admin', 'payload.review.body', 'payload.review.submitted_at', 'payload.review.state', 'payload.review.author_association', 'payload.review._links.html.href', 'payload.review._links.pull_request.href', 'payload.master_branch', 'payload.description', 'payload.comment.position', 'payload.comment.line', 'payload.comment.path', 'payload.comment.performed_via_github_app', 'payload.issue.assignee.login', 'payload.issue.assignee.type', 'payload.issue.assignee.site_admin', 'payload.release.author.login', 'payload.release.author.type', 'payload.release.author.site_admin', 'payload.release.tag_name', 'payload.release.target_commitish', 'payload.release.name', 'payload.release.draft', 'payload.release.prerelease', 'payload.release.created_at', 'payload.release.published_at', 'payload.release.assets', 'payload.release.body', 'payload.release.short_description_html', 'payload.release.is_short_description_html_truncated', 'payload.pull_request.auto_merge.enabled_by.login', 'payload.pull_request.auto_merge.enabled_by.type', 'payload.pull_request.auto_merge.enabled_by.site_admin', 'payload.pull_request.auto_merge.merge_method', 'payload.pull_request.auto_merge.commit_title', 'payload.pull_request.auto_merge.commit_message', 'payload.comment.performed_via_github_app.permissions.actions', 'payload.comment.performed_via_github_app.permissions.administration', 'payload.comment.performed_via_github_app.permissions.deployments', 'payload.comment.performed_via_github_app.permissions.discussions', 'payload.comment.performed_via_github_app.permissions.merge_queues', 'payload.comment.performed_via_github_app.permissions.packages', 'payload.comment.performed_via_github_app.permissions.pages', 'payload.comment.performed_via_github_app.permissions.repository_hooks', 'payload.comment.performed_via_github_app.permissions.repository_projects', 'payload.comment.performed_via_github_app.permissions.security_events', 'payload.comment.performed_via_github_app.permissions.emails', 'payload.issue.milestone.number', 'payload.issue.milestone.title', 'payload.issue.milestone.description', 'payload.issue.milestone.creator.login', 'payload.issue.milestone.creator.type', 'payload.issue.milestone.creator.site_admin', 'payload.issue.milestone.open_issues', 'payload.issue.milestone.closed_issues', 'payload.issue.milestone.state', 'payload.issue.milestone.created_at', 'payload.issue.milestone.updated_at', 'payload.issue.milestone.due_on', 'payload.issue.milestone.closed_at', 'payload.forkee.name', 'payload.forkee.full_name', 'payload.forkee.private', 'payload.forkee.owner.login', 'payload.forkee.owner.type', 'payload.forkee.owner.site_admin', 'payload.forkee.description', 'payload.forkee.fork', 'payload.forkee.created_at', 'payload.forkee.updated_at', 'payload.forkee.pushed_at', 'payload.forkee.homepage', 'payload.forkee.size', 'payload.forkee.stargazers_count', 'payload.forkee.watchers_count', 'payload.forkee.language', 'payload.forkee.has_issues', 'payload.forkee.has_projects', 'payload.forkee.has_downloads', 'payload.forkee.has_wiki', 'payload.forkee.has_pages', 'payload.forkee.has_discussions', 'payload.forkee.forks_count', 'payload.forkee.archived', 'payload.forkee.disabled', 'payload.forkee.open_issues_count', 'payload.forkee.license', 'payload.forkee.allow_forking', 'payload.forkee.is_template', 'payload.forkee.web_commit_signoff_required', 'payload.forkee.topics', 'payload.forkee.visibility', 'payload.forkee.forks', 'payload.forkee.open_issues', 'payload.forkee.watchers', 'payload.forkee.default_branch', 'payload.forkee.public', 'payload.pages', 'payload.member.login', 'payload.member.type', 'payload.member.site_admin', 'payload.comment.performed_via_github_app.permissions.codespaces', 'payload.comment.performed_via_github_app.permissions.organization_administration', 'payload.comment.performed_via_github_app.permissions.organization_hooks', 'payload.comment.performed_via_github_app.permissions.organization_plan', 'payload.comment.performed_via_github_app.permissions.organization_projects', 'payload.comment.performed_via_github_app.permissions.organization_secrets', 'payload.comment.performed_via_github_app.permissions.organization_self_hosted_runners', 'payload.comment.performed_via_github_app.permissions.organization_user_blocking', 'payload.comment.performed_via_github_app.permissions.secrets', 'payload.comment.performed_via_github_app.permissions.team_discussions', 'payload.comment.diff_hunk', 'payload.comment._links.self.href', 'payload.comment._links.html.href', 'payload.comment._links.pull_request.href', 'payload.comment.start_line', 'payload.comment.original_start_line', 'payload.comment.start_side', 'payload.comment.original_line', 'payload.comment.side', 'payload.comment.original_position', 'payload.comment.subject_type', 'payload.pull_request.milestone.number', 'payload.pull_request.milestone.title', 'payload.pull_request.milestone.description', 'payload.pull_request.milestone.creator.login', 'payload.pull_request.milestone.creator.type', 'payload.pull_request.milestone.creator.site_admin', 'payload.pull_request.milestone.open_issues', 'payload.pull_request.milestone.closed_issues', 'payload.pull_request.milestone.state', 'payload.pull_request.milestone.created_at', 'payload.pull_request.milestone.updated_at', 'payload.pull_request.milestone.due_on', 'payload.pull_request.milestone.closed_at', 'payload.comment.performed_via_github_app.permissions.environments', 'payload.comment.performed_via_github_app.permissions.secret_scanning_alerts', 'payload.comment.performed_via_github_app.permissions.codespaces_metadata', 'payload.release.mentions_count', 'payload.release.mentions', 'payload.comment.performed_via_github_app.permissions.single_file', 'payload.comment.performed_via_github_app.permissions.dependabot_secrets', 'payload.comment.performed_via_github_app.permissions.plan', 'payload.comment.performed_via_github_app.permissions.actions_variables', 'payload.comment.performed_via_github_app.permissions.gists', 'payload.comment.performed_via_github_app.permissions.codespaces_user_secrets', 'payload.comment.performed_via_github_app.permissions.organization_events', 'payload.forkee.license.key', 'payload.forkee.license.name', 'payload.comment.performed_via_github_app.permissions.organization_custom_properties', 'payload.comment.performed_via_github_app.permissions.organization_custom_roles', 'payload.comment.performed_via_github_app.permissions.blocking', 'payload.comment.performed_via_github_app.permissions.followers', 'payload.comment.performed_via_github_app.permissions.gpg_keys', 'payload.comment.performed_via_github_app.permissions.interaction_limits', 'payload.comment.performed_via_github_app.permissions.keys', 'payload.comment.performed_via_github_app.permissions.organization_dependabot_secrets', 'payload.comment.performed_via_github_app.permissions.starring', 'payload.comment.performed_via_github_app.permissions.watching', 'payload.comment.performed_via_github_app.permissions.codespaces_lifecycle_admin', 'payload.comment.performed_via_github_app.permissions.codespaces_secrets', 'payload.comment.performed_via_github_app.permissions.repository_advisories', 'date', 'hour']\n"
     ]
    }
   ],
   "source": [
    "print(len(flat.columns))\n",
    "print(list(flat.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ef1d107d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# 2) 평탄화 직후 \"즉시 삭제\" 패턴: 명백한 식별자/URL/해시류\n",
    "DROP_AFTER_FLATTEN_PATTERNS = [\n",
    "    r'(^|[._])id$', r'node_id', r'guid', r'uuid', r'(^|[._])sha$',\n",
    "    r'avatar_url', r'html_url', r'git_url', r'ssh_url', r'clone_url', r'svn_url',\n",
    "    r'_url$', r'(^|[._])url$',\n",
    "    r'^actor[._](login|display_login)$',\n",
    "    r'^repo[._](name|owner|repo|full_name)$',\n",
    "]\n",
    "\n",
    "def _re_any_match(patterns: list[str], text: str) -> bool:\n",
    "    return any(re.search(p, text) for p in patterns)\n",
    "\n",
    "def drop_after_flatten(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"평탄화된 DataFrame에서 DROP_AFTER_FLATTEN_PATTERNS에 매칭되는 컬럼 삭제\"\"\"\n",
    "    drop_cols = [c for c in df.columns if _re_any_match(DROP_AFTER_FLATTEN_PATTERNS, c)]\n",
    "    return df.drop(columns=drop_cols, errors=\"ignore\")\n",
    "\n",
    "flat = drop_after_flatten(flat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7c13497e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(158214, 379)\n",
      "379\n",
      "['type', 'created_at', 'org', 'payload.size', 'payload.distinct_size', 'payload.ref', 'payload.head', 'payload.before', 'payload.commits', 'payload.action', 'payload.issue.number', 'payload.issue.title', 'payload.issue.user.login', 'payload.issue.user.type', 'payload.issue.user.site_admin', 'payload.issue.labels', 'payload.issue.state', 'payload.issue.locked', 'payload.issue.assignee', 'payload.issue.assignees', 'payload.issue.milestone', 'payload.issue.comments', 'payload.issue.created_at', 'payload.issue.updated_at', 'payload.issue.closed_at', 'payload.issue.author_association', 'payload.issue.active_lock_reason', 'payload.issue.draft', 'payload.issue.pull_request.merged_at', 'payload.issue.body', 'payload.issue.reactions.total_count', 'payload.issue.reactions.+1', 'payload.issue.reactions.-1', 'payload.issue.reactions.laugh', 'payload.issue.reactions.hooray', 'payload.issue.reactions.confused', 'payload.issue.reactions.heart', 'payload.issue.reactions.rocket', 'payload.issue.reactions.eyes', 'payload.issue.performed_via_github_app', 'payload.issue.state_reason', 'payload.comment.user.login', 'payload.comment.user.type', 'payload.comment.user.site_admin', 'payload.comment.created_at', 'payload.comment.updated_at', 'payload.comment.author_association', 'payload.comment.body', 'payload.comment.reactions.total_count', 'payload.comment.reactions.+1', 'payload.comment.reactions.-1', 'payload.comment.reactions.laugh', 'payload.comment.reactions.hooray', 'payload.comment.reactions.confused', 'payload.comment.reactions.heart', 'payload.comment.reactions.rocket', 'payload.comment.reactions.eyes', 'payload.comment.performed_via_github_app.slug', 'payload.comment.performed_via_github_app.owner.login', 'payload.comment.performed_via_github_app.owner.type', 'payload.comment.performed_via_github_app.owner.site_admin', 'payload.comment.performed_via_github_app.name', 'payload.comment.performed_via_github_app.description', 'payload.comment.performed_via_github_app.created_at', 'payload.comment.performed_via_github_app.updated_at', 'payload.comment.performed_via_github_app.permissions.checks', 'payload.comment.performed_via_github_app.permissions.contents', 'payload.comment.performed_via_github_app.permissions.issues', 'payload.comment.performed_via_github_app.permissions.members', 'payload.comment.performed_via_github_app.permissions.metadata', 'payload.comment.performed_via_github_app.permissions.pull_requests', 'payload.comment.performed_via_github_app.permissions.statuses', 'payload.comment.performed_via_github_app.permissions.vulnerability_alerts', 'payload.comment.performed_via_github_app.permissions.workflows', 'payload.comment.performed_via_github_app.events', 'payload.number', 'payload.pull_request.number', 'payload.pull_request.state', 'payload.pull_request.locked', 'payload.pull_request.title', 'payload.pull_request.user.login', 'payload.pull_request.user.type', 'payload.pull_request.user.site_admin', 'payload.pull_request.body', 'payload.pull_request.created_at', 'payload.pull_request.updated_at', 'payload.pull_request.closed_at', 'payload.pull_request.merged_at', 'payload.pull_request.assignee', 'payload.pull_request.assignees', 'payload.pull_request.requested_reviewers', 'payload.pull_request.requested_teams', 'payload.pull_request.labels', 'payload.pull_request.milestone', 'payload.pull_request.draft', 'payload.pull_request.head.label', 'payload.pull_request.head.ref', 'payload.pull_request.head.user.login', 'payload.pull_request.head.user.type', 'payload.pull_request.head.user.site_admin', 'payload.pull_request.head.repo.name', 'payload.pull_request.head.repo.full_name', 'payload.pull_request.head.repo.private', 'payload.pull_request.head.repo.owner.login', 'payload.pull_request.head.repo.owner.type', 'payload.pull_request.head.repo.owner.site_admin', 'payload.pull_request.head.repo.description', 'payload.pull_request.head.repo.fork', 'payload.pull_request.head.repo.created_at', 'payload.pull_request.head.repo.updated_at', 'payload.pull_request.head.repo.pushed_at', 'payload.pull_request.head.repo.homepage', 'payload.pull_request.head.repo.size', 'payload.pull_request.head.repo.stargazers_count', 'payload.pull_request.head.repo.watchers_count', 'payload.pull_request.head.repo.language', 'payload.pull_request.head.repo.has_issues', 'payload.pull_request.head.repo.has_projects', 'payload.pull_request.head.repo.has_downloads', 'payload.pull_request.head.repo.has_wiki', 'payload.pull_request.head.repo.has_pages', 'payload.pull_request.head.repo.has_discussions', 'payload.pull_request.head.repo.forks_count', 'payload.pull_request.head.repo.archived', 'payload.pull_request.head.repo.disabled', 'payload.pull_request.head.repo.open_issues_count', 'payload.pull_request.head.repo.license.key', 'payload.pull_request.head.repo.license.name', 'payload.pull_request.head.repo.allow_forking', 'payload.pull_request.head.repo.is_template', 'payload.pull_request.head.repo.web_commit_signoff_required', 'payload.pull_request.head.repo.topics', 'payload.pull_request.head.repo.visibility', 'payload.pull_request.head.repo.forks', 'payload.pull_request.head.repo.open_issues', 'payload.pull_request.head.repo.watchers', 'payload.pull_request.head.repo.default_branch', 'payload.pull_request.base.label', 'payload.pull_request.base.ref', 'payload.pull_request.base.user.login', 'payload.pull_request.base.user.type', 'payload.pull_request.base.user.site_admin', 'payload.pull_request.base.repo.name', 'payload.pull_request.base.repo.full_name', 'payload.pull_request.base.repo.private', 'payload.pull_request.base.repo.owner.login', 'payload.pull_request.base.repo.owner.type', 'payload.pull_request.base.repo.owner.site_admin', 'payload.pull_request.base.repo.description', 'payload.pull_request.base.repo.fork', 'payload.pull_request.base.repo.created_at', 'payload.pull_request.base.repo.updated_at', 'payload.pull_request.base.repo.pushed_at', 'payload.pull_request.base.repo.homepage', 'payload.pull_request.base.repo.size', 'payload.pull_request.base.repo.stargazers_count', 'payload.pull_request.base.repo.watchers_count', 'payload.pull_request.base.repo.language', 'payload.pull_request.base.repo.has_issues', 'payload.pull_request.base.repo.has_projects', 'payload.pull_request.base.repo.has_downloads', 'payload.pull_request.base.repo.has_wiki', 'payload.pull_request.base.repo.has_pages', 'payload.pull_request.base.repo.has_discussions', 'payload.pull_request.base.repo.forks_count', 'payload.pull_request.base.repo.archived', 'payload.pull_request.base.repo.disabled', 'payload.pull_request.base.repo.open_issues_count', 'payload.pull_request.base.repo.license.key', 'payload.pull_request.base.repo.license.name', 'payload.pull_request.base.repo.allow_forking', 'payload.pull_request.base.repo.is_template', 'payload.pull_request.base.repo.web_commit_signoff_required', 'payload.pull_request.base.repo.topics', 'payload.pull_request.base.repo.visibility', 'payload.pull_request.base.repo.forks', 'payload.pull_request.base.repo.open_issues', 'payload.pull_request.base.repo.watchers', 'payload.pull_request.base.repo.default_branch', 'payload.pull_request._links.self.href', 'payload.pull_request._links.html.href', 'payload.pull_request._links.issue.href', 'payload.pull_request._links.comments.href', 'payload.pull_request._links.review_comments.href', 'payload.pull_request._links.review_comment.href', 'payload.pull_request._links.commits.href', 'payload.pull_request._links.statuses.href', 'payload.pull_request.author_association', 'payload.pull_request.auto_merge', 'payload.pull_request.active_lock_reason', 'payload.pull_request.merged', 'payload.pull_request.mergeable', 'payload.pull_request.rebaseable', 'payload.pull_request.mergeable_state', 'payload.pull_request.merged_by', 'payload.pull_request.comments', 'payload.pull_request.review_comments', 'payload.pull_request.maintainer_can_modify', 'payload.pull_request.commits', 'payload.pull_request.additions', 'payload.pull_request.deletions', 'payload.pull_request.changed_files', 'payload.pull_request.assignee.login', 'payload.pull_request.assignee.type', 'payload.pull_request.assignee.site_admin', 'payload.pull_request.merged_by.login', 'payload.pull_request.merged_by.type', 'payload.pull_request.merged_by.site_admin', 'org.login', 'payload.ref_type', 'payload.pusher_type', 'payload.pull_request.head.repo.license', 'payload.pull_request.base.repo.license', 'payload.review.user.login', 'payload.review.user.type', 'payload.review.user.site_admin', 'payload.review.body', 'payload.review.submitted_at', 'payload.review.state', 'payload.review.author_association', 'payload.review._links.html.href', 'payload.review._links.pull_request.href', 'payload.master_branch', 'payload.description', 'payload.comment.position', 'payload.comment.line', 'payload.comment.path', 'payload.comment.performed_via_github_app', 'payload.issue.assignee.login', 'payload.issue.assignee.type', 'payload.issue.assignee.site_admin', 'payload.release.author.login', 'payload.release.author.type', 'payload.release.author.site_admin', 'payload.release.tag_name', 'payload.release.target_commitish', 'payload.release.name', 'payload.release.draft', 'payload.release.prerelease', 'payload.release.created_at', 'payload.release.published_at', 'payload.release.assets', 'payload.release.body', 'payload.release.short_description_html', 'payload.release.is_short_description_html_truncated', 'payload.pull_request.auto_merge.enabled_by.login', 'payload.pull_request.auto_merge.enabled_by.type', 'payload.pull_request.auto_merge.enabled_by.site_admin', 'payload.pull_request.auto_merge.merge_method', 'payload.pull_request.auto_merge.commit_title', 'payload.pull_request.auto_merge.commit_message', 'payload.comment.performed_via_github_app.permissions.actions', 'payload.comment.performed_via_github_app.permissions.administration', 'payload.comment.performed_via_github_app.permissions.deployments', 'payload.comment.performed_via_github_app.permissions.discussions', 'payload.comment.performed_via_github_app.permissions.merge_queues', 'payload.comment.performed_via_github_app.permissions.packages', 'payload.comment.performed_via_github_app.permissions.pages', 'payload.comment.performed_via_github_app.permissions.repository_hooks', 'payload.comment.performed_via_github_app.permissions.repository_projects', 'payload.comment.performed_via_github_app.permissions.security_events', 'payload.comment.performed_via_github_app.permissions.emails', 'payload.issue.milestone.number', 'payload.issue.milestone.title', 'payload.issue.milestone.description', 'payload.issue.milestone.creator.login', 'payload.issue.milestone.creator.type', 'payload.issue.milestone.creator.site_admin', 'payload.issue.milestone.open_issues', 'payload.issue.milestone.closed_issues', 'payload.issue.milestone.state', 'payload.issue.milestone.created_at', 'payload.issue.milestone.updated_at', 'payload.issue.milestone.due_on', 'payload.issue.milestone.closed_at', 'payload.forkee.name', 'payload.forkee.full_name', 'payload.forkee.private', 'payload.forkee.owner.login', 'payload.forkee.owner.type', 'payload.forkee.owner.site_admin', 'payload.forkee.description', 'payload.forkee.fork', 'payload.forkee.created_at', 'payload.forkee.updated_at', 'payload.forkee.pushed_at', 'payload.forkee.homepage', 'payload.forkee.size', 'payload.forkee.stargazers_count', 'payload.forkee.watchers_count', 'payload.forkee.language', 'payload.forkee.has_issues', 'payload.forkee.has_projects', 'payload.forkee.has_downloads', 'payload.forkee.has_wiki', 'payload.forkee.has_pages', 'payload.forkee.has_discussions', 'payload.forkee.forks_count', 'payload.forkee.archived', 'payload.forkee.disabled', 'payload.forkee.open_issues_count', 'payload.forkee.license', 'payload.forkee.allow_forking', 'payload.forkee.is_template', 'payload.forkee.web_commit_signoff_required', 'payload.forkee.topics', 'payload.forkee.visibility', 'payload.forkee.forks', 'payload.forkee.open_issues', 'payload.forkee.watchers', 'payload.forkee.default_branch', 'payload.forkee.public', 'payload.pages', 'payload.member.login', 'payload.member.type', 'payload.member.site_admin', 'payload.comment.performed_via_github_app.permissions.codespaces', 'payload.comment.performed_via_github_app.permissions.organization_administration', 'payload.comment.performed_via_github_app.permissions.organization_hooks', 'payload.comment.performed_via_github_app.permissions.organization_plan', 'payload.comment.performed_via_github_app.permissions.organization_projects', 'payload.comment.performed_via_github_app.permissions.organization_secrets', 'payload.comment.performed_via_github_app.permissions.organization_self_hosted_runners', 'payload.comment.performed_via_github_app.permissions.organization_user_blocking', 'payload.comment.performed_via_github_app.permissions.secrets', 'payload.comment.performed_via_github_app.permissions.team_discussions', 'payload.comment.diff_hunk', 'payload.comment._links.self.href', 'payload.comment._links.html.href', 'payload.comment._links.pull_request.href', 'payload.comment.start_line', 'payload.comment.original_start_line', 'payload.comment.start_side', 'payload.comment.original_line', 'payload.comment.side', 'payload.comment.original_position', 'payload.comment.subject_type', 'payload.pull_request.milestone.number', 'payload.pull_request.milestone.title', 'payload.pull_request.milestone.description', 'payload.pull_request.milestone.creator.login', 'payload.pull_request.milestone.creator.type', 'payload.pull_request.milestone.creator.site_admin', 'payload.pull_request.milestone.open_issues', 'payload.pull_request.milestone.closed_issues', 'payload.pull_request.milestone.state', 'payload.pull_request.milestone.created_at', 'payload.pull_request.milestone.updated_at', 'payload.pull_request.milestone.due_on', 'payload.pull_request.milestone.closed_at', 'payload.comment.performed_via_github_app.permissions.environments', 'payload.comment.performed_via_github_app.permissions.secret_scanning_alerts', 'payload.comment.performed_via_github_app.permissions.codespaces_metadata', 'payload.release.mentions_count', 'payload.release.mentions', 'payload.comment.performed_via_github_app.permissions.single_file', 'payload.comment.performed_via_github_app.permissions.dependabot_secrets', 'payload.comment.performed_via_github_app.permissions.plan', 'payload.comment.performed_via_github_app.permissions.actions_variables', 'payload.comment.performed_via_github_app.permissions.gists', 'payload.comment.performed_via_github_app.permissions.codespaces_user_secrets', 'payload.comment.performed_via_github_app.permissions.organization_events', 'payload.forkee.license.key', 'payload.forkee.license.name', 'payload.comment.performed_via_github_app.permissions.organization_custom_properties', 'payload.comment.performed_via_github_app.permissions.organization_custom_roles', 'payload.comment.performed_via_github_app.permissions.blocking', 'payload.comment.performed_via_github_app.permissions.followers', 'payload.comment.performed_via_github_app.permissions.gpg_keys', 'payload.comment.performed_via_github_app.permissions.interaction_limits', 'payload.comment.performed_via_github_app.permissions.keys', 'payload.comment.performed_via_github_app.permissions.organization_dependabot_secrets', 'payload.comment.performed_via_github_app.permissions.starring', 'payload.comment.performed_via_github_app.permissions.watching', 'payload.comment.performed_via_github_app.permissions.codespaces_lifecycle_admin', 'payload.comment.performed_via_github_app.permissions.codespaces_secrets', 'payload.comment.performed_via_github_app.permissions.repository_advisories', 'date', 'hour']\n"
     ]
    }
   ],
   "source": [
    "print(flat.shape)\n",
    "print(len(flat.columns))\n",
    "print(list(flat.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c88b3a",
   "metadata": {},
   "source": [
    "# Profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "060cdea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "리스트 컬럼 개수: 14\n",
      "\n",
      "<리스트 컬럼 예시>\n",
      "- 컬럼명: payload.commits\n",
      "[{'sha': '195646fd7c4df907171342c983e3ebdbbf1586ce', 'author': {'email': 'you@example.com', 'name': 'Your Name'}, 'message': 'Empty Commit', 'distinct': True, 'url': 'https://api.github.com/repos/appref5555ix63/Repo1/commits/195646fd7c4df907171342c983e3ebdbbf1586ce'}]\n",
      "- 컬럼명: payload.issue.labels\n",
      "[{'id': 3667482194, 'node_id': 'LA_kwDOEk9Avc7amVZS', 'url': 'https://api.github.com/repos/wei/gogs/labels/dependencies', 'name': 'dependencies', 'color': '0366d6', 'default': False, 'description': 'Pull requests that update a dependency file'}]\n",
      "- 컬럼명: payload.issue.assignees\n",
      "[]\n",
      "- 컬럼명: payload.comment.performed_via_github_app.events\n",
      "['check_suite', 'issues', 'issue_comment', 'label', 'pull_request', 'pull_request_review', 'pull_request_review_comment', 'repository']\n",
      "- 컬럼명: payload.pull_request.assignees\n",
      "[]\n",
      "- 컬럼명: payload.pull_request.requested_reviewers\n",
      "[]\n",
      "- 컬럼명: payload.pull_request.requested_teams\n",
      "[]\n",
      "- 컬럼명: payload.pull_request.labels\n",
      "[{'id': 3667482194, 'node_id': 'LA_kwDOEk9Avc7amVZS', 'url': 'https://api.github.com/repos/wei/gogs/labels/dependencies', 'name': 'dependencies', 'color': '0366d6', 'default': False, 'description': 'Pull requests that update a dependency file'}]\n",
      "- 컬럼명: payload.pull_request.head.repo.topics\n",
      "[]\n",
      "- 컬럼명: payload.pull_request.base.repo.topics\n",
      "[]\n",
      "- 컬럼명: payload.release.assets\n",
      "[]\n",
      "- 컬럼명: payload.forkee.topics\n",
      "[]\n",
      "- 컬럼명: payload.pages\n",
      "[{'page_name': '상세보기', 'title': '상세보기', 'summary': None, 'action': 'edited', 'sha': 'b5c511d3b95479770a85fd3b8dcef24db32903f9', 'html_url': 'https://github.com/SoftStar99/Mallie-Project/wiki/%EC%83%81%EC%84%B8%EB%B3%B4%EA%B8%B0'}]\n",
      "- 컬럼명: payload.release.mentions\n",
      "[{'avatar_url': 'https://avatars.githubusercontent.com/u/43080478?v=4', 'login': 'aws-cdk-automation', 'profile_name': 'AWS CDK Automation', 'profile_url': 'https://github.com/aws-cdk-automation', 'avatar_user_actor': True}]\n",
      "\n",
      "\n",
      "딕셔너리 컬럼 개수: 0\n",
      "\n",
      "<딕셔너리 컬럼 예시>\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = flat.copy()\n",
    "\n",
    "# 컬럼별로 값 타입 확인\n",
    "list_cols = []\n",
    "dict_cols = []\n",
    "\n",
    "for c in df.columns:\n",
    "    if df[c].dtype == \"object\":  # object 타입만 검사\n",
    "        sample = df[c].dropna().head(20)  # 결측 제외, 샘플 20개만 확인\n",
    "        if not sample.empty:\n",
    "            if sample.apply(lambda x: isinstance(x, list)).any():\n",
    "                list_cols.append(c)\n",
    "            elif sample.apply(lambda x: isinstance(x, dict)).any():\n",
    "                dict_cols.append(c)\n",
    "\n",
    "print(\"리스트 컬럼 개수:\", len(list_cols))\n",
    "print(\"\\n<리스트 컬럼 예시>\")\n",
    "for c in list_cols:\n",
    "    print(f\"- 컬럼명: {c}\")\n",
    "    print(df[c].dropna().iloc[0])  # 첫 번째 비결측 값 예시\n",
    "\n",
    "print(\"\\n\\n딕셔너리 컬럼 개수:\", len(dict_cols))\n",
    "print(\"\\n<딕셔너리 컬럼 예시>\")\n",
    "for c in dict_cols:\n",
    "    print(f\"- 컬럼명: {c}\")\n",
    "    print(df[c].dropna().iloc[0])  # 첫 번째 비결측 값 예시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc0625f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\npayload.commits: 한 번의 Push에서 함께 올라간 커밋 객체들의 목록(sha, message, author 등).\\n\\npayload.issue.labels: 이슈에 붙은 라벨들의 목록(이름, 색상, 설명 등).\\n\\npayload.issue.assignees: 이슈 담당자(유저) 목록.\\n\\npayload.comment.performed_via_github_app.events: 해당 코멘트를 수행한 GitHub App이 구독하는 이벤트 타입 목록(예: pull_request, issues…).\\n\\npayload.pull_request.assignee, payload.pull_request.assignees: PR 담당자(유저) 목록.\\n\\npayload.pull_request.head.repo.topics, payload.pull_request.base.repo.topics, payload.forkee.topics : 리포 주제 태그\\n\\npayload.release.assets : 릴리스 자산들\\n\\npayload.pages : GitHub Pages 관련 변경\\n\\npayload.release.mentions : 릴리스 노트 멘션(자동화 계정 등)\\n\\npayload.comment.performed_via_github_app.events : 해당 GitHub App이 구독하는 이벤트들\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "payload.commits: 한 번의 Push에서 함께 올라간 커밋 객체들의 목록(sha, message, author 등).\n",
    "\n",
    "payload.issue.labels: 이슈에 붙은 라벨들의 목록(이름, 색상, 설명 등).\n",
    "\n",
    "payload.issue.assignees: 이슈 담당자(유저) 목록.\n",
    "\n",
    "payload.comment.performed_via_github_app.events: 해당 코멘트를 수행한 GitHub App이 구독하는 이벤트 타입 목록(예: pull_request, issues…).\n",
    "\n",
    "payload.pull_request.assignee, payload.pull_request.assignees: PR 담당자(유저) 목록.\n",
    "\n",
    "payload.pull_request.head.repo.topics, payload.pull_request.base.repo.topics, payload.forkee.topics : 리포 주제 태그\n",
    "\n",
    "payload.release.assets : 릴리스 자산들\n",
    "\n",
    "payload.pages : GitHub Pages 관련 변경\n",
    "\n",
    "payload.release.mentions : 릴리스 노트 멘션(자동화 계정 등)\n",
    "\n",
    "payload.comment.performed_via_github_app.events : 해당 GitHub App이 구독하는 이벤트들\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fdfae67a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['payload.commits',\n",
       " 'payload.issue.labels',\n",
       " 'payload.issue.assignees',\n",
       " 'payload.comment.performed_via_github_app.events',\n",
       " 'payload.pull_request.assignees',\n",
       " 'payload.pull_request.requested_reviewers',\n",
       " 'payload.pull_request.requested_teams',\n",
       " 'payload.pull_request.labels',\n",
       " 'payload.pull_request.head.repo.topics',\n",
       " 'payload.pull_request.base.repo.topics',\n",
       " 'payload.release.assets',\n",
       " 'payload.forkee.topics',\n",
       " 'payload.pages',\n",
       " 'payload.release.mentions']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "511fde4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본 컬럼: 379 → 처리 후: 398\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "new_feats = pd.DataFrame(index=df.index)\n",
    "\n",
    "# ------------------------------\n",
    "# 각 리스트 컬럼별 처리\n",
    "# ------------------------------\n",
    "\n",
    "# 1) commits\n",
    "### 평소와 다르게 커밋 메시지가 아예 비어 있거나, 갑자기 커밋 개수가 확 늘면 이상행동 신호가 될 수 있어요.\n",
    "if 'payload.commits' in list_cols:\n",
    "    def commits_stats(arr):\n",
    "        if not isinstance(arr, list) or len(arr) == 0:\n",
    "            return pd.Series({\n",
    "                \"f_commits_n\": 0,\n",
    "                \"f_commits_n_distinct\": 0,\n",
    "                \"f_commits_avg_msg_len\": 0.0,\n",
    "                \"f_commits_max_msg_len\": 0,\n",
    "                \"f_commits_has_empty_msg\": 0,\n",
    "            })\n",
    "        msg_lens, n_distinct, empty_flag = [], 0, 0\n",
    "        for it in arr:\n",
    "            if isinstance(it, dict):\n",
    "                msg = it.get(\"message\")\n",
    "                if not msg or not str(msg).strip():\n",
    "                    empty_flag = 1\n",
    "                if isinstance(msg, str):\n",
    "                    msg_lens.append(len(msg))\n",
    "                if it.get(\"distinct\") is True:\n",
    "                    n_distinct += 1\n",
    "        return pd.Series({\n",
    "            \"f_commits_n\": len(arr),   # 푸시된 커밋 개수\n",
    "            \"f_commits_n_distinct\": n_distinct,   # distinct=True인 커밋 개수 (중복 아닌 순수 커밋 수)\n",
    "            \"f_commits_avg_msg_len\": float(np.mean(msg_lens)) if msg_lens else 0.0,   # 커밋 메시지 평균 길이\n",
    "            \"f_commits_max_msg_len\": int(np.max(msg_lens)) if msg_lens else 0,  # 커밋 메시지 중 가장 긴 것의 길이\n",
    "            \"f_commits_has_empty_msg\": empty_flag,  # 메시지가 비어 있거나 공백뿐인 커밋이 있었는지 (0=없음, 1=있음)\n",
    "        })\n",
    "    new_feats = pd.concat([new_feats, df['payload.commits'].apply(commits_stats)], axis=1)\n",
    "\n",
    "# 2) issue / PR labels\n",
    "### “보안(Security)” 라벨이나 “의존성(Dependencies)” 라벨이 갑자기 많이 붙는 경우 → 비정상 활동 징후일 수 있음.\n",
    "def labels_feats(arr, prefix):\n",
    "    if not isinstance(arr, list) or len(arr) == 0:\n",
    "        return pd.Series({\n",
    "            f\"f_{prefix}_labels_n\": 0,\n",
    "            f\"f_{prefix}_labels_has_bug\": 0,\n",
    "            f\"f_{prefix}_labels_has_dependencies\": 0,\n",
    "            f\"f_{prefix}_labels_has_security\": 0\n",
    "        })\n",
    "    names = [str(it.get(\"name\",\"\")).lower() for it in arr if isinstance(it, dict)]\n",
    "    def has(k): return int(any(k in n for n in names))\n",
    "    return pd.Series({\n",
    "        f\"f_{prefix}_labels_n\": len(arr),   # 이슈/PR에 달린 라벨 개수\n",
    "        f\"f_{prefix}_labels_has_bug\": has(\"bug\"),   # bug 라벨이 있는지\n",
    "        f\"f_{prefix}_labels_has_dependencies\": has(\"dependenc\"),   # dependencies 라벨이 있는지\n",
    "        f\"f_{prefix}_labels_has_security\": has(\"security\")  # security 라벨이 있는지\n",
    "    })\n",
    "\n",
    "if 'payload.issue.labels' in list_cols:\n",
    "    new_feats = pd.concat([new_feats, df['payload.issue.labels'].apply(lambda x: labels_feats(x,\"issue\"))], axis=1)\n",
    "\n",
    "if 'payload.pull_request.labels' in list_cols:\n",
    "    new_feats = pd.concat([new_feats, df['payload.pull_request.labels'].apply(lambda x: labels_feats(x,\"pr\"))], axis=1)\n",
    "\n",
    "# 3) assignees / reviewers / teams → 단순 개수\n",
    "### 갑자기 너무 많은 사람/팀을 배정하거나, 평소 없던 팀에 리뷰 요청이 몰리면 의심 상황.\n",
    "for col in [\n",
    "    'payload.issue.assignees',  # -> 이슈에 지정된 담당자 수 \n",
    "    'payload.pull_request.assignees',  # -> PR에 지정된 담당자 수 \n",
    "    'payload.pull_request.requested_reviewers',  # -> 리뷰 요청된 사용자 수\n",
    "    'payload.pull_request.requested_teams'  # -> 리뷰 요청된 팀 수 \n",
    "]:\n",
    "    if col in list_cols and col in df.columns:\n",
    "        new_feats[f\"f_{col}_n\"] = df[col].apply(lambda x: len(x) if isinstance(x, list) else 0)\n",
    "\n",
    "# 4) topics\n",
    "### 특정 주제(토픽)가 갑자기 추가되거나, 평소 없는 토픽이 붙는 경우\n",
    "for col in ['payload.pull_request.head.repo.topics', 'payload.pull_request.base.repo.topics', 'payload.forkee.topics']:\n",
    "    if col in list_cols and col in df.columns:\n",
    "        new_feats[f\"f_{col}_n\"] = df[col].apply(lambda x: len(x) if isinstance(x, list) else 0)  # ~~에 붙은 토픽 개수\n",
    "        new_feats[f\"f_{col}_has_any\"] = (new_feats[f\"f_{col}_n\"] > 0).astype(int)   # 토픽이 하나라도 있으면 1\n",
    "\n",
    "# 5) release.assets\n",
    "### 평소 안 나오던 자동화 계정이 릴리스에 언급되면 자동화/스크립트 공격 가능성 체크\n",
    "if 'payload.release.assets' in list_cols and 'payload.release.assets' in df.columns:\n",
    "    def assets_feats(arr):\n",
    "        if not isinstance(arr, list) or len(arr) == 0:\n",
    "            return pd.Series({\"f_release_assets_n\": 0,  # 릴리스에 첨부된 파일 개수\n",
    "                              \"f_release_assets_total_size\": 0, # 첨부 파일들의 크기 합계\n",
    "                              \"f_release_assets_total_dl\": 0})  # 첨부 파일들의 다운로드 수 합계\n",
    "        total_size, total_dl = 0, 0\n",
    "        for it in arr:\n",
    "            if isinstance(it, dict):\n",
    "                total_size += int(it.get(\"size\",0) or 0)\n",
    "                total_dl += int(it.get(\"download_count\",0) or 0)\n",
    "        return pd.Series({\"f_release_assets_n\": len(arr), \"f_release_assets_total_size\": total_size, \"f_release_assets_total_dl\": total_dl})\n",
    "    new_feats = pd.concat([new_feats, df['payload.release.assets'].apply(assets_feats)], axis=1)\n",
    "\n",
    "# 6) pages\n",
    "### 문서만 바꾸는 줄 알았는데 자꾸 수정(action=edited)이 들어오면, 비정상적인 문서 변경 신호.\n",
    "if 'payload.pages' in list_cols and 'payload.pages' in df.columns:\n",
    "    def pages_feats(arr):\n",
    "        if not isinstance(arr, list) or len(arr) == 0:\n",
    "            return pd.Series({\"f_pages_n\": 0,   # Pages 이벤트 개수 (보통 문서 페이지 수정) \n",
    "                              \"f_pages_has_edited\": 0})  # action 값이 edited 인 페이지가 있었는지\n",
    "        edited = int(any(str(it.get(\"action\",\"\")).lower()==\"edited\" for it in arr if isinstance(it, dict)))\n",
    "        return pd.Series({\"f_pages_n\": len(arr), \"f_pages_has_edited\": edited})\n",
    "    new_feats = pd.concat([new_feats, df['payload.pages'].apply(pages_feats)], axis=1)\n",
    "\n",
    "# 7) release.mentions\n",
    "### 평소 안 나오던 자동화 계정이 릴리스에 언급되면 자동화/스크립트 공격 가능성 체크\n",
    "if 'payload.release.mentions' in list_cols and 'payload.release.mentions' in df.columns:\n",
    "    def mentions_feats(arr):\n",
    "        if not isinstance(arr, list) or len(arr) == 0:\n",
    "            return pd.Series({\"f_release_mentions_n\": 0, \"f_release_mentions_has_auto\": 0})\n",
    "        auto = int(any(\"bot\" in str(it.get(\"login\",\"\")).lower() or  \n",
    "                       \"auto\" in str(it.get(\"login\",\"\")).lower()\n",
    "                       for it in arr if isinstance(it, dict)))\n",
    "        return pd.Series({\"f_release_mentions_n\": len(arr), # 릴리스 노트에 언급된 사용자/계정 수\n",
    "                          \"f_release_mentions_has_auto\": auto})   # 봇/자동화 계정(예: bot, automation)이 멘션되었는지\n",
    "    new_feats = pd.concat([new_feats, df['payload.release.mentions'].apply(mentions_feats)], axis=1)\n",
    "\n",
    "# 8) app.events\n",
    "### 갑자기 구독 이벤트 개수가 많아지거나, 특정 이벤트(pull_request)만 집중되면 이상 신호\n",
    "if 'payload.comment.performed_via_github_app.events' in list_cols and 'payload.comment.performed_via_github_app.events' in df.columns:\n",
    "    def app_events_feats(arr):\n",
    "        if not isinstance(arr, list) or len(arr) == 0:\n",
    "            return pd.Series({\"f_app_events_n\": 0,\"f_app_events_has_pr\":0,\"f_app_events_has_issues\":0})\n",
    "        low = [str(x).lower() for x in arr]\n",
    "        return pd.Series({\n",
    "            \"f_app_events_n\": len(arr), # 앱이 구독하는 이벤트 개수\n",
    "            \"f_app_events_has_pr\": int(any(\"pull_request\" in e for e in low)),  # pull_request 관련 이벤트를 구독하는지\n",
    "            \"f_app_events_has_issues\": int(any(\"issues\" in e for e in low)) # issues 관련 이벤트를 구독하는지\n",
    "        })\n",
    "    new_feats = pd.concat([new_feats, df['payload.comment.performed_via_github_app.events'].apply(app_events_feats)], axis=1)\n",
    "\n",
    "# ------------------------------\n",
    "# 최종 결과: 리스트 컬럼 드롭 + 요약 피처 붙이기\n",
    "# ------------------------------\n",
    "df_lists_processed = pd.concat([df.drop(columns=list_cols, errors=\"ignore\"), new_feats], axis=1)\n",
    "\n",
    "print(\"원본 컬럼:\", df.shape[1], \"→ 처리 후:\", df_lists_processed.shape[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db4e77c",
   "metadata": {},
   "source": [
    "모든 컬럼이 평탄화 됐는지 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "da8db0d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "리스트 컬럼 개수: 0\n",
      "\n",
      "딕셔너리 컬럼 개수: 0\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ===== 입력: 리스트/딕셔너리 처리 이후 DF =====\n",
    "DF = df_lists_processed.copy()\n",
    "\n",
    "# 컬럼별로 값 타입 확인\n",
    "list_cols = []\n",
    "dict_cols = []\n",
    "\n",
    "for c in DF.columns:\n",
    "    if DF[c].dtype == \"object\":  # object 타입만 검사\n",
    "        sample = DF[c].dropna().head(20)  # 결측 제외, 샘플 20개만 확인\n",
    "        if not sample.empty:\n",
    "            if sample.apply(lambda x: isinstance(x, list)).any():\n",
    "                list_cols.append(c)\n",
    "            elif sample.apply(lambda x: isinstance(x, dict)).any():\n",
    "                dict_cols.append(c)\n",
    "\n",
    "print(\"리스트 컬럼 개수:\", len(list_cols))\n",
    "print(\"\\n딕셔너리 컬럼 개수:\", len(dict_cols))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f3b67f",
   "metadata": {},
   "source": [
    "### 컬럼 프로파일링 & Drop/Keep/Review 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4a1b427c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\3262277817.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[요약] 전체: 398  Drop: 360  Review: 29  Keep: 9\n",
      "[drop] rows: 360\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column</th>\n",
       "      <th>dtype</th>\n",
       "      <th>nunique</th>\n",
       "      <th>null_ratio</th>\n",
       "      <th>top_freq_ratio</th>\n",
       "      <th>example</th>\n",
       "      <th>drop_reasons</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>date</td>\n",
       "      <td>object</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>constant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hour</td>\n",
       "      <td>datetime64[ns, UTC]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2024-01-01 10:00:00+00:00</td>\n",
       "      <td>constant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>f_payload.forkee.topics_n</td>\n",
       "      <td>int64</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>constant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>f_payload.forkee.topics_has_any</td>\n",
       "      <td>int64</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>constant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>payload.action</td>\n",
       "      <td>object</td>\n",
       "      <td>7</td>\n",
       "      <td>0.821527</td>\n",
       "      <td>0.051671</td>\n",
       "      <td>created</td>\n",
       "      <td>high_null=0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>payload.pull_request.base.repo.license</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>high_null=1.00;constant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>payload.comment.performed_via_github_app</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>high_null=1.00;constant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>payload.forkee.language</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>high_null=1.00;constant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>payload.forkee.license</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>high_null=1.00;constant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>payload.pull_request.milestone.closed_at</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>high_null=1.00;constant</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>360 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       column                dtype  nunique  \\\n",
       "0                                        date               object        1   \n",
       "1                                        hour  datetime64[ns, UTC]        1   \n",
       "2                   f_payload.forkee.topics_n                int64        1   \n",
       "3             f_payload.forkee.topics_has_any                int64        1   \n",
       "4                              payload.action               object        7   \n",
       "..                                        ...                  ...      ...   \n",
       "355    payload.pull_request.base.repo.license              float64        0   \n",
       "356  payload.comment.performed_via_github_app              float64        0   \n",
       "357                   payload.forkee.language              float64        0   \n",
       "358                    payload.forkee.license              float64        0   \n",
       "359  payload.pull_request.milestone.closed_at              float64        0   \n",
       "\n",
       "     null_ratio  top_freq_ratio                    example  \\\n",
       "0      0.000000        1.000000                 2024-01-01   \n",
       "1      0.000000        1.000000  2024-01-01 10:00:00+00:00   \n",
       "2      0.000000        1.000000                          0   \n",
       "3      0.000000        1.000000                          0   \n",
       "4      0.821527        0.051671                    created   \n",
       "..          ...             ...                        ...   \n",
       "355    1.000000        0.000000                        NaN   \n",
       "356    1.000000        0.000000                        NaN   \n",
       "357    1.000000        0.000000                        NaN   \n",
       "358    1.000000        0.000000                        NaN   \n",
       "359    1.000000        0.000000                        NaN   \n",
       "\n",
       "                drop_reasons  \n",
       "0                   constant  \n",
       "1                   constant  \n",
       "2                   constant  \n",
       "3                   constant  \n",
       "4             high_null=0.82  \n",
       "..                       ...  \n",
       "355  high_null=1.00;constant  \n",
       "356  high_null=1.00;constant  \n",
       "357  high_null=1.00;constant  \n",
       "358  high_null=1.00;constant  \n",
       "359  high_null=1.00;constant  \n",
       "\n",
       "[360 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[review] rows: 29\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column</th>\n",
       "      <th>dtype</th>\n",
       "      <th>nunique</th>\n",
       "      <th>null_ratio</th>\n",
       "      <th>top_freq_ratio</th>\n",
       "      <th>example</th>\n",
       "      <th>review_reasons</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f_commits_has_empty_msg</td>\n",
       "      <td>float64</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999191</td>\n",
       "      <td>0.0</td>\n",
       "      <td>near_constant=1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>f_issue_labels_has_bug</td>\n",
       "      <td>int64</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.997415</td>\n",
       "      <td>0</td>\n",
       "      <td>near_constant=1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>f_issue_labels_has_security</td>\n",
       "      <td>int64</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999823</td>\n",
       "      <td>0</td>\n",
       "      <td>near_constant=1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>f_pr_labels_has_bug</td>\n",
       "      <td>int64</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999659</td>\n",
       "      <td>0</td>\n",
       "      <td>near_constant=1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>f_pr_labels_has_security</td>\n",
       "      <td>int64</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999937</td>\n",
       "      <td>0</td>\n",
       "      <td>near_constant=1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>f_pages_has_edited</td>\n",
       "      <td>int64</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999305</td>\n",
       "      <td>0</td>\n",
       "      <td>near_constant=1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>f_release_mentions_has_auto</td>\n",
       "      <td>int64</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999937</td>\n",
       "      <td>0</td>\n",
       "      <td>near_constant=1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>f_app_events_has_issues</td>\n",
       "      <td>int64</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.985899</td>\n",
       "      <td>0</td>\n",
       "      <td>near_constant=0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>f_issue_labels_has_dependencies</td>\n",
       "      <td>int64</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.983402</td>\n",
       "      <td>0</td>\n",
       "      <td>near_constant=0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>f_app_events_has_pr</td>\n",
       "      <td>int64</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.979534</td>\n",
       "      <td>0</td>\n",
       "      <td>near_constant=0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>f_payload.pull_request.head.repo.topics_has_any</td>\n",
       "      <td>int64</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.969099</td>\n",
       "      <td>0</td>\n",
       "      <td>near_constant=0.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>f_payload.pull_request.base.repo.topics_has_any</td>\n",
       "      <td>int64</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.966128</td>\n",
       "      <td>0</td>\n",
       "      <td>near_constant=0.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>f_pr_labels_has_dependencies</td>\n",
       "      <td>int64</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.957248</td>\n",
       "      <td>0</td>\n",
       "      <td>near_constant=0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>f_release_assets_total_dl</td>\n",
       "      <td>int64</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>0</td>\n",
       "      <td>near_constant=1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>f_pages_n</td>\n",
       "      <td>int64</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999065</td>\n",
       "      <td>0</td>\n",
       "      <td>near_constant=1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>f_payload.pull_request.requested_teams_n</td>\n",
       "      <td>int64</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.998527</td>\n",
       "      <td>0</td>\n",
       "      <td>near_constant=1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>f_release_mentions_n</td>\n",
       "      <td>int64</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999779</td>\n",
       "      <td>0</td>\n",
       "      <td>near_constant=1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>f_payload.pull_request.assignees_n</td>\n",
       "      <td>int64</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.993648</td>\n",
       "      <td>0</td>\n",
       "      <td>near_constant=0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>f_payload.issue.assignees_n</td>\n",
       "      <td>int64</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.994014</td>\n",
       "      <td>0</td>\n",
       "      <td>near_constant=0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>f_pr_labels_n</td>\n",
       "      <td>int64</td>\n",
       "      <td>10</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.948032</td>\n",
       "      <td>0</td>\n",
       "      <td>near_constant=0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>f_release_assets_n</td>\n",
       "      <td>int64</td>\n",
       "      <td>11</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999368</td>\n",
       "      <td>0</td>\n",
       "      <td>near_constant=1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>f_issue_labels_n</td>\n",
       "      <td>int64</td>\n",
       "      <td>11</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.967778</td>\n",
       "      <td>0</td>\n",
       "      <td>near_constant=0.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>f_payload.pull_request.requested_reviewers_n</td>\n",
       "      <td>int64</td>\n",
       "      <td>13</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.993572</td>\n",
       "      <td>0</td>\n",
       "      <td>near_constant=0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>f_payload.pull_request.head.repo.topics_n</td>\n",
       "      <td>int64</td>\n",
       "      <td>21</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.969099</td>\n",
       "      <td>0</td>\n",
       "      <td>near_constant=0.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>f_payload.pull_request.base.repo.topics_n</td>\n",
       "      <td>int64</td>\n",
       "      <td>21</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.966128</td>\n",
       "      <td>0</td>\n",
       "      <td>near_constant=0.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>f_app_events_n</td>\n",
       "      <td>int64</td>\n",
       "      <td>22</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.979408</td>\n",
       "      <td>0</td>\n",
       "      <td>near_constant=0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>f_release_assets_total_size</td>\n",
       "      <td>int64</td>\n",
       "      <td>91</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999368</td>\n",
       "      <td>0</td>\n",
       "      <td>near_constant=1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>payload.head</td>\n",
       "      <td>object</td>\n",
       "      <td>104144</td>\n",
       "      <td>0.328327</td>\n",
       "      <td>0.000676</td>\n",
       "      <td>195646fd7c4df907171342c983e3ebdbbf1586ce</td>\n",
       "      <td>high_card_categorical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>payload.before</td>\n",
       "      <td>object</td>\n",
       "      <td>104155</td>\n",
       "      <td>0.328327</td>\n",
       "      <td>0.000695</td>\n",
       "      <td>2b0bfcedd702611ccf00a0d5a72b511d4881a7e8</td>\n",
       "      <td>high_card_categorical</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             column    dtype  nunique  \\\n",
       "0                           f_commits_has_empty_msg  float64        2   \n",
       "1                            f_issue_labels_has_bug    int64        2   \n",
       "2                       f_issue_labels_has_security    int64        2   \n",
       "3                               f_pr_labels_has_bug    int64        2   \n",
       "4                          f_pr_labels_has_security    int64        2   \n",
       "5                                f_pages_has_edited    int64        2   \n",
       "6                       f_release_mentions_has_auto    int64        2   \n",
       "7                           f_app_events_has_issues    int64        2   \n",
       "8                   f_issue_labels_has_dependencies    int64        2   \n",
       "9                               f_app_events_has_pr    int64        2   \n",
       "10  f_payload.pull_request.head.repo.topics_has_any    int64        2   \n",
       "11  f_payload.pull_request.base.repo.topics_has_any    int64        2   \n",
       "12                     f_pr_labels_has_dependencies    int64        2   \n",
       "13                        f_release_assets_total_dl    int64        3   \n",
       "14                                        f_pages_n    int64        4   \n",
       "15         f_payload.pull_request.requested_teams_n    int64        5   \n",
       "16                             f_release_mentions_n    int64        5   \n",
       "17               f_payload.pull_request.assignees_n    int64        5   \n",
       "18                      f_payload.issue.assignees_n    int64        6   \n",
       "19                                    f_pr_labels_n    int64       10   \n",
       "20                               f_release_assets_n    int64       11   \n",
       "21                                 f_issue_labels_n    int64       11   \n",
       "22     f_payload.pull_request.requested_reviewers_n    int64       13   \n",
       "23        f_payload.pull_request.head.repo.topics_n    int64       21   \n",
       "24        f_payload.pull_request.base.repo.topics_n    int64       21   \n",
       "25                                   f_app_events_n    int64       22   \n",
       "26                      f_release_assets_total_size    int64       91   \n",
       "27                                     payload.head   object   104144   \n",
       "28                                   payload.before   object   104155   \n",
       "\n",
       "    null_ratio  top_freq_ratio                                   example  \\\n",
       "0     0.000000        0.999191                                       0.0   \n",
       "1     0.000000        0.997415                                         0   \n",
       "2     0.000000        0.999823                                         0   \n",
       "3     0.000000        0.999659                                         0   \n",
       "4     0.000000        0.999937                                         0   \n",
       "5     0.000000        0.999305                                         0   \n",
       "6     0.000000        0.999937                                         0   \n",
       "7     0.000000        0.985899                                         0   \n",
       "8     0.000000        0.983402                                         0   \n",
       "9     0.000000        0.979534                                         0   \n",
       "10    0.000000        0.969099                                         0   \n",
       "11    0.000000        0.966128                                         0   \n",
       "12    0.000000        0.957248                                         0   \n",
       "13    0.000000        0.999987                                         0   \n",
       "14    0.000000        0.999065                                         0   \n",
       "15    0.000000        0.998527                                         0   \n",
       "16    0.000000        0.999779                                         0   \n",
       "17    0.000000        0.993648                                         0   \n",
       "18    0.000000        0.994014                                         0   \n",
       "19    0.000000        0.948032                                         0   \n",
       "20    0.000000        0.999368                                         0   \n",
       "21    0.000000        0.967778                                         0   \n",
       "22    0.000000        0.993572                                         0   \n",
       "23    0.000000        0.969099                                         0   \n",
       "24    0.000000        0.966128                                         0   \n",
       "25    0.000000        0.979408                                         0   \n",
       "26    0.000000        0.999368                                         0   \n",
       "27    0.328327        0.000676  195646fd7c4df907171342c983e3ebdbbf1586ce   \n",
       "28    0.328327        0.000695  2b0bfcedd702611ccf00a0d5a72b511d4881a7e8   \n",
       "\n",
       "           review_reasons  \n",
       "0      near_constant=1.00  \n",
       "1      near_constant=1.00  \n",
       "2      near_constant=1.00  \n",
       "3      near_constant=1.00  \n",
       "4      near_constant=1.00  \n",
       "5      near_constant=1.00  \n",
       "6      near_constant=1.00  \n",
       "7      near_constant=0.99  \n",
       "8      near_constant=0.98  \n",
       "9      near_constant=0.98  \n",
       "10     near_constant=0.97  \n",
       "11     near_constant=0.97  \n",
       "12     near_constant=0.96  \n",
       "13     near_constant=1.00  \n",
       "14     near_constant=1.00  \n",
       "15     near_constant=1.00  \n",
       "16     near_constant=1.00  \n",
       "17     near_constant=0.99  \n",
       "18     near_constant=0.99  \n",
       "19     near_constant=0.95  \n",
       "20     near_constant=1.00  \n",
       "21     near_constant=0.97  \n",
       "22     near_constant=0.99  \n",
       "23     near_constant=0.97  \n",
       "24     near_constant=0.97  \n",
       "25     near_constant=0.98  \n",
       "26     near_constant=1.00  \n",
       "27  high_card_categorical  \n",
       "28  high_card_categorical  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[keep] rows: 9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column</th>\n",
       "      <th>dtype</th>\n",
       "      <th>nunique</th>\n",
       "      <th>null_ratio</th>\n",
       "      <th>top_freq_ratio</th>\n",
       "      <th>example</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>type</td>\n",
       "      <td>object</td>\n",
       "      <td>15</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.671673</td>\n",
       "      <td>PushEvent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>f_commits_n</td>\n",
       "      <td>float64</td>\n",
       "      <td>21</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.623598</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>f_commits_n_distinct</td>\n",
       "      <td>float64</td>\n",
       "      <td>21</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.638471</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>f_commits_max_msg_len</td>\n",
       "      <td>float64</td>\n",
       "      <td>910</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.330281</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>f_commits_avg_msg_len</td>\n",
       "      <td>float64</td>\n",
       "      <td>2499</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.330281</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>created_at</td>\n",
       "      <td>datetime64[ns, UTC]</td>\n",
       "      <td>3600</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000442</td>\n",
       "      <td>2024-01-01 10:00:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>payload.ref</td>\n",
       "      <td>object</td>\n",
       "      <td>10686</td>\n",
       "      <td>0.222338</td>\n",
       "      <td>0.469232</td>\n",
       "      <td>refs/heads/main</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>payload.distinct_size</td>\n",
       "      <td>float64</td>\n",
       "      <td>155</td>\n",
       "      <td>0.328327</td>\n",
       "      <td>0.638913</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>payload.size</td>\n",
       "      <td>float64</td>\n",
       "      <td>186</td>\n",
       "      <td>0.328327</td>\n",
       "      <td>0.623598</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  column                dtype  nunique  null_ratio  \\\n",
       "0                   type               object       15    0.000000   \n",
       "1            f_commits_n              float64       21    0.000000   \n",
       "2   f_commits_n_distinct              float64       21    0.000000   \n",
       "3  f_commits_max_msg_len              float64      910    0.000000   \n",
       "4  f_commits_avg_msg_len              float64     2499    0.000000   \n",
       "5             created_at  datetime64[ns, UTC]     3600    0.000000   \n",
       "6            payload.ref               object    10686    0.222338   \n",
       "7  payload.distinct_size              float64      155    0.328327   \n",
       "8           payload.size              float64      186    0.328327   \n",
       "\n",
       "   top_freq_ratio                    example  \n",
       "0        0.671673                  PushEvent  \n",
       "1        0.623598                        1.0  \n",
       "2        0.638471                        1.0  \n",
       "3        0.330281                       12.0  \n",
       "4        0.330281                       12.0  \n",
       "5        0.000442  2024-01-01 10:00:00+00:00  \n",
       "6        0.469232            refs/heads/main  \n",
       "7        0.638913                        1.0  \n",
       "8        0.623598                        1.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import re                               \n",
    "import numpy as np                      \n",
    "import pandas as pd                    \n",
    "from pandas.api.types import (           # 안전한 dtype 판별 함수들(NumPy 대신 사용)\n",
    "    is_numeric_dtype,\n",
    "    is_datetime64_any_dtype,\n",
    "    is_string_dtype,\n",
    ")\n",
    "\n",
    "# ---------- 설정값 ----------\n",
    "NULL_THRESH_DROP   = 0.80                # 결측률 > 80% 이면 Drop\n",
    "NEAR_CONST_THRESH  = 0.80                # 최빈값 비율 ≥ 80% 이면 Review(거의 상수)\n",
    "HIGH_CARD_CAT_ABS  = 1000                # 범주형 고유값 절대 기준\n",
    "HIGH_CARD_CAT_FRAC = 0.50                # 범주형 고유값 상대 기준(행의 50%)\n",
    "\n",
    "ID_URL_PATTERNS = [                      # ID/URL/해시 등 식별자 컬럼명 패턴\n",
    "    r'(^|[._])id$', r'node_id', r'gravatar_id', r'avatar_url',\n",
    "    r'html_url', r'_url$', r'(^|[._])url$', r'(^|[._])sha$',\n",
    "    r'^git_url$', r'^ssh_url$', r'^clone_url$', r'^svn_url$'\n",
    "    , r'guid', r'uuid', r'hash', r'(?:^|[._])url$'\n",
    "]\n",
    "\n",
    "def looks_like_id_url(colname: str) -> bool:\n",
    "    name = colname.lower()               # 소문자 통일\n",
    "    return any(re.search(p, name) for p in ID_URL_PATTERNS)  # 하나라도 매칭되면 True\n",
    "\n",
    "def avg_str_len(s: pd.Series) -> float:\n",
    "    # 문자열 dtype(object/string)인 경우에만 평균 길이 계산\n",
    "    if s.dtype != \"object\" and not is_string_dtype(s):\n",
    "        return 0.0\n",
    "    vals = s.dropna().astype(str)        # 결측 제외 후 문자열 변환\n",
    "    return float(vals.str.len().mean()) if not vals.empty else 0.0\n",
    "\n",
    "def is_datetime_like(s: pd.Series) -> bool:\n",
    "    # dtype 자체가 datetime 계열이면 바로 True\n",
    "    if is_datetime64_any_dtype(s):\n",
    "        return True\n",
    "    # dtype이 object/string인데 날짜일 수도 있으니 샘플을 뽑아  datetime으로 파싱해보고 60% 이상 성공 시 날짜형으로 간주\n",
    "    sample = s.dropna().head(50)\n",
    "    if sample.empty:\n",
    "        return False\n",
    "    parsed = pd.to_datetime(sample.astype(str), errors=\"coerce\", utc=True)\n",
    "    return parsed.notna().mean() > 0.6\n",
    "\n",
    "# ---------- 프로파일링 ----------\n",
    "rows = []                                 # 컬럼별 요약을 담을 리스트\n",
    "n_rows = len(DF)                          # 전체 행 수\n",
    "\n",
    "for c in DF.columns:                      # 컬럼을 하나씩 순회\n",
    "    s = DF[c]                             # 해당 컬럼 시리즈\n",
    "    \n",
    "    # 결측치 비율\n",
    "    null_ratio     = float(s.isna().mean())                \n",
    "    high_null    = (null_ratio > NULL_THRESH_DROP)          # 결측 과다\n",
    "\n",
    "    nunique        = int(s.nunique(dropna=True))  # 고유값 개수(결측 제외)\n",
    "    is_constant  = (nunique <= 1)                           # 상수 컬럼\n",
    "\n",
    "    top_freq_ratio = float(s.value_counts(dropna=True).iloc[0] / n_rows) if (n_rows > 0 and nunique > 0) else 0.0 # 최빈값 비율(거의 상수)\n",
    "    near_constant = (top_freq_ratio >= NEAR_CONST_THRESH and not is_constant)  # 거의 상수(Review 대상)\n",
    "\n",
    "    \n",
    "    id_url_like  = looks_like_id_url(c)                     # ID/URL 패턴\n",
    "    \n",
    "    is_num    = is_numeric_dtype(s)      # 수치형 여부(판다스 함수)\n",
    "    is_dt     = is_datetime_like(s)      # 날짜형 여부(함수 위에서 정의)\n",
    "    high_card_cat = (not is_num and not is_dt and nunique >= max(HIGH_CARD_CAT_ABS, int(HIGH_CARD_CAT_FRAC * n_rows)))   # 범주형 고유값 과다(검토 대상)\n",
    "\n",
    "    # ---------- 처리   ----------\n",
    "    drop_reasons, review_reasons = [], []                  # 사유 누적\n",
    "\n",
    "    ### Drop\n",
    "    if high_null:    drop_reasons.append(f\"high_null={null_ratio:.2f}\")  # 결측 과다 → Drop\n",
    "    if is_constant:  drop_reasons.append(\"constant\")                 # 상수 → Drop\n",
    "    if id_url_like:  drop_reasons.append(\"id/url-like\")              # ID/URL → Drop\n",
    "\n",
    "    ### Review\n",
    "    if near_constant:  review_reasons.append(f\"near_constant={top_freq_ratio:.2f}\")  # 거의 상수 → Review\n",
    "    if high_card_cat:  review_reasons.append(\"high_card_categorical\")                   # 고카디널리티 → Review\n",
    "\n",
    "    # 한 컬럼에 대한 요약 정보 기록\n",
    "    dtype_str = str(s.dtype)             # dtype 문자열(기록용)\n",
    "    rows.append({\n",
    "        \"column\": c,\n",
    "        \"dtype\": dtype_str,\n",
    "        \"nunique\": nunique,\n",
    "        \"null_ratio\": round(null_ratio, 6),\n",
    "        \"top_freq_ratio\": round(top_freq_ratio, 6),\n",
    "        \"is_datetime\": is_dt,\n",
    "        \"is_numeric\": is_num,\n",
    "        \"drop_reasons\": \";\".join(drop_reasons),\n",
    "        \"review_reasons\": \";\".join(review_reasons),\n",
    "        \"example\": (s.dropna().iloc[0] if s.notna().any() else np.nan),  # 예시 값\n",
    "    })\n",
    "\n",
    "# ---------- summary DataFrame 생성 ----------\n",
    "summary = (\n",
    "    pd.DataFrame(rows)\n",
    "      .sort_values([\"drop_reasons\",\"review_reasons\",\"null_ratio\",\"nunique\"],\n",
    "                   ascending=[False, False, True, True])\n",
    "      .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# ---------- 분류 DataFrame 만들기 ----------\n",
    "df_drop   = summary.loc[summary.drop_reasons != \"\"].copy()                        # Drop 대상\n",
    "df_review = summary.loc[(summary.drop_reasons == \"\") & (summary.review_reasons != \"\")].copy()  # Review 대상\n",
    "df_keep   = summary.loc[(summary.drop_reasons == \"\") & (summary.review_reasons == \"\")].copy()  # Keep 대상\n",
    "\n",
    "print(\"\\n[요약] 전체:\", len(summary), \" Drop:\", len(df_drop), \" Review:\", len(df_review), \" Keep:\", len(df_keep))\n",
    "\n",
    "# 공통으로 볼 핵심 컬럼\n",
    "BASE_COLS = [\"column\", \"dtype\", \"nunique\", \"null_ratio\", \"top_freq_ratio\", \"example\"]\n",
    "\n",
    "# 그룹별 요약 DF\n",
    "df_drop_summary   = df_drop[BASE_COLS + [\"drop_reasons\"]]\\\n",
    "    .sort_values([\"null_ratio\",\"nunique\"], ascending=[True, True])\\\n",
    "    .reset_index(drop=True)\n",
    "\n",
    "df_review_summary = df_review[BASE_COLS + [\"review_reasons\"]]\\\n",
    "    .sort_values([\"null_ratio\",\"nunique\"], ascending=[True, True])\\\n",
    "    .reset_index(drop=True)\n",
    "\n",
    "df_keep_summary   = df_keep[BASE_COLS]\\\n",
    "    .sort_values([\"null_ratio\",\"nunique\"], ascending=[True, True])\\\n",
    "    .reset_index(drop=True)\n",
    "\n",
    "print(\"[drop] rows:\", len(df_drop_summary))\n",
    "display(df_drop_summary) #.head(15).to_string(index=False))\n",
    "\n",
    "print(\"[review] rows:\", len(df_review_summary))\n",
    "display(df_review_summary)\n",
    "\n",
    "print(\"[keep] rows:\", len(df_keep_summary))\n",
    "display(df_keep_summary)\n",
    "\n",
    "\n",
    "# ---------- Drop 목록 생성 & 적용 ----------\n",
    "drop_cols = df_drop[\"column\"].tolist()                   # 실제로 제거할 컬럼 목록\n",
    "DF_stage1 = DF.drop(columns=drop_cols, errors=\"ignore\")  # DF에서 드롭 적용\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "064bc81d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column</th>\n",
       "      <th>dtype</th>\n",
       "      <th>nunique</th>\n",
       "      <th>null_ratio</th>\n",
       "      <th>top_freq_ratio</th>\n",
       "      <th>is_datetime</th>\n",
       "      <th>is_numeric</th>\n",
       "      <th>drop_reasons</th>\n",
       "      <th>review_reasons</th>\n",
       "      <th>example</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>payload.release.author.site_admin</td>\n",
       "      <td>object</td>\n",
       "      <td>1</td>\n",
       "      <td>0.996777</td>\n",
       "      <td>0.003223</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>high_null=1.00;constant</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>payload.issue.milestone.creator.site_admin</td>\n",
       "      <td>object</td>\n",
       "      <td>1</td>\n",
       "      <td>0.998609</td>\n",
       "      <td>0.001391</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>high_null=1.00;constant</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>payload.member.type</td>\n",
       "      <td>object</td>\n",
       "      <td>1</td>\n",
       "      <td>0.998875</td>\n",
       "      <td>0.001125</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>high_null=1.00;constant</td>\n",
       "      <td></td>\n",
       "      <td>User</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>payload.member.site_admin</td>\n",
       "      <td>object</td>\n",
       "      <td>1</td>\n",
       "      <td>0.998875</td>\n",
       "      <td>0.001125</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>high_null=1.00;constant</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>payload.pull_request.milestone.creator.site_admin</td>\n",
       "      <td>object</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999197</td>\n",
       "      <td>0.000803</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>high_null=1.00;constant</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>f_commits_avg_msg_len</td>\n",
       "      <td>float64</td>\n",
       "      <td>2499</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.330281</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>created_at</td>\n",
       "      <td>datetime64[ns, UTC]</td>\n",
       "      <td>3600</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000442</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2024-01-01 10:00:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>payload.ref</td>\n",
       "      <td>object</td>\n",
       "      <td>10686</td>\n",
       "      <td>0.222338</td>\n",
       "      <td>0.469232</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>refs/heads/main</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>payload.distinct_size</td>\n",
       "      <td>float64</td>\n",
       "      <td>155</td>\n",
       "      <td>0.328327</td>\n",
       "      <td>0.638913</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>payload.size</td>\n",
       "      <td>float64</td>\n",
       "      <td>186</td>\n",
       "      <td>0.328327</td>\n",
       "      <td>0.623598</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>398 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                column                dtype  \\\n",
       "0                    payload.release.author.site_admin               object   \n",
       "1           payload.issue.milestone.creator.site_admin               object   \n",
       "2                                  payload.member.type               object   \n",
       "3                            payload.member.site_admin               object   \n",
       "4    payload.pull_request.milestone.creator.site_admin               object   \n",
       "..                                                 ...                  ...   \n",
       "393                              f_commits_avg_msg_len              float64   \n",
       "394                                         created_at  datetime64[ns, UTC]   \n",
       "395                                        payload.ref               object   \n",
       "396                              payload.distinct_size              float64   \n",
       "397                                       payload.size              float64   \n",
       "\n",
       "     nunique  null_ratio  top_freq_ratio  is_datetime  is_numeric  \\\n",
       "0          1    0.996777        0.003223        False       False   \n",
       "1          1    0.998609        0.001391        False       False   \n",
       "2          1    0.998875        0.001125        False       False   \n",
       "3          1    0.998875        0.001125        False       False   \n",
       "4          1    0.999197        0.000803        False       False   \n",
       "..       ...         ...             ...          ...         ...   \n",
       "393     2499    0.000000        0.330281        False        True   \n",
       "394     3600    0.000000        0.000442         True       False   \n",
       "395    10686    0.222338        0.469232        False       False   \n",
       "396      155    0.328327        0.638913        False        True   \n",
       "397      186    0.328327        0.623598        False        True   \n",
       "\n",
       "                drop_reasons review_reasons                    example  \n",
       "0    high_null=1.00;constant                                     False  \n",
       "1    high_null=1.00;constant                                     False  \n",
       "2    high_null=1.00;constant                                      User  \n",
       "3    high_null=1.00;constant                                     False  \n",
       "4    high_null=1.00;constant                                     False  \n",
       "..                       ...            ...                        ...  \n",
       "393                                                               12.0  \n",
       "394                                          2024-01-01 10:00:00+00:00  \n",
       "395                                                    refs/heads/main  \n",
       "396                                                                1.0  \n",
       "397                                                                1.0  \n",
       "\n",
       "[398 rows x 10 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3f29ca99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>created_at</th>\n",
       "      <th>payload.size</th>\n",
       "      <th>payload.distinct_size</th>\n",
       "      <th>payload.ref</th>\n",
       "      <th>payload.head</th>\n",
       "      <th>payload.before</th>\n",
       "      <th>f_commits_n</th>\n",
       "      <th>f_commits_n_distinct</th>\n",
       "      <th>f_commits_avg_msg_len</th>\n",
       "      <th>...</th>\n",
       "      <th>f_release_assets_n</th>\n",
       "      <th>f_release_assets_total_size</th>\n",
       "      <th>f_release_assets_total_dl</th>\n",
       "      <th>f_pages_n</th>\n",
       "      <th>f_pages_has_edited</th>\n",
       "      <th>f_release_mentions_n</th>\n",
       "      <th>f_release_mentions_has_auto</th>\n",
       "      <th>f_app_events_n</th>\n",
       "      <th>f_app_events_has_pr</th>\n",
       "      <th>f_app_events_has_issues</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PushEvent</td>\n",
       "      <td>2024-01-01 10:00:00+00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>refs/heads/main</td>\n",
       "      <td>195646fd7c4df907171342c983e3ebdbbf1586ce</td>\n",
       "      <td>2b0bfcedd702611ccf00a0d5a72b511d4881a7e8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PushEvent</td>\n",
       "      <td>2024-01-01 10:00:00+00:00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>refs/heads/main</td>\n",
       "      <td>3eec155a81a9e0e115c9f6be58e8370efe1244b1</td>\n",
       "      <td>e9db10ee221a19b7a15e7f24175d204124147769</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>27.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PushEvent</td>\n",
       "      <td>2024-01-01 10:00:00+00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>refs/heads/master</td>\n",
       "      <td>36b3bb6975019e7b298ee049335711926da15a80</td>\n",
       "      <td>0d8c9fea95752e3537507c101799e3eb6019ca85</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PushEvent</td>\n",
       "      <td>2024-01-01 10:00:00+00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>refs/heads/main</td>\n",
       "      <td>09dbaa7c85c16fcbf863f83185cf1689e0b12ff9</td>\n",
       "      <td>2684d35b84596a34923ee2066d04b05902f6f1a2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PushEvent</td>\n",
       "      <td>2024-01-01 10:00:00+00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>refs/heads/main</td>\n",
       "      <td>166c6d2a6043ee0d86299919563bed9d8754f1ea</td>\n",
       "      <td>cbda25658e493bdfddc1c9223af50b75dac6f64c</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158209</th>\n",
       "      <td>IssueCommentEvent</td>\n",
       "      <td>2024-01-01 10:59:59+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158210</th>\n",
       "      <td>PushEvent</td>\n",
       "      <td>2024-01-01 10:59:59+00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>refs/heads/master</td>\n",
       "      <td>7f9568cf5da5981870f0c514f242e8bb69749118</td>\n",
       "      <td>2b4909198f5c9a242722f3c856e83c783f215e88</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158211</th>\n",
       "      <td>PushEvent</td>\n",
       "      <td>2024-01-01 10:59:59+00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>refs/heads/main</td>\n",
       "      <td>cb9633ba593f30501bf23a2bf09d5232b6b04f1f</td>\n",
       "      <td>22731a2dd7cfbe629a207c984ae0d3f322178b8e</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158212</th>\n",
       "      <td>PushEvent</td>\n",
       "      <td>2024-01-01 10:59:59+00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>refs/heads/main</td>\n",
       "      <td>c127779c93fdd326d0ab33f795318205fcc3dcbb</td>\n",
       "      <td>7d685e32ef2191e52075fe819394b568763830cd</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158213</th>\n",
       "      <td>PushEvent</td>\n",
       "      <td>2024-01-01 10:59:59+00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>refs/heads/master</td>\n",
       "      <td>c45892b70c5bc614a890d25ae088657e8946ecf7</td>\n",
       "      <td>74d1445dc6153a99ad8ef714f8073ac099c64eef</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>158214 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     type                created_at  payload.size  \\\n",
       "0               PushEvent 2024-01-01 10:00:00+00:00           1.0   \n",
       "1               PushEvent 2024-01-01 10:00:00+00:00           2.0   \n",
       "2               PushEvent 2024-01-01 10:00:00+00:00           1.0   \n",
       "3               PushEvent 2024-01-01 10:00:00+00:00           1.0   \n",
       "4               PushEvent 2024-01-01 10:00:00+00:00           1.0   \n",
       "...                   ...                       ...           ...   \n",
       "158209  IssueCommentEvent 2024-01-01 10:59:59+00:00           NaN   \n",
       "158210          PushEvent 2024-01-01 10:59:59+00:00           1.0   \n",
       "158211          PushEvent 2024-01-01 10:59:59+00:00           1.0   \n",
       "158212          PushEvent 2024-01-01 10:59:59+00:00           1.0   \n",
       "158213          PushEvent 2024-01-01 10:59:59+00:00           1.0   \n",
       "\n",
       "        payload.distinct_size        payload.ref  \\\n",
       "0                         1.0    refs/heads/main   \n",
       "1                         2.0    refs/heads/main   \n",
       "2                         1.0  refs/heads/master   \n",
       "3                         1.0    refs/heads/main   \n",
       "4                         1.0    refs/heads/main   \n",
       "...                       ...                ...   \n",
       "158209                    NaN                NaN   \n",
       "158210                    1.0  refs/heads/master   \n",
       "158211                    1.0    refs/heads/main   \n",
       "158212                    1.0    refs/heads/main   \n",
       "158213                    1.0  refs/heads/master   \n",
       "\n",
       "                                    payload.head  \\\n",
       "0       195646fd7c4df907171342c983e3ebdbbf1586ce   \n",
       "1       3eec155a81a9e0e115c9f6be58e8370efe1244b1   \n",
       "2       36b3bb6975019e7b298ee049335711926da15a80   \n",
       "3       09dbaa7c85c16fcbf863f83185cf1689e0b12ff9   \n",
       "4       166c6d2a6043ee0d86299919563bed9d8754f1ea   \n",
       "...                                          ...   \n",
       "158209                                       NaN   \n",
       "158210  7f9568cf5da5981870f0c514f242e8bb69749118   \n",
       "158211  cb9633ba593f30501bf23a2bf09d5232b6b04f1f   \n",
       "158212  c127779c93fdd326d0ab33f795318205fcc3dcbb   \n",
       "158213  c45892b70c5bc614a890d25ae088657e8946ecf7   \n",
       "\n",
       "                                  payload.before  f_commits_n  \\\n",
       "0       2b0bfcedd702611ccf00a0d5a72b511d4881a7e8          1.0   \n",
       "1       e9db10ee221a19b7a15e7f24175d204124147769          2.0   \n",
       "2       0d8c9fea95752e3537507c101799e3eb6019ca85          1.0   \n",
       "3       2684d35b84596a34923ee2066d04b05902f6f1a2          1.0   \n",
       "4       cbda25658e493bdfddc1c9223af50b75dac6f64c          1.0   \n",
       "...                                          ...          ...   \n",
       "158209                                       NaN          0.0   \n",
       "158210  2b4909198f5c9a242722f3c856e83c783f215e88          1.0   \n",
       "158211  22731a2dd7cfbe629a207c984ae0d3f322178b8e          1.0   \n",
       "158212  7d685e32ef2191e52075fe819394b568763830cd          1.0   \n",
       "158213  74d1445dc6153a99ad8ef714f8073ac099c64eef          1.0   \n",
       "\n",
       "        f_commits_n_distinct  f_commits_avg_msg_len  ...  f_release_assets_n  \\\n",
       "0                        1.0                   12.0  ...                   0   \n",
       "1                        2.0                   27.5  ...                   0   \n",
       "2                        1.0                   23.0  ...                   0   \n",
       "3                        1.0                   12.0  ...                   0   \n",
       "4                        1.0                   12.0  ...                   0   \n",
       "...                      ...                    ...  ...                 ...   \n",
       "158209                   0.0                    0.0  ...                   0   \n",
       "158210                   1.0                   56.0  ...                   0   \n",
       "158211                   1.0                   14.0  ...                   0   \n",
       "158212                   1.0                   11.0  ...                   0   \n",
       "158213                   1.0                    8.0  ...                   0   \n",
       "\n",
       "        f_release_assets_total_size  f_release_assets_total_dl  f_pages_n  \\\n",
       "0                                 0                          0          0   \n",
       "1                                 0                          0          0   \n",
       "2                                 0                          0          0   \n",
       "3                                 0                          0          0   \n",
       "4                                 0                          0          0   \n",
       "...                             ...                        ...        ...   \n",
       "158209                            0                          0          0   \n",
       "158210                            0                          0          0   \n",
       "158211                            0                          0          0   \n",
       "158212                            0                          0          0   \n",
       "158213                            0                          0          0   \n",
       "\n",
       "        f_pages_has_edited  f_release_mentions_n  f_release_mentions_has_auto  \\\n",
       "0                        0                     0                            0   \n",
       "1                        0                     0                            0   \n",
       "2                        0                     0                            0   \n",
       "3                        0                     0                            0   \n",
       "4                        0                     0                            0   \n",
       "...                    ...                   ...                          ...   \n",
       "158209                   0                     0                            0   \n",
       "158210                   0                     0                            0   \n",
       "158211                   0                     0                            0   \n",
       "158212                   0                     0                            0   \n",
       "158213                   0                     0                            0   \n",
       "\n",
       "        f_app_events_n  f_app_events_has_pr  f_app_events_has_issues  \n",
       "0                    0                    0                        0  \n",
       "1                    0                    0                        0  \n",
       "2                    0                    0                        0  \n",
       "3                    0                    0                        0  \n",
       "4                    0                    0                        0  \n",
       "...                ...                  ...                      ...  \n",
       "158209               8                    1                        1  \n",
       "158210               0                    0                        0  \n",
       "158211               0                    0                        0  \n",
       "158212               0                    0                        0  \n",
       "158213               0                    0                        0  \n",
       "\n",
       "[158214 rows x 38 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF_stage1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ecb9ea7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['f_commits_has_empty_msg', 'f_issue_labels_has_bug',\n",
       "       'f_issue_labels_has_security', 'f_pr_labels_has_bug',\n",
       "       'f_pr_labels_has_security', 'f_pages_has_edited',\n",
       "       'f_release_mentions_has_auto', 'f_app_events_has_issues',\n",
       "       'f_issue_labels_has_dependencies', 'f_app_events_has_pr',\n",
       "       'f_payload.pull_request.head.repo.topics_has_any',\n",
       "       'f_payload.pull_request.base.repo.topics_has_any',\n",
       "       'f_pr_labels_has_dependencies', 'f_release_assets_total_dl',\n",
       "       'f_pages_n', 'f_payload.pull_request.requested_teams_n',\n",
       "       'f_release_mentions_n', 'f_payload.pull_request.assignees_n',\n",
       "       'f_payload.issue.assignees_n', 'f_pr_labels_n',\n",
       "       'f_release_assets_n', 'f_issue_labels_n',\n",
       "       'f_payload.pull_request.requested_reviewers_n',\n",
       "       'f_payload.pull_request.head.repo.topics_n',\n",
       "       'f_payload.pull_request.base.repo.topics_n', 'f_app_events_n',\n",
       "       'f_release_assets_total_size', 'payload.head', 'payload.before'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_review_summary[\"column\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c38d01e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 버릴 컬럼 리스트\n",
    "drop_cols = ['f_commits_has_empty_msg', \n",
    "            'f_issue_labels_has_bug',\n",
    "            'f_issue_labels_has_security', \n",
    "            'f_pr_labels_has_bug',\n",
    "            'f_pr_labels_has_security',\n",
    "            'f_pages_has_edited',\n",
    "            'f_release_mentions_has_auto', \n",
    "            'f_app_events_has_issues',\n",
    "            'f_issue_labels_has_dependencies', \n",
    "            'f_app_events_has_pr',\n",
    "            'f_payload.pull_request.head.repo.topics_has_any',\n",
    "            'f_payload.pull_request.base.repo.topics_has_any',\n",
    "            'f_pr_labels_has_dependencies', \n",
    "            'f_release_assets_total_dl',\n",
    "            # 'f_pages_n', \n",
    "            'f_payload.pull_request.requested_teams_n',\n",
    "            # 'f_release_mentions_n', \n",
    "            # 'f_payload.pull_request.assignees_n',\n",
    "            # 'f_payload.issue.assignees_n', \n",
    "            # 'f_pr_labels_n',\n",
    "            # 'f_release_assets_n', \n",
    "            # 'f_issue_labels_n',\n",
    "            # 'f_payload.pull_request.requested_reviewers_n',\n",
    "            # 'f_payload.pull_request.head.repo.topics_n',\n",
    "            # 'f_payload.pull_request.base.repo.topics_n',\n",
    "            # 'f_app_events_n',\n",
    "            # 'f_release_assets_total_size', \n",
    "            'payload.head', \n",
    "            'payload.before']\n",
    "\n",
    "# 설명) 주석처리 한 애들 중 비록 0이 많아도, 특정 상황에서 값이 커지면 이상행동 신호일 수 있으니 일단 남김."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3f9e1898",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column</th>\n",
       "      <th>dtype</th>\n",
       "      <th>nunique</th>\n",
       "      <th>null_ratio</th>\n",
       "      <th>top_freq_ratio</th>\n",
       "      <th>is_datetime</th>\n",
       "      <th>is_numeric</th>\n",
       "      <th>drop_reasons</th>\n",
       "      <th>review_reasons</th>\n",
       "      <th>example</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>payload.head</td>\n",
       "      <td>object</td>\n",
       "      <td>104144</td>\n",
       "      <td>0.328327</td>\n",
       "      <td>0.000676</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td>high_card_categorical</td>\n",
       "      <td>195646fd7c4df907171342c983e3ebdbbf1586ce</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>payload.before</td>\n",
       "      <td>object</td>\n",
       "      <td>104155</td>\n",
       "      <td>0.328327</td>\n",
       "      <td>0.000695</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td>high_card_categorical</td>\n",
       "      <td>2b0bfcedd702611ccf00a0d5a72b511d4881a7e8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             column   dtype  nunique  null_ratio  top_freq_ratio  is_datetime  \\\n",
       "387    payload.head  object   104144    0.328327        0.000676        False   \n",
       "388  payload.before  object   104155    0.328327        0.000695        False   \n",
       "\n",
       "     is_numeric drop_reasons         review_reasons  \\\n",
       "387       False               high_card_categorical   \n",
       "388       False               high_card_categorical   \n",
       "\n",
       "                                      example  \n",
       "387  195646fd7c4df907171342c983e3ebdbbf1586ce  \n",
       "388  2b0bfcedd702611ccf00a0d5a72b511d4881a7e8  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hcc = df_review[df_review[\"review_reasons\"].str.contains(\"high_card_categorical\", na=False)].copy()\n",
    "df_hcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f3f7255a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 컬럼 삭제\n",
    "df_clean = DF_stage1.drop(columns=drop_cols, errors=\"ignore\")\n",
    "\n",
    "# 중간 저장 (Parquet 추천: 용량↓, 속도↑)\n",
    "df_clean.to_csv(\"cleaned_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e5d6b5",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d76b920f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"cleaned_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "8aaac43c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>created_at</th>\n",
       "      <th>payload.size</th>\n",
       "      <th>payload.distinct_size</th>\n",
       "      <th>payload.ref</th>\n",
       "      <th>f_commits_n</th>\n",
       "      <th>f_commits_n_distinct</th>\n",
       "      <th>f_commits_avg_msg_len</th>\n",
       "      <th>f_commits_max_msg_len</th>\n",
       "      <th>f_issue_labels_n</th>\n",
       "      <th>...</th>\n",
       "      <th>f_payload.issue.assignees_n</th>\n",
       "      <th>f_payload.pull_request.assignees_n</th>\n",
       "      <th>f_payload.pull_request.requested_reviewers_n</th>\n",
       "      <th>f_payload.pull_request.head.repo.topics_n</th>\n",
       "      <th>f_payload.pull_request.base.repo.topics_n</th>\n",
       "      <th>f_release_assets_n</th>\n",
       "      <th>f_release_assets_total_size</th>\n",
       "      <th>f_pages_n</th>\n",
       "      <th>f_release_mentions_n</th>\n",
       "      <th>f_app_events_n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PushEvent</td>\n",
       "      <td>2024-01-01 10:00:00+00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>refs/heads/main</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PushEvent</td>\n",
       "      <td>2024-01-01 10:00:00+00:00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>refs/heads/main</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>27.5</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PushEvent</td>\n",
       "      <td>2024-01-01 10:00:00+00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>refs/heads/master</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PushEvent</td>\n",
       "      <td>2024-01-01 10:00:00+00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>refs/heads/main</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PushEvent</td>\n",
       "      <td>2024-01-01 10:00:00+00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>refs/heads/main</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158209</th>\n",
       "      <td>IssueCommentEvent</td>\n",
       "      <td>2024-01-01 10:59:59+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158210</th>\n",
       "      <td>PushEvent</td>\n",
       "      <td>2024-01-01 10:59:59+00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>refs/heads/master</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158211</th>\n",
       "      <td>PushEvent</td>\n",
       "      <td>2024-01-01 10:59:59+00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>refs/heads/main</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158212</th>\n",
       "      <td>PushEvent</td>\n",
       "      <td>2024-01-01 10:59:59+00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>refs/heads/main</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158213</th>\n",
       "      <td>PushEvent</td>\n",
       "      <td>2024-01-01 10:59:59+00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>refs/heads/master</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>158214 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     type                 created_at  payload.size  \\\n",
       "0               PushEvent  2024-01-01 10:00:00+00:00           1.0   \n",
       "1               PushEvent  2024-01-01 10:00:00+00:00           2.0   \n",
       "2               PushEvent  2024-01-01 10:00:00+00:00           1.0   \n",
       "3               PushEvent  2024-01-01 10:00:00+00:00           1.0   \n",
       "4               PushEvent  2024-01-01 10:00:00+00:00           1.0   \n",
       "...                   ...                        ...           ...   \n",
       "158209  IssueCommentEvent  2024-01-01 10:59:59+00:00           NaN   \n",
       "158210          PushEvent  2024-01-01 10:59:59+00:00           1.0   \n",
       "158211          PushEvent  2024-01-01 10:59:59+00:00           1.0   \n",
       "158212          PushEvent  2024-01-01 10:59:59+00:00           1.0   \n",
       "158213          PushEvent  2024-01-01 10:59:59+00:00           1.0   \n",
       "\n",
       "        payload.distinct_size        payload.ref  f_commits_n  \\\n",
       "0                         1.0    refs/heads/main          1.0   \n",
       "1                         2.0    refs/heads/main          2.0   \n",
       "2                         1.0  refs/heads/master          1.0   \n",
       "3                         1.0    refs/heads/main          1.0   \n",
       "4                         1.0    refs/heads/main          1.0   \n",
       "...                       ...                ...          ...   \n",
       "158209                    NaN                NaN          0.0   \n",
       "158210                    1.0  refs/heads/master          1.0   \n",
       "158211                    1.0    refs/heads/main          1.0   \n",
       "158212                    1.0    refs/heads/main          1.0   \n",
       "158213                    1.0  refs/heads/master          1.0   \n",
       "\n",
       "        f_commits_n_distinct  f_commits_avg_msg_len  f_commits_max_msg_len  \\\n",
       "0                        1.0                   12.0                   12.0   \n",
       "1                        2.0                   27.5                   45.0   \n",
       "2                        1.0                   23.0                   23.0   \n",
       "3                        1.0                   12.0                   12.0   \n",
       "4                        1.0                   12.0                   12.0   \n",
       "...                      ...                    ...                    ...   \n",
       "158209                   0.0                    0.0                    0.0   \n",
       "158210                   1.0                   56.0                   56.0   \n",
       "158211                   1.0                   14.0                   14.0   \n",
       "158212                   1.0                   11.0                   11.0   \n",
       "158213                   1.0                    8.0                    8.0   \n",
       "\n",
       "        f_issue_labels_n  ...  f_payload.issue.assignees_n  \\\n",
       "0                      0  ...                            0   \n",
       "1                      0  ...                            0   \n",
       "2                      0  ...                            0   \n",
       "3                      0  ...                            0   \n",
       "4                      0  ...                            0   \n",
       "...                  ...  ...                          ...   \n",
       "158209                 1  ...                            0   \n",
       "158210                 0  ...                            0   \n",
       "158211                 0  ...                            0   \n",
       "158212                 0  ...                            0   \n",
       "158213                 0  ...                            0   \n",
       "\n",
       "        f_payload.pull_request.assignees_n  \\\n",
       "0                                        0   \n",
       "1                                        0   \n",
       "2                                        0   \n",
       "3                                        0   \n",
       "4                                        0   \n",
       "...                                    ...   \n",
       "158209                                   0   \n",
       "158210                                   0   \n",
       "158211                                   0   \n",
       "158212                                   0   \n",
       "158213                                   0   \n",
       "\n",
       "        f_payload.pull_request.requested_reviewers_n  \\\n",
       "0                                                  0   \n",
       "1                                                  0   \n",
       "2                                                  0   \n",
       "3                                                  0   \n",
       "4                                                  0   \n",
       "...                                              ...   \n",
       "158209                                             0   \n",
       "158210                                             0   \n",
       "158211                                             0   \n",
       "158212                                             0   \n",
       "158213                                             0   \n",
       "\n",
       "        f_payload.pull_request.head.repo.topics_n  \\\n",
       "0                                               0   \n",
       "1                                               0   \n",
       "2                                               0   \n",
       "3                                               0   \n",
       "4                                               0   \n",
       "...                                           ...   \n",
       "158209                                          0   \n",
       "158210                                          0   \n",
       "158211                                          0   \n",
       "158212                                          0   \n",
       "158213                                          0   \n",
       "\n",
       "        f_payload.pull_request.base.repo.topics_n  f_release_assets_n  \\\n",
       "0                                               0                   0   \n",
       "1                                               0                   0   \n",
       "2                                               0                   0   \n",
       "3                                               0                   0   \n",
       "4                                               0                   0   \n",
       "...                                           ...                 ...   \n",
       "158209                                          0                   0   \n",
       "158210                                          0                   0   \n",
       "158211                                          0                   0   \n",
       "158212                                          0                   0   \n",
       "158213                                          0                   0   \n",
       "\n",
       "        f_release_assets_total_size  f_pages_n  f_release_mentions_n  \\\n",
       "0                                 0          0                     0   \n",
       "1                                 0          0                     0   \n",
       "2                                 0          0                     0   \n",
       "3                                 0          0                     0   \n",
       "4                                 0          0                     0   \n",
       "...                             ...        ...                   ...   \n",
       "158209                            0          0                     0   \n",
       "158210                            0          0                     0   \n",
       "158211                            0          0                     0   \n",
       "158212                            0          0                     0   \n",
       "158213                            0          0                     0   \n",
       "\n",
       "        f_app_events_n  \n",
       "0                    0  \n",
       "1                    0  \n",
       "2                    0  \n",
       "3                    0  \n",
       "4                    0  \n",
       "...                ...  \n",
       "158209               8  \n",
       "158210               0  \n",
       "158211               0  \n",
       "158212               0  \n",
       "158213               0  \n",
       "\n",
       "[158214 rows x 21 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "9973d4b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type                                                0\n",
      "created_at                                          0\n",
      "payload.size                                    51946\n",
      "payload.distinct_size                           51946\n",
      "payload.ref                                     35177\n",
      "f_commits_n                                         0\n",
      "f_commits_n_distinct                                0\n",
      "f_commits_avg_msg_len                               0\n",
      "f_commits_max_msg_len                               0\n",
      "f_issue_labels_n                                    0\n",
      "f_pr_labels_n                                       0\n",
      "f_payload.issue.assignees_n                         0\n",
      "f_payload.pull_request.assignees_n                  0\n",
      "f_payload.pull_request.requested_reviewers_n        0\n",
      "f_payload.pull_request.head.repo.topics_n           0\n",
      "f_payload.pull_request.base.repo.topics_n           0\n",
      "f_release_assets_n                                  0\n",
      "f_release_assets_total_size                         0\n",
      "f_pages_n                                           0\n",
      "f_release_mentions_n                                0\n",
      "f_app_events_n                                      0\n",
      "dtype: int64\n",
      "남은 숫자 결측 합: 0\n",
      "남은 텍스트 결측 합: 0\n"
     ]
    }
   ],
   "source": [
    "### 결측치 처리\n",
    "\n",
    "# 1) 결측 표준화: 문자열 결측 토큰을 모두 np.nan 으로 통일\n",
    "MISSING_TOKENS = [\"\", \" \", \"NA\", \"N/A\", \"NaN\", \"nan\", \"NULL\", \"null\", None]\n",
    "df = df.replace(MISSING_TOKENS, np.nan)\n",
    "print(df.isna().sum())\n",
    "\n",
    "# 2) dtype 정리\n",
    "num_cols = df.select_dtypes(include=[\"number\"]).columns\n",
    "txt_cols = df.select_dtypes(include=[\"object\", \"string\"]).columns\n",
    "\n",
    "# 3) 결측치 채우기\n",
    "df[num_cols] = df[num_cols].fillna(df[num_cols].median())        # 숫자 -> 중앙값\n",
    "df[txt_cols] = df[txt_cols].astype(\"string\").fillna(\"missing\")   # 텍스트/범주 -> \"missing\"\n",
    "\n",
    "# 4) 적용 확인 (NaN 남아있는지 체크)\n",
    "print(\"남은 숫자 결측 합:\", int(df[num_cols].isna().sum().sum()))\n",
    "print(\"남은 텍스트 결측 합:\", int(df[txt_cols].isna().sum().sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b9ca4d84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>created_at</th>\n",
       "      <th>payload.size</th>\n",
       "      <th>payload.distinct_size</th>\n",
       "      <th>payload.ref</th>\n",
       "      <th>f_commits_n</th>\n",
       "      <th>f_commits_n_distinct</th>\n",
       "      <th>f_commits_avg_msg_len</th>\n",
       "      <th>f_commits_max_msg_len</th>\n",
       "      <th>f_issue_labels_n</th>\n",
       "      <th>...</th>\n",
       "      <th>f_payload.issue.assignees_n</th>\n",
       "      <th>f_payload.pull_request.assignees_n</th>\n",
       "      <th>f_payload.pull_request.requested_reviewers_n</th>\n",
       "      <th>f_payload.pull_request.head.repo.topics_n</th>\n",
       "      <th>f_payload.pull_request.base.repo.topics_n</th>\n",
       "      <th>f_release_assets_n</th>\n",
       "      <th>f_release_assets_total_size</th>\n",
       "      <th>f_pages_n</th>\n",
       "      <th>f_release_mentions_n</th>\n",
       "      <th>f_app_events_n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PushEvent</td>\n",
       "      <td>2024-01-01 10:00:00+00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>refs/heads/main</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PushEvent</td>\n",
       "      <td>2024-01-01 10:00:00+00:00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>refs/heads/main</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>27.5</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PushEvent</td>\n",
       "      <td>2024-01-01 10:00:00+00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>refs/heads/master</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PushEvent</td>\n",
       "      <td>2024-01-01 10:00:00+00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>refs/heads/main</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PushEvent</td>\n",
       "      <td>2024-01-01 10:00:00+00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>refs/heads/main</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158209</th>\n",
       "      <td>IssueCommentEvent</td>\n",
       "      <td>2024-01-01 10:59:59+00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>missing</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158210</th>\n",
       "      <td>PushEvent</td>\n",
       "      <td>2024-01-01 10:59:59+00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>refs/heads/master</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158211</th>\n",
       "      <td>PushEvent</td>\n",
       "      <td>2024-01-01 10:59:59+00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>refs/heads/main</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158212</th>\n",
       "      <td>PushEvent</td>\n",
       "      <td>2024-01-01 10:59:59+00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>refs/heads/main</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158213</th>\n",
       "      <td>PushEvent</td>\n",
       "      <td>2024-01-01 10:59:59+00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>refs/heads/master</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>158214 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     type                 created_at  payload.size  \\\n",
       "0               PushEvent  2024-01-01 10:00:00+00:00           1.0   \n",
       "1               PushEvent  2024-01-01 10:00:00+00:00           2.0   \n",
       "2               PushEvent  2024-01-01 10:00:00+00:00           1.0   \n",
       "3               PushEvent  2024-01-01 10:00:00+00:00           1.0   \n",
       "4               PushEvent  2024-01-01 10:00:00+00:00           1.0   \n",
       "...                   ...                        ...           ...   \n",
       "158209  IssueCommentEvent  2024-01-01 10:59:59+00:00           1.0   \n",
       "158210          PushEvent  2024-01-01 10:59:59+00:00           1.0   \n",
       "158211          PushEvent  2024-01-01 10:59:59+00:00           1.0   \n",
       "158212          PushEvent  2024-01-01 10:59:59+00:00           1.0   \n",
       "158213          PushEvent  2024-01-01 10:59:59+00:00           1.0   \n",
       "\n",
       "        payload.distinct_size        payload.ref  f_commits_n  \\\n",
       "0                         1.0    refs/heads/main          1.0   \n",
       "1                         2.0    refs/heads/main          2.0   \n",
       "2                         1.0  refs/heads/master          1.0   \n",
       "3                         1.0    refs/heads/main          1.0   \n",
       "4                         1.0    refs/heads/main          1.0   \n",
       "...                       ...                ...          ...   \n",
       "158209                    1.0            missing          0.0   \n",
       "158210                    1.0  refs/heads/master          1.0   \n",
       "158211                    1.0    refs/heads/main          1.0   \n",
       "158212                    1.0    refs/heads/main          1.0   \n",
       "158213                    1.0  refs/heads/master          1.0   \n",
       "\n",
       "        f_commits_n_distinct  f_commits_avg_msg_len  f_commits_max_msg_len  \\\n",
       "0                        1.0                   12.0                   12.0   \n",
       "1                        2.0                   27.5                   45.0   \n",
       "2                        1.0                   23.0                   23.0   \n",
       "3                        1.0                   12.0                   12.0   \n",
       "4                        1.0                   12.0                   12.0   \n",
       "...                      ...                    ...                    ...   \n",
       "158209                   0.0                    0.0                    0.0   \n",
       "158210                   1.0                   56.0                   56.0   \n",
       "158211                   1.0                   14.0                   14.0   \n",
       "158212                   1.0                   11.0                   11.0   \n",
       "158213                   1.0                    8.0                    8.0   \n",
       "\n",
       "        f_issue_labels_n  ...  f_payload.issue.assignees_n  \\\n",
       "0                      0  ...                            0   \n",
       "1                      0  ...                            0   \n",
       "2                      0  ...                            0   \n",
       "3                      0  ...                            0   \n",
       "4                      0  ...                            0   \n",
       "...                  ...  ...                          ...   \n",
       "158209                 1  ...                            0   \n",
       "158210                 0  ...                            0   \n",
       "158211                 0  ...                            0   \n",
       "158212                 0  ...                            0   \n",
       "158213                 0  ...                            0   \n",
       "\n",
       "        f_payload.pull_request.assignees_n  \\\n",
       "0                                        0   \n",
       "1                                        0   \n",
       "2                                        0   \n",
       "3                                        0   \n",
       "4                                        0   \n",
       "...                                    ...   \n",
       "158209                                   0   \n",
       "158210                                   0   \n",
       "158211                                   0   \n",
       "158212                                   0   \n",
       "158213                                   0   \n",
       "\n",
       "        f_payload.pull_request.requested_reviewers_n  \\\n",
       "0                                                  0   \n",
       "1                                                  0   \n",
       "2                                                  0   \n",
       "3                                                  0   \n",
       "4                                                  0   \n",
       "...                                              ...   \n",
       "158209                                             0   \n",
       "158210                                             0   \n",
       "158211                                             0   \n",
       "158212                                             0   \n",
       "158213                                             0   \n",
       "\n",
       "        f_payload.pull_request.head.repo.topics_n  \\\n",
       "0                                               0   \n",
       "1                                               0   \n",
       "2                                               0   \n",
       "3                                               0   \n",
       "4                                               0   \n",
       "...                                           ...   \n",
       "158209                                          0   \n",
       "158210                                          0   \n",
       "158211                                          0   \n",
       "158212                                          0   \n",
       "158213                                          0   \n",
       "\n",
       "        f_payload.pull_request.base.repo.topics_n  f_release_assets_n  \\\n",
       "0                                               0                   0   \n",
       "1                                               0                   0   \n",
       "2                                               0                   0   \n",
       "3                                               0                   0   \n",
       "4                                               0                   0   \n",
       "...                                           ...                 ...   \n",
       "158209                                          0                   0   \n",
       "158210                                          0                   0   \n",
       "158211                                          0                   0   \n",
       "158212                                          0                   0   \n",
       "158213                                          0                   0   \n",
       "\n",
       "        f_release_assets_total_size  f_pages_n  f_release_mentions_n  \\\n",
       "0                                 0          0                     0   \n",
       "1                                 0          0                     0   \n",
       "2                                 0          0                     0   \n",
       "3                                 0          0                     0   \n",
       "4                                 0          0                     0   \n",
       "...                             ...        ...                   ...   \n",
       "158209                            0          0                     0   \n",
       "158210                            0          0                     0   \n",
       "158211                            0          0                     0   \n",
       "158212                            0          0                     0   \n",
       "158213                            0          0                     0   \n",
       "\n",
       "        f_app_events_n  \n",
       "0                    0  \n",
       "1                    0  \n",
       "2                    0  \n",
       "3                    0  \n",
       "4                    0  \n",
       "...                ...  \n",
       "158209               8  \n",
       "158210               0  \n",
       "158211               0  \n",
       "158212               0  \n",
       "158213               0  \n",
       "\n",
       "[158214 rows x 21 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "538288d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['type', 'created_at', 'payload.size', 'payload.distinct_size',\n",
       "       'payload.ref', 'f_commits_n', 'f_commits_n_distinct',\n",
       "       'f_commits_avg_msg_len', 'f_commits_max_msg_len', 'f_issue_labels_n',\n",
       "       'f_pr_labels_n', 'f_payload.issue.assignees_n',\n",
       "       'f_payload.pull_request.assignees_n',\n",
       "       'f_payload.pull_request.requested_reviewers_n',\n",
       "       'f_payload.pull_request.head.repo.topics_n',\n",
       "       'f_payload.pull_request.base.repo.topics_n', 'f_release_assets_n',\n",
       "       'f_release_assets_total_size', 'f_pages_n', 'f_release_mentions_n',\n",
       "       'f_app_events_n'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6208d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'which'��(��) ���� �Ǵ� �ܺ� ����, ������ �� �ִ� ���α׷�, �Ǵ�\n",
      "��ġ ������ �ƴմϴ�.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in c:\\users\\el044\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (25.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\el044\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.2.5)\n",
      "Requirement already satisfied: pandas in c:\\users\\el044\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.2.3)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.7.2-cp313-cp313-win_amd64.whl.metadata (11 kB)\n",
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.20.0-cp313-cp313-win_amd64.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\el044\\appdata\\roaming\\python\\python313\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\el044\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\el044\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2025.2)\n",
      "Collecting scipy>=1.8.0 (from scikit-learn)\n",
      "  Downloading scipy-1.16.2-cp313-cp313-win_amd64.whl.metadata (60 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Downloading joblib-1.5.2-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Using cached threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow)\n",
      "  Using cached absl_py-2.3.1-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow)\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow)\n",
      "  Using cached flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\n",
      "  Using cached gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google_pasta>=0.1.1 (from tensorflow)\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting libclang>=13.0.0 (from tensorflow)\n",
      "  Using cached libclang-18.1.1-py2.py3-none-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting opt_einsum>=2.3.2 (from tensorflow)\n",
      "  Using cached opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\el044\\appdata\\roaming\\python\\python313\\site-packages (from tensorflow) (25.0)\n",
      "Collecting protobuf>=5.28.0 (from tensorflow)\n",
      "  Downloading protobuf-6.32.1-cp310-abi3-win_amd64.whl.metadata (593 bytes)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\el044\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorflow) (2.32.3)\n",
      "Collecting setuptools (from tensorflow)\n",
      "  Using cached setuptools-80.9.0-py3-none-any.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\el044\\appdata\\roaming\\python\\python313\\site-packages (from tensorflow) (1.17.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Using cached termcolor-3.1.0-py3-none-any.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: typing_extensions>=3.6.6 in c:\\users\\el044\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorflow) (4.14.1)\n",
      "Collecting wrapt>=1.11.0 (from tensorflow)\n",
      "  Downloading wrapt-1.17.3-cp313-cp313-win_amd64.whl.metadata (6.5 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow)\n",
      "  Downloading grpcio-1.74.0-cp313-cp313-win_amd64.whl.metadata (4.0 kB)\n",
      "Collecting tensorboard~=2.20.0 (from tensorflow)\n",
      "  Using cached tensorboard-2.20.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting keras>=3.10.0 (from tensorflow)\n",
      "  Downloading keras-3.11.3-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting h5py>=3.11.0 (from tensorflow)\n",
      "  Downloading h5py-3.14.0-cp313-cp313-win_amd64.whl.metadata (2.7 kB)\n",
      "Collecting ml_dtypes<1.0.0,>=0.5.1 (from tensorflow)\n",
      "  Downloading ml_dtypes-0.5.3-cp313-cp313-win_amd64.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\el044\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\el044\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\el044\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\el044\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2025.8.3)\n",
      "Collecting markdown>=2.6.8 (from tensorboard~=2.20.0->tensorflow)\n",
      "  Using cached markdown-3.9-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: pillow in c:\\users\\el044\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (11.2.1)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard~=2.20.0->tensorflow)\n",
      "  Using cached tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard~=2.20.0->tensorflow)\n",
      "  Using cached werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting wheel<1.0,>=0.23.0 (from astunparse>=1.6.0->tensorflow)\n",
      "  Using cached wheel-0.45.1-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting rich (from keras>=3.10.0->tensorflow)\n",
      "  Downloading rich-14.1.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting namex (from keras>=3.10.0->tensorflow)\n",
      "  Using cached namex-0.1.0-py3-none-any.whl.metadata (322 bytes)\n",
      "Collecting optree (from keras>=3.10.0->tensorflow)\n",
      "  Downloading optree-0.17.0-cp313-cp313-win_amd64.whl.metadata (34 kB)\n",
      "Collecting MarkupSafe>=2.1.1 (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow)\n",
      "  Using cached MarkupSafe-3.0.2-cp313-cp313-win_amd64.whl.metadata (4.1 kB)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->keras>=3.10.0->tensorflow)\n",
      "  Downloading markdown_it_py-4.0.0-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\el044\\appdata\\roaming\\python\\python313\\site-packages (from rich->keras>=3.10.0->tensorflow) (2.19.1)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow)\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Downloading scikit_learn-1.7.2-cp313-cp313-win_amd64.whl (8.7 MB)\n",
      "   ---------------------------------------- 0.0/8.7 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.5/8.7 MB 5.1 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 1.0/8.7 MB 3.3 MB/s eta 0:00:03\n",
      "   -------- ------------------------------- 1.8/8.7 MB 2.8 MB/s eta 0:00:03\n",
      "   -------- ------------------------------- 1.8/8.7 MB 2.8 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 2.6/8.7 MB 2.7 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 2.6/8.7 MB 2.7 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 2.6/8.7 MB 2.7 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 2.6/8.7 MB 2.7 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 2.6/8.7 MB 2.7 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 2.6/8.7 MB 2.7 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 2.6/8.7 MB 2.7 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 2.6/8.7 MB 2.7 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 2.6/8.7 MB 2.7 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 3.7/8.7 MB 1.3 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 3.7/8.7 MB 1.3 MB/s eta 0:00:04\n",
      "   ------------------- -------------------- 4.2/8.7 MB 1.2 MB/s eta 0:00:04\n",
      "   ---------------------- ----------------- 5.0/8.7 MB 1.4 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 6.6/8.7 MB 1.7 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 7.9/8.7 MB 2.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 8.7/8.7 MB 2.1 MB/s  0:00:04\n",
      "Downloading tensorflow-2.20.0-cp313-cp313-win_amd64.whl (332.0 MB)\n",
      "   ---------------------------------------- 0.0/332.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.3/332.0 MB 11.1 MB/s eta 0:00:30\n",
      "   ---------------------------------------- 3.1/332.0 MB 9.6 MB/s eta 0:00:35\n",
      "   ---------------------------------------- 3.7/332.0 MB 6.7 MB/s eta 0:00:49\n",
      "    --------------------------------------- 5.2/332.0 MB 7.1 MB/s eta 0:00:47\n",
      "    --------------------------------------- 6.8/332.0 MB 7.1 MB/s eta 0:00:46\n",
      "   - -------------------------------------- 8.4/332.0 MB 7.2 MB/s eta 0:00:45\n",
      "   - -------------------------------------- 10.2/332.0 MB 7.5 MB/s eta 0:00:43\n",
      "   - -------------------------------------- 11.3/332.0 MB 7.2 MB/s eta 0:00:45\n",
      "   - -------------------------------------- 13.1/332.0 MB 7.4 MB/s eta 0:00:43\n",
      "   - -------------------------------------- 14.4/332.0 MB 7.4 MB/s eta 0:00:44\n",
      "   - -------------------------------------- 15.2/332.0 MB 6.9 MB/s eta 0:00:46\n",
      "   - -------------------------------------- 16.3/332.0 MB 6.9 MB/s eta 0:00:47\n",
      "   -- ------------------------------------- 17.8/332.0 MB 6.9 MB/s eta 0:00:46\n",
      "   -- ------------------------------------- 18.4/332.0 MB 6.5 MB/s eta 0:00:49\n",
      "   -- ------------------------------------- 18.9/332.0 MB 6.5 MB/s eta 0:00:49\n",
      "   -- ------------------------------------- 18.9/332.0 MB 6.5 MB/s eta 0:00:49\n",
      "   -- ------------------------------------- 18.9/332.0 MB 6.5 MB/s eta 0:00:49\n",
      "   -- ------------------------------------- 20.2/332.0 MB 5.5 MB/s eta 0:00:57\n",
      "   -- ------------------------------------- 21.0/332.0 MB 5.4 MB/s eta 0:00:58\n",
      "   -- ------------------------------------- 22.5/332.0 MB 5.5 MB/s eta 0:00:57\n",
      "   -- ------------------------------------- 23.3/332.0 MB 5.5 MB/s eta 0:00:57\n",
      "   -- ------------------------------------- 24.1/332.0 MB 5.5 MB/s eta 0:00:56\n",
      "   --- ------------------------------------ 24.9/332.0 MB 5.4 MB/s eta 0:00:57\n",
      "   --- ------------------------------------ 24.9/332.0 MB 5.4 MB/s eta 0:00:57\n",
      "   --- ------------------------------------ 24.9/332.0 MB 5.4 MB/s eta 0:00:57\n",
      "   --- ------------------------------------ 25.4/332.0 MB 4.9 MB/s eta 0:01:03\n",
      "   --- ------------------------------------ 25.7/332.0 MB 4.8 MB/s eta 0:01:05\n",
      "   --- ------------------------------------ 26.0/332.0 MB 4.6 MB/s eta 0:01:07\n",
      "   --- ------------------------------------ 26.0/332.0 MB 4.6 MB/s eta 0:01:07\n",
      "   --- ------------------------------------ 26.2/332.0 MB 4.4 MB/s eta 0:01:11\n",
      "   --- ------------------------------------ 26.5/332.0 MB 4.3 MB/s eta 0:01:12\n",
      "   --- ------------------------------------ 26.7/332.0 MB 4.0 MB/s eta 0:01:16\n",
      "   --- ------------------------------------ 27.3/332.0 MB 4.0 MB/s eta 0:01:17\n",
      "   --- ------------------------------------ 27.3/332.0 MB 4.0 MB/s eta 0:01:17\n",
      "   --- ------------------------------------ 27.3/332.0 MB 4.0 MB/s eta 0:01:17\n",
      "   --- ------------------------------------ 28.0/332.0 MB 3.8 MB/s eta 0:01:21\n",
      "   --- ------------------------------------ 28.6/332.0 MB 3.7 MB/s eta 0:01:22\n",
      "   --- ------------------------------------ 29.1/332.0 MB 3.7 MB/s eta 0:01:22\n",
      "   --- ------------------------------------ 29.9/332.0 MB 3.7 MB/s eta 0:01:22\n",
      "   --- ------------------------------------ 31.2/332.0 MB 3.8 MB/s eta 0:01:20\n",
      "   --- ------------------------------------ 32.5/332.0 MB 3.8 MB/s eta 0:01:18\n",
      "   ---- ----------------------------------- 33.8/332.0 MB 3.9 MB/s eta 0:01:17\n",
      "   ---- ----------------------------------- 34.9/332.0 MB 3.9 MB/s eta 0:01:16\n",
      "   ---- ----------------------------------- 36.7/332.0 MB 4.0 MB/s eta 0:01:14\n",
      "   ---- ----------------------------------- 37.7/332.0 MB 4.1 MB/s eta 0:01:13\n",
      "   ---- ----------------------------------- 39.3/332.0 MB 4.1 MB/s eta 0:01:11\n",
      "   ---- ----------------------------------- 40.9/332.0 MB 4.2 MB/s eta 0:01:10\n",
      "   ----- ---------------------------------- 42.7/332.0 MB 4.3 MB/s eta 0:01:08\n",
      "   ----- ---------------------------------- 44.8/332.0 MB 4.4 MB/s eta 0:01:06\n",
      "   ----- ---------------------------------- 45.9/332.0 MB 4.5 MB/s eta 0:01:04\n",
      "   ----- ---------------------------------- 46.7/332.0 MB 4.5 MB/s eta 0:01:04\n",
      "   ----- ---------------------------------- 47.7/332.0 MB 4.4 MB/s eta 0:01:05\n",
      "   ----- ---------------------------------- 48.5/332.0 MB 4.4 MB/s eta 0:01:04\n",
      "   ----- ---------------------------------- 48.8/332.0 MB 4.4 MB/s eta 0:01:05\n",
      "   ------ --------------------------------- 49.8/332.0 MB 4.4 MB/s eta 0:01:05\n",
      "   ------ --------------------------------- 50.6/332.0 MB 4.4 MB/s eta 0:01:05\n",
      "   ------ --------------------------------- 51.4/332.0 MB 4.4 MB/s eta 0:01:05\n",
      "   ------ --------------------------------- 52.2/332.0 MB 4.4 MB/s eta 0:01:04\n",
      "   ------ --------------------------------- 53.2/332.0 MB 4.4 MB/s eta 0:01:05\n",
      "   ------ --------------------------------- 54.3/332.0 MB 4.4 MB/s eta 0:01:04\n",
      "   ------ --------------------------------- 55.1/332.0 MB 4.4 MB/s eta 0:01:03\n",
      "   ------ --------------------------------- 55.6/332.0 MB 4.3 MB/s eta 0:01:05\n",
      "   ------ --------------------------------- 55.8/332.0 MB 4.3 MB/s eta 0:01:05\n",
      "   ------ --------------------------------- 56.1/332.0 MB 4.3 MB/s eta 0:01:05\n",
      "   ------ --------------------------------- 56.1/332.0 MB 4.3 MB/s eta 0:01:05\n",
      "   ------ --------------------------------- 56.1/332.0 MB 4.3 MB/s eta 0:01:05\n",
      "   ------ --------------------------------- 56.1/332.0 MB 4.3 MB/s eta 0:01:05\n",
      "   ------ --------------------------------- 56.1/332.0 MB 4.3 MB/s eta 0:01:05\n",
      "   ------ --------------------------------- 57.1/332.0 MB 4.0 MB/s eta 0:01:09\n",
      "   ------ --------------------------------- 57.1/332.0 MB 4.0 MB/s eta 0:01:09\n",
      "   ------ --------------------------------- 57.1/332.0 MB 4.0 MB/s eta 0:01:09\n",
      "   ------- -------------------------------- 58.2/332.0 MB 3.9 MB/s eta 0:01:11\n",
      "   ------- -------------------------------- 59.2/332.0 MB 3.9 MB/s eta 0:01:10\n",
      "   ------- -------------------------------- 60.6/332.0 MB 4.0 MB/s eta 0:01:09\n",
      "   ------- -------------------------------- 61.6/332.0 MB 4.0 MB/s eta 0:01:09\n",
      "   ------- -------------------------------- 62.9/332.0 MB 4.0 MB/s eta 0:01:08\n",
      "   ------- -------------------------------- 63.7/332.0 MB 4.0 MB/s eta 0:01:08\n",
      "   ------- -------------------------------- 64.2/332.0 MB 4.0 MB/s eta 0:01:08\n",
      "   ------- -------------------------------- 64.7/332.0 MB 4.0 MB/s eta 0:01:08\n",
      "   ------- -------------------------------- 65.3/332.0 MB 3.9 MB/s eta 0:01:09\n",
      "   ------- -------------------------------- 65.8/332.0 MB 3.9 MB/s eta 0:01:09\n",
      "   -------- ------------------------------- 66.8/332.0 MB 3.9 MB/s eta 0:01:08\n",
      "   -------- ------------------------------- 67.4/332.0 MB 3.9 MB/s eta 0:01:08\n",
      "   -------- ------------------------------- 68.7/332.0 MB 3.9 MB/s eta 0:01:07\n",
      "   -------- ------------------------------- 68.9/332.0 MB 3.9 MB/s eta 0:01:07\n",
      "   -------- ------------------------------- 69.2/332.0 MB 3.9 MB/s eta 0:01:08\n",
      "   -------- ------------------------------- 69.7/332.0 MB 3.9 MB/s eta 0:01:09\n",
      "   -------- ------------------------------- 70.5/332.0 MB 3.9 MB/s eta 0:01:08\n",
      "   -------- ------------------------------- 71.6/332.0 MB 3.9 MB/s eta 0:01:08\n",
      "   -------- ------------------------------- 71.8/332.0 MB 3.8 MB/s eta 0:01:08\n",
      "   -------- ------------------------------- 72.6/332.0 MB 3.8 MB/s eta 0:01:08\n",
      "   -------- ------------------------------- 73.4/332.0 MB 3.8 MB/s eta 0:01:08\n",
      "   -------- ------------------------------- 73.7/332.0 MB 3.8 MB/s eta 0:01:08\n",
      "   --------- ------------------------------ 74.7/332.0 MB 3.8 MB/s eta 0:01:08\n",
      "   --------- ------------------------------ 74.7/332.0 MB 3.8 MB/s eta 0:01:08\n",
      "   --------- ------------------------------ 75.0/332.0 MB 3.8 MB/s eta 0:01:09\n",
      "   --------- ------------------------------ 75.5/332.0 MB 3.7 MB/s eta 0:01:09\n",
      "   --------- ------------------------------ 75.8/332.0 MB 3.7 MB/s eta 0:01:09\n",
      "   --------- ------------------------------ 75.8/332.0 MB 3.7 MB/s eta 0:01:09\n",
      "   --------- ------------------------------ 76.3/332.0 MB 3.7 MB/s eta 0:01:10\n",
      "   --------- ------------------------------ 77.1/332.0 MB 3.7 MB/s eta 0:01:10\n",
      "   --------- ------------------------------ 77.1/332.0 MB 3.7 MB/s eta 0:01:10\n",
      "   --------- ------------------------------ 77.1/332.0 MB 3.7 MB/s eta 0:01:10\n",
      "   --------- ------------------------------ 77.6/332.0 MB 3.6 MB/s eta 0:01:11\n",
      "   --------- ------------------------------ 77.6/332.0 MB 3.6 MB/s eta 0:01:11\n",
      "   --------- ------------------------------ 77.6/332.0 MB 3.6 MB/s eta 0:01:11\n",
      "   --------- ------------------------------ 77.9/332.0 MB 3.5 MB/s eta 0:01:13\n",
      "   --------- ------------------------------ 77.9/332.0 MB 3.5 MB/s eta 0:01:13\n",
      "   --------- ------------------------------ 78.6/332.0 MB 3.5 MB/s eta 0:01:14\n",
      "   --------- ------------------------------ 79.2/332.0 MB 3.5 MB/s eta 0:01:14\n",
      "   --------- ------------------------------ 80.5/332.0 MB 3.5 MB/s eta 0:01:13\n",
      "   --------- ------------------------------ 81.5/332.0 MB 3.5 MB/s eta 0:01:12\n",
      "   --------- ------------------------------ 82.6/332.0 MB 3.5 MB/s eta 0:01:11\n",
      "   ---------- ----------------------------- 83.4/332.0 MB 3.5 MB/s eta 0:01:11\n",
      "   ---------- ----------------------------- 83.9/332.0 MB 3.5 MB/s eta 0:01:11\n",
      "   ---------- ----------------------------- 84.4/332.0 MB 3.5 MB/s eta 0:01:11\n",
      "   ---------- ----------------------------- 85.2/332.0 MB 3.5 MB/s eta 0:01:11\n",
      "   ---------- ----------------------------- 86.2/332.0 MB 3.5 MB/s eta 0:01:10\n",
      "   ---------- ----------------------------- 86.8/332.0 MB 3.5 MB/s eta 0:01:10\n",
      "   ---------- ----------------------------- 87.6/332.0 MB 3.5 MB/s eta 0:01:10\n",
      "   ---------- ----------------------------- 88.3/332.0 MB 3.5 MB/s eta 0:01:10\n",
      "   ---------- ----------------------------- 89.1/332.0 MB 3.5 MB/s eta 0:01:10\n",
      "   ---------- ----------------------------- 89.9/332.0 MB 3.5 MB/s eta 0:01:09\n",
      "   ---------- ----------------------------- 90.7/332.0 MB 3.5 MB/s eta 0:01:09\n",
      "   ----------- ---------------------------- 92.0/332.0 MB 3.5 MB/s eta 0:01:08\n",
      "   ----------- ---------------------------- 92.8/332.0 MB 3.6 MB/s eta 0:01:08\n",
      "   ----------- ---------------------------- 93.8/332.0 MB 3.6 MB/s eta 0:01:07\n",
      "   ----------- ---------------------------- 94.6/332.0 MB 3.6 MB/s eta 0:01:07\n",
      "   ----------- ---------------------------- 94.9/332.0 MB 3.5 MB/s eta 0:01:08\n",
      "   ----------- ---------------------------- 95.2/332.0 MB 3.5 MB/s eta 0:01:08\n",
      "   ----------- ---------------------------- 95.9/332.0 MB 3.5 MB/s eta 0:01:08\n",
      "   ----------- ---------------------------- 96.7/332.0 MB 3.5 MB/s eta 0:01:07\n",
      "   ----------- ---------------------------- 96.7/332.0 MB 3.5 MB/s eta 0:01:07\n",
      "   ----------- ---------------------------- 97.0/332.0 MB 3.5 MB/s eta 0:01:08\n",
      "   ----------- ---------------------------- 97.8/332.0 MB 3.5 MB/s eta 0:01:08\n",
      "   ----------- ---------------------------- 98.0/332.0 MB 3.5 MB/s eta 0:01:08\n",
      "   ----------- ---------------------------- 98.3/332.0 MB 3.5 MB/s eta 0:01:08\n",
      "   ----------- ---------------------------- 98.3/332.0 MB 3.5 MB/s eta 0:01:08\n",
      "   ----------- ---------------------------- 98.3/332.0 MB 3.5 MB/s eta 0:01:08\n",
      "   ----------- ---------------------------- 98.3/332.0 MB 3.5 MB/s eta 0:01:08\n",
      "   ----------- ---------------------------- 98.3/332.0 MB 3.5 MB/s eta 0:01:08\n",
      "   ----------- ---------------------------- 98.8/332.0 MB 3.3 MB/s eta 0:01:10\n",
      "   ----------- ---------------------------- 99.4/332.0 MB 3.3 MB/s eta 0:01:10\n",
      "   ----------- ---------------------------- 99.4/332.0 MB 3.3 MB/s eta 0:01:10\n",
      "   ------------ --------------------------- 100.1/332.0 MB 3.3 MB/s eta 0:01:11\n",
      "   ------------ --------------------------- 100.4/332.0 MB 3.2 MB/s eta 0:01:12\n",
      "   ------------ --------------------------- 100.7/332.0 MB 3.3 MB/s eta 0:01:12\n",
      "   ------------ --------------------------- 100.7/332.0 MB 3.3 MB/s eta 0:01:12\n",
      "   ------------ --------------------------- 100.9/332.0 MB 3.2 MB/s eta 0:01:13\n",
      "   ------------ --------------------------- 101.4/332.0 MB 3.1 MB/s eta 0:01:15\n",
      "   ------------ --------------------------- 101.7/332.0 MB 3.1 MB/s eta 0:01:16\n",
      "   ------------ --------------------------- 101.7/332.0 MB 3.1 MB/s eta 0:01:16\n",
      "   ------------ --------------------------- 101.7/332.0 MB 3.1 MB/s eta 0:01:16\n",
      "   ------------ --------------------------- 102.0/332.0 MB 2.9 MB/s eta 0:01:19\n",
      "   ------------ --------------------------- 103.0/332.0 MB 2.9 MB/s eta 0:01:19\n",
      "   ------------ --------------------------- 104.1/332.0 MB 2.9 MB/s eta 0:01:18\n",
      "   ------------ --------------------------- 104.6/332.0 MB 2.9 MB/s eta 0:01:18\n",
      "   ------------ --------------------------- 104.6/332.0 MB 2.9 MB/s eta 0:01:18\n",
      "   ------------ --------------------------- 105.4/332.0 MB 2.9 MB/s eta 0:01:18\n",
      "   ------------ --------------------------- 105.6/332.0 MB 2.9 MB/s eta 0:01:18\n",
      "   ------------ --------------------------- 105.6/332.0 MB 2.9 MB/s eta 0:01:18\n",
      "   ------------ --------------------------- 105.6/332.0 MB 2.9 MB/s eta 0:01:18\n",
      "   ------------ --------------------------- 105.6/332.0 MB 2.9 MB/s eta 0:01:18\n",
      "   ------------ --------------------------- 106.7/332.0 MB 2.8 MB/s eta 0:01:20\n",
      "   ------------ --------------------------- 107.5/332.0 MB 2.8 MB/s eta 0:01:21\n",
      "   ------------- -------------------------- 108.0/332.0 MB 2.8 MB/s eta 0:01:21\n",
      "   ------------- -------------------------- 108.3/332.0 MB 2.8 MB/s eta 0:01:20\n",
      "   ------------- -------------------------- 108.3/332.0 MB 2.8 MB/s eta 0:01:20\n",
      "   ------------- -------------------------- 108.8/332.0 MB 2.8 MB/s eta 0:01:20\n",
      "   ------------- -------------------------- 109.6/332.0 MB 2.8 MB/s eta 0:01:20\n",
      "   ------------- -------------------------- 109.8/332.0 MB 2.8 MB/s eta 0:01:20\n",
      "   ------------- -------------------------- 109.8/332.0 MB 2.8 MB/s eta 0:01:20\n",
      "   ------------- -------------------------- 110.4/332.0 MB 2.8 MB/s eta 0:01:19\n",
      "   ------------- -------------------------- 110.6/332.0 MB 2.8 MB/s eta 0:01:19\n",
      "   ------------- -------------------------- 111.4/332.0 MB 2.8 MB/s eta 0:01:18\n",
      "   ------------- -------------------------- 111.9/332.0 MB 2.8 MB/s eta 0:01:18\n",
      "   ------------- -------------------------- 112.2/332.0 MB 2.9 MB/s eta 0:01:17\n",
      "   ------------- -------------------------- 112.5/332.0 MB 2.9 MB/s eta 0:01:17\n",
      "   ------------- -------------------------- 112.7/332.0 MB 2.9 MB/s eta 0:01:17\n",
      "   ------------- -------------------------- 112.7/332.0 MB 2.9 MB/s eta 0:01:17\n",
      "   ------------- -------------------------- 112.7/332.0 MB 2.9 MB/s eta 0:01:17\n",
      "   ------------- -------------------------- 112.7/332.0 MB 2.9 MB/s eta 0:01:17\n",
      "   ------------- -------------------------- 112.7/332.0 MB 2.9 MB/s eta 0:01:17\n",
      "   ------------- -------------------------- 112.7/332.0 MB 2.9 MB/s eta 0:01:17\n",
      "   ------------- -------------------------- 112.7/332.0 MB 2.9 MB/s eta 0:01:17\n",
      "   ------------- -------------------------- 113.2/332.0 MB 2.7 MB/s eta 0:01:23\n",
      "   ------------- -------------------------- 114.0/332.0 MB 2.6 MB/s eta 0:01:23\n",
      "   ------------- -------------------------- 114.3/332.0 MB 2.6 MB/s eta 0:01:25\n",
      "   ------------- -------------------------- 114.8/332.0 MB 2.6 MB/s eta 0:01:25\n",
      "   ------------- -------------------------- 115.1/332.0 MB 2.5 MB/s eta 0:01:26\n",
      "   ------------- -------------------------- 115.6/332.0 MB 2.5 MB/s eta 0:01:27\n",
      "   ------------- -------------------------- 116.1/332.0 MB 2.5 MB/s eta 0:01:28\n",
      "   -------------- ------------------------- 116.7/332.0 MB 2.4 MB/s eta 0:01:29\n",
      "   -------------- ------------------------- 117.2/332.0 MB 2.4 MB/s eta 0:01:31\n",
      "   -------------- ------------------------- 117.7/332.0 MB 2.4 MB/s eta 0:01:31\n",
      "   -------------- ------------------------- 118.2/332.0 MB 2.4 MB/s eta 0:01:31\n",
      "   -------------- ------------------------- 118.8/332.0 MB 2.3 MB/s eta 0:01:31\n",
      "   -------------- ------------------------- 119.5/332.0 MB 2.4 MB/s eta 0:01:30\n",
      "   -------------- ------------------------- 120.1/332.0 MB 2.3 MB/s eta 0:01:31\n",
      "   -------------- ------------------------- 120.6/332.0 MB 2.3 MB/s eta 0:01:31\n",
      "   -------------- ------------------------- 120.8/332.0 MB 2.3 MB/s eta 0:01:31\n",
      "   -------------- ------------------------- 121.1/332.0 MB 2.3 MB/s eta 0:01:32\n",
      "   -------------- ------------------------- 121.6/332.0 MB 2.3 MB/s eta 0:01:32\n",
      "   -------------- ------------------------- 121.6/332.0 MB 2.3 MB/s eta 0:01:32\n",
      "   -------------- ------------------------- 121.6/332.0 MB 2.3 MB/s eta 0:01:32\n",
      "   -------------- ------------------------- 122.2/332.0 MB 2.2 MB/s eta 0:01:35\n",
      "   -------------- ------------------------- 122.4/332.0 MB 2.2 MB/s eta 0:01:35\n",
      "   -------------- ------------------------- 122.7/332.0 MB 2.3 MB/s eta 0:01:32\n",
      "   -------------- ------------------------- 122.9/332.0 MB 2.3 MB/s eta 0:01:32\n",
      "   -------------- ------------------------- 123.2/332.0 MB 2.3 MB/s eta 0:01:32\n",
      "   -------------- ------------------------- 124.0/332.0 MB 2.3 MB/s eta 0:01:32\n",
      "   --------------- ------------------------ 124.5/332.0 MB 2.3 MB/s eta 0:01:31\n",
      "   --------------- ------------------------ 125.3/332.0 MB 2.3 MB/s eta 0:01:30\n",
      "   --------------- ------------------------ 126.1/332.0 MB 2.3 MB/s eta 0:01:29\n",
      "   --------------- ------------------------ 126.1/332.0 MB 2.3 MB/s eta 0:01:29\n",
      "   --------------- ------------------------ 126.1/332.0 MB 2.3 MB/s eta 0:01:29\n",
      "   --------------- ------------------------ 126.1/332.0 MB 2.3 MB/s eta 0:01:29\n",
      "   --------------- ------------------------ 126.1/332.0 MB 2.3 MB/s eta 0:01:29\n",
      "   --------------- ------------------------ 126.1/332.0 MB 2.3 MB/s eta 0:01:29\n",
      "   --------------- ------------------------ 126.4/332.0 MB 2.2 MB/s eta 0:01:36\n",
      "   --------------- ------------------------ 126.4/332.0 MB 2.2 MB/s eta 0:01:36\n",
      "   --------------- ------------------------ 126.4/332.0 MB 2.2 MB/s eta 0:01:36\n",
      "   --------------- ------------------------ 126.4/332.0 MB 2.2 MB/s eta 0:01:36\n",
      "   --------------- ------------------------ 126.9/332.0 MB 2.1 MB/s eta 0:01:40\n",
      "   --------------- ------------------------ 126.9/332.0 MB 2.1 MB/s eta 0:01:40\n",
      "   --------------- ------------------------ 126.9/332.0 MB 2.1 MB/s eta 0:01:40\n",
      "   --------------- ------------------------ 126.9/332.0 MB 2.1 MB/s eta 0:01:40\n",
      "   --------------- ------------------------ 126.9/332.0 MB 2.1 MB/s eta 0:01:40\n",
      "   --------------- ------------------------ 126.9/332.0 MB 2.1 MB/s eta 0:01:40\n",
      "   --------------- ------------------------ 126.9/332.0 MB 2.1 MB/s eta 0:01:40\n",
      "   --------------- ------------------------ 127.1/332.0 MB 1.9 MB/s eta 0:01:47\n",
      "   --------------- ------------------------ 127.1/332.0 MB 1.9 MB/s eta 0:01:47\n",
      "   --------------- ------------------------ 127.1/332.0 MB 1.9 MB/s eta 0:01:47\n",
      "   --------------- ------------------------ 127.1/332.0 MB 1.9 MB/s eta 0:01:47\n",
      "   --------------- ------------------------ 127.1/332.0 MB 1.9 MB/s eta 0:01:47\n",
      "   --------------- ------------------------ 127.4/332.0 MB 1.8 MB/s eta 0:01:52\n",
      "   --------------- ------------------------ 127.4/332.0 MB 1.8 MB/s eta 0:01:52\n",
      "   --------------- ------------------------ 127.7/332.0 MB 1.8 MB/s eta 0:01:54\n",
      "   --------------- ------------------------ 127.9/332.0 MB 1.8 MB/s eta 0:01:54\n",
      "   --------------- ------------------------ 128.2/332.0 MB 1.8 MB/s eta 0:01:55\n",
      "   --------------- ------------------------ 128.2/332.0 MB 1.8 MB/s eta 0:01:55\n",
      "   --------------- ------------------------ 128.5/332.0 MB 1.8 MB/s eta 0:01:56\n",
      "   --------------- ------------------------ 128.5/332.0 MB 1.8 MB/s eta 0:01:56\n",
      "   --------------- ------------------------ 128.7/332.0 MB 1.8 MB/s eta 0:01:56\n",
      "   --------------- ------------------------ 129.0/332.0 MB 1.8 MB/s eta 0:01:56\n",
      "   --------------- ------------------------ 129.5/332.0 MB 1.8 MB/s eta 0:01:56\n",
      "   --------------- ------------------------ 129.5/332.0 MB 1.8 MB/s eta 0:01:56\n",
      "   --------------- ------------------------ 129.8/332.0 MB 1.7 MB/s eta 0:01:56\n",
      "   --------------- ------------------------ 130.0/332.0 MB 1.8 MB/s eta 0:01:54\n",
      "   --------------- ------------------------ 130.0/332.0 MB 1.8 MB/s eta 0:01:54\n",
      "   --------------- ------------------------ 130.5/332.0 MB 1.8 MB/s eta 0:01:55\n",
      "   --------------- ------------------------ 130.5/332.0 MB 1.8 MB/s eta 0:01:55\n",
      "   --------------- ------------------------ 130.8/332.0 MB 1.8 MB/s eta 0:01:55\n",
      "   --------------- ------------------------ 131.1/332.0 MB 1.7 MB/s eta 0:01:56\n",
      "   --------------- ------------------------ 131.9/332.0 MB 1.7 MB/s eta 0:01:56\n",
      "   --------------- ------------------------ 132.1/332.0 MB 1.7 MB/s eta 0:01:56\n",
      "   --------------- ------------------------ 132.1/332.0 MB 1.7 MB/s eta 0:01:56\n",
      "   --------------- ------------------------ 132.1/332.0 MB 1.7 MB/s eta 0:01:56\n",
      "   --------------- ------------------------ 132.1/332.0 MB 1.7 MB/s eta 0:01:56\n",
      "   --------------- ------------------------ 132.1/332.0 MB 1.7 MB/s eta 0:01:56\n",
      "   --------------- ------------------------ 132.4/332.0 MB 1.6 MB/s eta 0:02:06\n",
      "   --------------- ------------------------ 132.6/332.0 MB 1.6 MB/s eta 0:02:07\n",
      "   --------------- ------------------------ 132.6/332.0 MB 1.6 MB/s eta 0:02:07\n",
      "   ---------------- ----------------------- 132.9/332.0 MB 1.5 MB/s eta 0:02:10\n",
      "   ---------------- ----------------------- 133.2/332.0 MB 1.5 MB/s eta 0:02:12\n",
      "   ---------------- ----------------------- 133.2/332.0 MB 1.5 MB/s eta 0:02:12\n",
      "   ---------------- ----------------------- 133.4/332.0 MB 1.5 MB/s eta 0:02:17\n",
      "   ---------------- ----------------------- 133.7/332.0 MB 1.5 MB/s eta 0:02:17\n",
      "   ---------------- ----------------------- 133.7/332.0 MB 1.5 MB/s eta 0:02:17\n",
      "   ---------------- ----------------------- 134.0/332.0 MB 1.4 MB/s eta 0:02:23\n",
      "   ---------------- ----------------------- 134.0/332.0 MB 1.4 MB/s eta 0:02:23\n",
      "   ---------------- ----------------------- 134.0/332.0 MB 1.4 MB/s eta 0:02:23\n",
      "   ---------------- ----------------------- 134.5/332.0 MB 1.3 MB/s eta 0:02:30\n",
      "   ---------------- ----------------------- 135.0/332.0 MB 1.3 MB/s eta 0:02:28\n",
      "   ---------------- ----------------------- 136.1/332.0 MB 1.4 MB/s eta 0:02:25\n",
      "   ---------------- ----------------------- 137.1/332.0 MB 1.4 MB/s eta 0:02:25\n",
      "   ---------------- ----------------------- 138.7/332.0 MB 1.4 MB/s eta 0:02:19\n",
      "   ---------------- ----------------------- 140.2/332.0 MB 1.4 MB/s eta 0:02:14\n",
      "   ----------------- ---------------------- 141.6/332.0 MB 1.5 MB/s eta 0:02:10\n",
      "   ----------------- ---------------------- 142.6/332.0 MB 1.5 MB/s eta 0:02:08\n",
      "   ----------------- ---------------------- 144.4/332.0 MB 1.5 MB/s eta 0:02:02\n",
      "   ----------------- ---------------------- 146.5/332.0 MB 1.6 MB/s eta 0:01:54\n",
      "   ----------------- ---------------------- 148.4/332.0 MB 1.7 MB/s eta 0:01:49\n",
      "   ------------------ --------------------- 149.4/332.0 MB 1.7 MB/s eta 0:01:47\n",
      "   ------------------ --------------------- 150.2/332.0 MB 1.7 MB/s eta 0:01:45\n",
      "   ------------------ --------------------- 150.7/332.0 MB 1.7 MB/s eta 0:01:45\n",
      "   ------------------ --------------------- 152.3/332.0 MB 1.8 MB/s eta 0:01:42\n",
      "   ------------------ --------------------- 153.4/332.0 MB 1.8 MB/s eta 0:01:40\n",
      "   ------------------ --------------------- 153.6/332.0 MB 1.8 MB/s eta 0:01:40\n",
      "   ------------------ --------------------- 154.4/332.0 MB 1.8 MB/s eta 0:01:39\n",
      "   ------------------ --------------------- 155.2/332.0 MB 1.8 MB/s eta 0:01:37\n",
      "   ------------------ --------------------- 156.2/332.0 MB 1.9 MB/s eta 0:01:35\n",
      "   ------------------- -------------------- 157.8/332.0 MB 1.9 MB/s eta 0:01:32\n",
      "   ------------------- -------------------- 157.8/332.0 MB 1.9 MB/s eta 0:01:32\n",
      "   ------------------- -------------------- 158.1/332.0 MB 1.9 MB/s eta 0:01:32\n",
      "   ------------------- -------------------- 158.1/332.0 MB 1.9 MB/s eta 0:01:32\n",
      "   ------------------- -------------------- 158.6/332.0 MB 1.9 MB/s eta 0:01:31\n",
      "   ------------------- -------------------- 158.9/332.0 MB 1.9 MB/s eta 0:01:31\n",
      "   ------------------- -------------------- 159.4/332.0 MB 1.9 MB/s eta 0:01:32\n",
      "   ------------------- -------------------- 159.6/332.0 MB 1.9 MB/s eta 0:01:32\n",
      "   ------------------- -------------------- 159.9/332.0 MB 1.9 MB/s eta 0:01:33\n",
      "   ------------------- -------------------- 160.4/332.0 MB 1.9 MB/s eta 0:01:32\n",
      "   ------------------- -------------------- 160.7/332.0 MB 1.9 MB/s eta 0:01:32\n",
      "   ------------------- -------------------- 161.0/332.0 MB 1.9 MB/s eta 0:01:32\n",
      "   ------------------- -------------------- 161.0/332.0 MB 1.9 MB/s eta 0:01:32\n",
      "   ------------------- -------------------- 161.0/332.0 MB 1.9 MB/s eta 0:01:32\n",
      "   ------------------- -------------------- 163.6/332.0 MB 1.9 MB/s eta 0:01:27\n",
      "   ------------------- -------------------- 165.4/332.0 MB 2.0 MB/s eta 0:01:24\n",
      "   -------------------- ------------------- 167.0/332.0 MB 2.0 MB/s eta 0:01:23\n",
      "   -------------------- ------------------- 168.6/332.0 MB 2.0 MB/s eta 0:01:21\n",
      "   -------------------- ------------------- 169.9/332.0 MB 2.1 MB/s eta 0:01:19\n",
      "   -------------------- ------------------- 171.2/332.0 MB 2.1 MB/s eta 0:01:17\n",
      "   -------------------- ------------------- 172.8/332.0 MB 2.1 MB/s eta 0:01:15\n",
      "   --------------------- ------------------ 174.3/332.0 MB 2.2 MB/s eta 0:01:13\n",
      "   --------------------- ------------------ 176.2/332.0 MB 2.2 MB/s eta 0:01:11\n",
      "   --------------------- ------------------ 177.7/332.0 MB 2.3 MB/s eta 0:01:08\n",
      "   --------------------- ------------------ 179.0/332.0 MB 2.3 MB/s eta 0:01:07\n",
      "   --------------------- ------------------ 180.6/332.0 MB 2.3 MB/s eta 0:01:05\n",
      "   --------------------- ------------------ 181.4/332.0 MB 2.4 MB/s eta 0:01:05\n",
      "   ---------------------- ----------------- 182.7/332.0 MB 2.4 MB/s eta 0:01:03\n",
      "   ---------------------- ----------------- 184.3/332.0 MB 2.4 MB/s eta 0:01:02\n",
      "   ---------------------- ----------------- 184.5/332.0 MB 2.4 MB/s eta 0:01:02\n",
      "   ---------------------- ----------------- 185.1/332.0 MB 2.4 MB/s eta 0:01:01\n",
      "   ---------------------- ----------------- 185.6/332.0 MB 2.5 MB/s eta 0:00:58\n",
      "   ---------------------- ----------------- 186.6/332.0 MB 2.6 MB/s eta 0:00:57\n",
      "   ---------------------- ----------------- 187.2/332.0 MB 2.6 MB/s eta 0:00:57\n",
      "   ---------------------- ----------------- 187.7/332.0 MB 2.6 MB/s eta 0:00:57\n",
      "   ---------------------- ----------------- 188.0/332.0 MB 2.5 MB/s eta 0:00:57\n",
      "   ---------------------- ----------------- 188.2/332.0 MB 2.5 MB/s eta 0:00:57\n",
      "   ---------------------- ----------------- 189.3/332.0 MB 2.5 MB/s eta 0:00:57\n",
      "   ---------------------- ----------------- 190.3/332.0 MB 2.6 MB/s eta 0:00:56\n",
      "   ---------------------- ----------------- 190.6/332.0 MB 2.5 MB/s eta 0:00:56\n",
      "   ---------------------- ----------------- 190.8/332.0 MB 2.5 MB/s eta 0:00:56\n",
      "   ----------------------- ---------------- 191.1/332.0 MB 2.5 MB/s eta 0:00:56\n",
      "   ----------------------- ---------------- 191.6/332.0 MB 2.6 MB/s eta 0:00:55\n",
      "   ----------------------- ---------------- 191.9/332.0 MB 2.5 MB/s eta 0:00:56\n",
      "   ----------------------- ---------------- 191.9/332.0 MB 2.5 MB/s eta 0:00:56\n",
      "   ----------------------- ---------------- 191.9/332.0 MB 2.5 MB/s eta 0:00:56\n",
      "   ----------------------- ---------------- 191.9/332.0 MB 2.5 MB/s eta 0:00:56\n",
      "   ----------------------- ---------------- 192.4/332.0 MB 2.5 MB/s eta 0:00:57\n",
      "   ----------------------- ---------------- 192.7/332.0 MB 2.5 MB/s eta 0:00:57\n",
      "   ----------------------- ---------------- 192.7/332.0 MB 2.5 MB/s eta 0:00:57\n",
      "   ----------------------- ---------------- 192.9/332.0 MB 2.4 MB/s eta 0:00:57\n",
      "   ----------------------- ---------------- 192.9/332.0 MB 2.4 MB/s eta 0:00:57\n",
      "   ----------------------- ---------------- 193.5/332.0 MB 2.4 MB/s eta 0:00:58\n",
      "   ----------------------- ---------------- 194.0/332.0 MB 2.4 MB/s eta 0:00:57\n",
      "   ----------------------- ---------------- 194.2/332.0 MB 2.4 MB/s eta 0:00:57\n",
      "   ----------------------- ---------------- 194.2/332.0 MB 2.4 MB/s eta 0:00:57\n",
      "   ----------------------- ---------------- 195.3/332.0 MB 2.5 MB/s eta 0:00:56\n",
      "   ----------------------- ---------------- 197.4/332.0 MB 2.5 MB/s eta 0:00:54\n",
      "   ----------------------- ---------------- 197.7/332.0 MB 2.5 MB/s eta 0:00:54\n",
      "   ----------------------- ---------------- 197.9/332.0 MB 2.5 MB/s eta 0:00:54\n",
      "   ------------------------ --------------- 199.2/332.0 MB 2.5 MB/s eta 0:00:53\n",
      "   ------------------------ --------------- 200.8/332.0 MB 2.6 MB/s eta 0:00:51\n",
      "   ------------------------ --------------- 203.4/332.0 MB 2.6 MB/s eta 0:00:49\n",
      "   ------------------------ --------------- 204.7/332.0 MB 2.7 MB/s eta 0:00:48\n",
      "   ------------------------ --------------- 206.3/332.0 MB 2.7 MB/s eta 0:00:47\n",
      "   ------------------------ --------------- 207.1/332.0 MB 2.8 MB/s eta 0:00:45\n",
      "   ------------------------- -------------- 207.9/332.0 MB 2.8 MB/s eta 0:00:45\n",
      "   ------------------------- -------------- 208.4/332.0 MB 2.8 MB/s eta 0:00:45\n",
      "   ------------------------- -------------- 209.2/332.0 MB 2.8 MB/s eta 0:00:44\n",
      "   ------------------------- -------------- 210.0/332.0 MB 2.8 MB/s eta 0:00:44\n",
      "   ------------------------- -------------- 211.3/332.0 MB 2.8 MB/s eta 0:00:43\n",
      "   ------------------------- -------------- 211.8/332.0 MB 2.9 MB/s eta 0:00:42\n",
      "   ------------------------- -------------- 212.9/332.0 MB 2.9 MB/s eta 0:00:41\n",
      "   ------------------------- -------------- 213.6/332.0 MB 2.9 MB/s eta 0:00:41\n",
      "   ------------------------- -------------- 214.7/332.0 MB 2.9 MB/s eta 0:00:40\n",
      "   ------------------------- -------------- 215.5/332.0 MB 3.1 MB/s eta 0:00:38\n",
      "   -------------------------- ------------- 216.0/332.0 MB 3.1 MB/s eta 0:00:38\n",
      "   -------------------------- ------------- 216.0/332.0 MB 3.1 MB/s eta 0:00:38\n",
      "   -------------------------- ------------- 216.0/332.0 MB 3.1 MB/s eta 0:00:38\n",
      "   -------------------------- ------------- 216.8/332.0 MB 3.1 MB/s eta 0:00:38\n",
      "   -------------------------- ------------- 217.1/332.0 MB 3.0 MB/s eta 0:00:38\n",
      "   -------------------------- ------------- 217.6/332.0 MB 3.0 MB/s eta 0:00:38\n",
      "   -------------------------- ------------- 217.6/332.0 MB 3.0 MB/s eta 0:00:38\n",
      "   -------------------------- ------------- 218.1/332.0 MB 3.1 MB/s eta 0:00:37\n",
      "   -------------------------- ------------- 218.1/332.0 MB 3.1 MB/s eta 0:00:37\n",
      "   -------------------------- ------------- 218.4/332.0 MB 3.1 MB/s eta 0:00:38\n",
      "   -------------------------- ------------- 218.6/332.0 MB 3.1 MB/s eta 0:00:37\n",
      "   -------------------------- ------------- 219.9/332.0 MB 3.1 MB/s eta 0:00:37\n",
      "   -------------------------- ------------- 221.0/332.0 MB 3.1 MB/s eta 0:00:36\n",
      "   -------------------------- ------------- 222.0/332.0 MB 3.2 MB/s eta 0:00:35\n",
      "   -------------------------- ------------- 223.6/332.0 MB 3.2 MB/s eta 0:00:34\n",
      "   --------------------------- ------------ 225.4/332.0 MB 3.3 MB/s eta 0:00:33\n",
      "   --------------------------- ------------ 226.5/332.0 MB 3.3 MB/s eta 0:00:33\n",
      "   --------------------------- ------------ 227.5/332.0 MB 3.3 MB/s eta 0:00:32\n",
      "   --------------------------- ------------ 228.3/332.0 MB 3.3 MB/s eta 0:00:32\n",
      "   --------------------------- ------------ 229.4/332.0 MB 3.4 MB/s eta 0:00:31\n",
      "   --------------------------- ------------ 229.9/332.0 MB 3.4 MB/s eta 0:00:31\n",
      "   --------------------------- ------------ 230.7/332.0 MB 3.4 MB/s eta 0:00:30\n",
      "   --------------------------- ------------ 231.2/332.0 MB 3.4 MB/s eta 0:00:30\n",
      "   --------------------------- ------------ 231.7/332.0 MB 3.4 MB/s eta 0:00:30\n",
      "   ---------------------------- ----------- 232.5/332.0 MB 3.4 MB/s eta 0:00:29\n",
      "   ---------------------------- ----------- 233.6/332.0 MB 3.4 MB/s eta 0:00:29\n",
      "   ---------------------------- ----------- 234.1/332.0 MB 3.5 MB/s eta 0:00:29\n",
      "   ---------------------------- ----------- 234.9/332.0 MB 3.5 MB/s eta 0:00:28\n",
      "   ---------------------------- ----------- 235.4/332.0 MB 3.5 MB/s eta 0:00:28\n",
      "   ---------------------------- ----------- 235.7/332.0 MB 3.5 MB/s eta 0:00:28\n",
      "   ---------------------------- ----------- 235.9/332.0 MB 3.5 MB/s eta 0:00:28\n",
      "   ---------------------------- ----------- 236.2/332.0 MB 3.6 MB/s eta 0:00:27\n",
      "   ---------------------------- ----------- 236.5/332.0 MB 3.6 MB/s eta 0:00:27\n",
      "   ---------------------------- ----------- 236.7/332.0 MB 3.5 MB/s eta 0:00:27\n",
      "   ---------------------------- ----------- 237.0/332.0 MB 3.5 MB/s eta 0:00:27\n",
      "   ---------------------------- ----------- 237.5/332.0 MB 3.5 MB/s eta 0:00:27\n",
      "   ---------------------------- ----------- 238.0/332.0 MB 3.5 MB/s eta 0:00:27\n",
      "   ---------------------------- ----------- 238.0/332.0 MB 3.5 MB/s eta 0:00:27\n",
      "   ---------------------------- ----------- 238.3/332.0 MB 3.5 MB/s eta 0:00:27\n",
      "   ---------------------------- ----------- 238.6/332.0 MB 3.5 MB/s eta 0:00:27\n",
      "   ---------------------------- ----------- 239.3/332.0 MB 3.6 MB/s eta 0:00:26\n",
      "   ---------------------------- ----------- 239.9/332.0 MB 3.6 MB/s eta 0:00:26\n",
      "   ----------------------------- ---------- 241.2/332.0 MB 3.6 MB/s eta 0:00:26\n",
      "   ----------------------------- ---------- 241.7/332.0 MB 3.6 MB/s eta 0:00:25\n",
      "   ----------------------------- ---------- 241.7/332.0 MB 3.6 MB/s eta 0:00:25\n",
      "   ----------------------------- ---------- 242.2/332.0 MB 3.7 MB/s eta 0:00:25\n",
      "   ----------------------------- ---------- 242.5/332.0 MB 3.7 MB/s eta 0:00:25\n",
      "   ----------------------------- ---------- 242.5/332.0 MB 3.7 MB/s eta 0:00:25\n",
      "   ----------------------------- ---------- 242.5/332.0 MB 3.7 MB/s eta 0:00:25\n",
      "   ----------------------------- ---------- 242.5/332.0 MB 3.7 MB/s eta 0:00:25\n",
      "   ----------------------------- ---------- 242.5/332.0 MB 3.7 MB/s eta 0:00:25\n",
      "   ----------------------------- ---------- 242.5/332.0 MB 3.7 MB/s eta 0:00:25\n",
      "   ----------------------------- ---------- 242.5/332.0 MB 3.7 MB/s eta 0:00:25\n",
      "   ----------------------------- ---------- 242.5/332.0 MB 3.7 MB/s eta 0:00:25\n",
      "   ----------------------------- ---------- 242.5/332.0 MB 3.7 MB/s eta 0:00:25\n",
      "   ----------------------------- ---------- 246.2/332.0 MB 3.4 MB/s eta 0:00:26\n",
      "   ------------------------------ --------- 249.0/332.0 MB 3.4 MB/s eta 0:00:25\n",
      "   ------------------------------ --------- 251.7/332.0 MB 3.5 MB/s eta 0:00:24\n",
      "   ------------------------------ --------- 253.5/332.0 MB 3.5 MB/s eta 0:00:23\n",
      "   ------------------------------ --------- 255.6/332.0 MB 3.5 MB/s eta 0:00:22\n",
      "   ------------------------------- -------- 259.3/332.0 MB 3.6 MB/s eta 0:00:21\n",
      "   ------------------------------- -------- 261.9/332.0 MB 3.7 MB/s eta 0:00:20\n",
      "   ------------------------------- -------- 264.0/332.0 MB 3.7 MB/s eta 0:00:19\n",
      "   -------------------------------- ------- 266.6/332.0 MB 3.8 MB/s eta 0:00:18\n",
      "   -------------------------------- ------- 268.7/332.0 MB 3.8 MB/s eta 0:00:17\n",
      "   -------------------------------- ------- 270.5/332.0 MB 3.9 MB/s eta 0:00:16\n",
      "   -------------------------------- ------- 273.2/332.0 MB 3.9 MB/s eta 0:00:16\n",
      "   --------------------------------- ------ 276.0/332.0 MB 3.9 MB/s eta 0:00:15\n",
      "   --------------------------------- ------ 277.3/332.0 MB 4.0 MB/s eta 0:00:14\n",
      "   --------------------------------- ------ 280.2/332.0 MB 4.1 MB/s eta 0:00:13\n",
      "   --------------------------------- ------ 281.8/332.0 MB 4.1 MB/s eta 0:00:13\n",
      "   ---------------------------------- ----- 282.3/332.0 MB 4.1 MB/s eta 0:00:13\n",
      "   ---------------------------------- ----- 282.9/332.0 MB 4.1 MB/s eta 0:00:12\n",
      "   ---------------------------------- ----- 283.4/332.0 MB 4.1 MB/s eta 0:00:12\n",
      "   ---------------------------------- ----- 284.2/332.0 MB 4.2 MB/s eta 0:00:12\n",
      "   ---------------------------------- ----- 285.7/332.0 MB 4.2 MB/s eta 0:00:12\n",
      "   ---------------------------------- ----- 287.3/332.0 MB 4.2 MB/s eta 0:00:11\n",
      "   ---------------------------------- ----- 288.4/332.0 MB 4.3 MB/s eta 0:00:11\n",
      "   ---------------------------------- ----- 288.6/332.0 MB 4.3 MB/s eta 0:00:10\n",
      "   ---------------------------------- ----- 289.1/332.0 MB 4.3 MB/s eta 0:00:10\n",
      "   ----------------------------------- ---- 290.7/332.0 MB 4.3 MB/s eta 0:00:10\n",
      "   ----------------------------------- ---- 291.2/332.0 MB 4.3 MB/s eta 0:00:10\n",
      "   ----------------------------------- ---- 292.6/332.0 MB 4.2 MB/s eta 0:00:10\n",
      "   ----------------------------------- ---- 293.1/332.0 MB 4.2 MB/s eta 0:00:10\n",
      "   ----------------------------------- ---- 293.3/332.0 MB 4.2 MB/s eta 0:00:10\n",
      "   ----------------------------------- ---- 293.3/332.0 MB 4.2 MB/s eta 0:00:10\n",
      "   ----------------------------------- ---- 293.3/332.0 MB 4.2 MB/s eta 0:00:10\n",
      "   ----------------------------------- ---- 293.3/332.0 MB 4.2 MB/s eta 0:00:10\n",
      "   ----------------------------------- ---- 293.3/332.0 MB 4.2 MB/s eta 0:00:10\n",
      "   ----------------------------------- ---- 293.3/332.0 MB 4.2 MB/s eta 0:00:10\n",
      "   ----------------------------------- ---- 293.3/332.0 MB 4.2 MB/s eta 0:00:10\n",
      "   ----------------------------------- ---- 293.3/332.0 MB 4.2 MB/s eta 0:00:10\n",
      "   ----------------------------------- ---- 293.3/332.0 MB 4.2 MB/s eta 0:00:10\n",
      "   ----------------------------------- ---- 293.3/332.0 MB 4.2 MB/s eta 0:00:10\n",
      "   ----------------------------------- ---- 296.5/332.0 MB 3.8 MB/s eta 0:00:10\n",
      "   ----------------------------------- ---- 297.3/332.0 MB 3.8 MB/s eta 0:00:10\n",
      "   ----------------------------------- ---- 298.1/332.0 MB 3.8 MB/s eta 0:00:09\n",
      "   ------------------------------------ --- 299.1/332.0 MB 3.8 MB/s eta 0:00:09\n",
      "   ------------------------------------ --- 300.4/332.0 MB 3.8 MB/s eta 0:00:09\n",
      "   ------------------------------------ --- 301.7/332.0 MB 3.8 MB/s eta 0:00:08\n",
      "   ------------------------------------ --- 303.3/332.0 MB 3.9 MB/s eta 0:00:08\n",
      "   ------------------------------------ --- 305.1/332.0 MB 3.9 MB/s eta 0:00:07\n",
      "   ------------------------------------ --- 305.7/332.0 MB 3.9 MB/s eta 0:00:07\n",
      "   ------------------------------------ --- 306.4/332.0 MB 3.9 MB/s eta 0:00:07\n",
      "   ------------------------------------- -- 307.2/332.0 MB 3.9 MB/s eta 0:00:07\n",
      "   ------------------------------------- -- 308.3/332.0 MB 3.9 MB/s eta 0:00:07\n",
      "   ------------------------------------- -- 311.2/332.0 MB 4.0 MB/s eta 0:00:06\n",
      "   ------------------------------------- -- 312.7/332.0 MB 4.1 MB/s eta 0:00:05\n",
      "   -------------------------------------- - 315.6/332.0 MB 4.2 MB/s eta 0:00:04\n",
      "   -------------------------------------- - 317.5/332.0 MB 4.2 MB/s eta 0:00:04\n",
      "   -------------------------------------- - 319.0/332.0 MB 4.3 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 320.6/332.0 MB 4.4 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 321.9/332.0 MB 4.4 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 322.4/332.0 MB 4.4 MB/s eta 0:00:03\n",
      "   ---------------------------------------  324.0/332.0 MB 4.4 MB/s eta 0:00:02\n",
      "   ---------------------------------------  325.1/332.0 MB 4.5 MB/s eta 0:00:02\n",
      "   ---------------------------------------  326.4/332.0 MB 4.5 MB/s eta 0:00:02\n",
      "   ---------------------------------------  328.5/332.0 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  330.6/332.0 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  331.6/332.0 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  331.9/332.0 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  331.9/332.0 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  331.9/332.0 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  331.9/332.0 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  331.9/332.0 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  331.9/332.0 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 332.0/332.0 MB 4.5 MB/s  0:01:42\n",
      "Downloading grpcio-1.74.0-cp313-cp313-win_amd64.whl (4.5 MB)\n",
      "   ---------------------------------------- 0.0/4.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/4.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/4.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/4.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/4.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/4.5 MB ? eta -:--:--\n",
      "   --------- ------------------------------ 1.0/4.5 MB 9.6 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 1.6/4.5 MB 4.8 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 2.6/4.5 MB 4.1 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 2.9/4.5 MB 3.5 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 4.2/4.5 MB 4.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 4.5/4.5 MB 4.0 MB/s  0:00:02\n",
      "Downloading ml_dtypes-0.5.3-cp313-cp313-win_amd64.whl (208 kB)\n",
      "Using cached tensorboard-2.20.0-py3-none-any.whl (5.5 MB)\n",
      "Using cached tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Using cached absl_py-2.3.1-py3-none-any.whl (135 kB)\n",
      "Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Using cached wheel-0.45.1-py3-none-any.whl (72 kB)\n",
      "Using cached flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
      "Using cached gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Downloading h5py-3.14.0-cp313-cp313-win_amd64.whl (2.9 MB)\n",
      "   ---------------------------------------- 0.0/2.9 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 0.3/2.9 MB ? eta -:--:--\n",
      "   ------------------ --------------------- 1.3/2.9 MB 5.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 2.6/2.9 MB 5.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.9/2.9 MB 4.1 MB/s  0:00:00\n",
      "Downloading joblib-1.5.2-py3-none-any.whl (308 kB)\n",
      "Downloading keras-3.11.3-py3-none-any.whl (1.4 MB)\n",
      "   ---------------------------------------- 0.0/1.4 MB ? eta -:--:--\n",
      "   -------------- ------------------------- 0.5/1.4 MB 7.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.4/1.4 MB 5.0 MB/s  0:00:00\n",
      "Using cached libclang-18.1.1-py2.py3-none-win_amd64.whl (26.4 MB)\n",
      "Using cached markdown-3.9-py3-none-any.whl (107 kB)\n",
      "Using cached opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Downloading protobuf-6.32.1-cp310-abi3-win_amd64.whl (435 kB)\n",
      "Downloading scipy-1.16.2-cp313-cp313-win_amd64.whl (38.5 MB)\n",
      "   ---------------------------------------- 0.0/38.5 MB ? eta -:--:--\n",
      "   - -------------------------------------- 1.6/38.5 MB 7.5 MB/s eta 0:00:05\n",
      "   -- ------------------------------------- 2.1/38.5 MB 5.5 MB/s eta 0:00:07\n",
      "   -- ------------------------------------- 2.6/38.5 MB 4.4 MB/s eta 0:00:09\n",
      "   --- ------------------------------------ 3.1/38.5 MB 4.1 MB/s eta 0:00:09\n",
      "   ---- ----------------------------------- 4.2/38.5 MB 4.1 MB/s eta 0:00:09\n",
      "   ----- ---------------------------------- 5.0/38.5 MB 4.2 MB/s eta 0:00:09\n",
      "   ----- ---------------------------------- 5.8/38.5 MB 4.1 MB/s eta 0:00:09\n",
      "   ------ --------------------------------- 6.3/38.5 MB 3.9 MB/s eta 0:00:09\n",
      "   ------- -------------------------------- 7.1/38.5 MB 3.7 MB/s eta 0:00:09\n",
      "   ------- -------------------------------- 7.6/38.5 MB 3.7 MB/s eta 0:00:09\n",
      "   -------- ------------------------------- 8.4/38.5 MB 3.7 MB/s eta 0:00:09\n",
      "   -------- ------------------------------- 8.4/38.5 MB 3.7 MB/s eta 0:00:09\n",
      "   -------- ------------------------------- 8.7/38.5 MB 3.2 MB/s eta 0:00:10\n",
      "   -------- ------------------------------- 8.7/38.5 MB 3.2 MB/s eta 0:00:10\n",
      "   --------- ------------------------------ 8.9/38.5 MB 3.0 MB/s eta 0:00:11\n",
      "   --------- ------------------------------ 9.4/38.5 MB 2.9 MB/s eta 0:00:11\n",
      "   ---------- ----------------------------- 9.7/38.5 MB 2.8 MB/s eta 0:00:11\n",
      "   ---------- ----------------------------- 9.7/38.5 MB 2.8 MB/s eta 0:00:11\n",
      "   ---------- ----------------------------- 9.7/38.5 MB 2.8 MB/s eta 0:00:11\n",
      "   ---------- ----------------------------- 10.0/38.5 MB 2.3 MB/s eta 0:00:13\n",
      "   ---------- ----------------------------- 10.0/38.5 MB 2.3 MB/s eta 0:00:13\n",
      "   ---------- ----------------------------- 10.0/38.5 MB 2.3 MB/s eta 0:00:13\n",
      "   ---------- ----------------------------- 10.2/38.5 MB 2.1 MB/s eta 0:00:14\n",
      "   ---------- ----------------------------- 10.5/38.5 MB 2.1 MB/s eta 0:00:14\n",
      "   ----------- ---------------------------- 10.7/38.5 MB 2.1 MB/s eta 0:00:14\n",
      "   ----------- ---------------------------- 11.0/38.5 MB 2.0 MB/s eta 0:00:14\n",
      "   ----------- ---------------------------- 11.0/38.5 MB 2.0 MB/s eta 0:00:14\n",
      "   ----------- ---------------------------- 11.0/38.5 MB 2.0 MB/s eta 0:00:14\n",
      "   ------------ --------------------------- 12.1/38.5 MB 2.0 MB/s eta 0:00:14\n",
      "   ------------- -------------------------- 13.1/38.5 MB 2.1 MB/s eta 0:00:13\n",
      "   --------------- ------------------------ 14.7/38.5 MB 2.3 MB/s eta 0:00:11\n",
      "   ---------------- ----------------------- 15.7/38.5 MB 2.3 MB/s eta 0:00:10\n",
      "   ----------------- ---------------------- 17.3/38.5 MB 2.5 MB/s eta 0:00:09\n",
      "   ------------------- -------------------- 18.9/38.5 MB 2.7 MB/s eta 0:00:08\n",
      "   -------------------- ------------------- 19.9/38.5 MB 2.7 MB/s eta 0:00:07\n",
      "   --------------------- ------------------ 21.0/38.5 MB 2.8 MB/s eta 0:00:07\n",
      "   ---------------------- ----------------- 22.0/38.5 MB 2.9 MB/s eta 0:00:06\n",
      "   ----------------------- ---------------- 22.8/38.5 MB 2.9 MB/s eta 0:00:06\n",
      "   ------------------------ --------------- 23.9/38.5 MB 2.9 MB/s eta 0:00:05\n",
      "   ------------------------- -------------- 24.6/38.5 MB 3.0 MB/s eta 0:00:05\n",
      "   --------------------------- ------------ 26.2/38.5 MB 3.0 MB/s eta 0:00:05\n",
      "   --------------------------- ------------ 26.7/38.5 MB 3.0 MB/s eta 0:00:04\n",
      "   ---------------------------- ----------- 27.3/38.5 MB 3.0 MB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 28.0/38.5 MB 3.0 MB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 28.8/38.5 MB 3.1 MB/s eta 0:00:04\n",
      "   ------------------------------ --------- 29.4/38.5 MB 3.1 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 29.9/38.5 MB 3.1 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 30.7/38.5 MB 3.1 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 30.9/38.5 MB 3.1 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 30.9/38.5 MB 3.1 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 30.9/38.5 MB 3.1 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 30.9/38.5 MB 3.1 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 30.9/38.5 MB 3.1 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 30.9/38.5 MB 3.1 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 30.9/38.5 MB 3.1 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 30.9/38.5 MB 3.1 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 30.9/38.5 MB 3.1 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 30.9/38.5 MB 3.1 MB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 33.6/38.5 MB 2.7 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 34.9/38.5 MB 2.8 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 35.9/38.5 MB 2.8 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 36.4/38.5 MB 2.8 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 37.5/38.5 MB 2.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  38.3/38.5 MB 2.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 38.5/38.5 MB 2.9 MB/s  0:00:13\n",
      "Using cached setuptools-80.9.0-py3-none-any.whl (1.2 MB)\n",
      "Using cached termcolor-3.1.0-py3-none-any.whl (7.7 kB)\n",
      "Using cached threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Using cached werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "Using cached MarkupSafe-3.0.2-cp313-cp313-win_amd64.whl (15 kB)\n",
      "Downloading wrapt-1.17.3-cp313-cp313-win_amd64.whl (38 kB)\n",
      "Using cached namex-0.1.0-py3-none-any.whl (5.9 kB)\n",
      "Downloading optree-0.17.0-cp313-cp313-win_amd64.whl (316 kB)\n",
      "Downloading rich-14.1.0-py3-none-any.whl (243 kB)\n",
      "Downloading markdown_it_py-4.0.0-py3-none-any.whl (87 kB)\n",
      "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, wrapt, wheel, threadpoolctl, termcolor, tensorboard-data-server, setuptools, scipy, protobuf, optree, opt_einsum, ml_dtypes, mdurl, MarkupSafe, markdown, joblib, h5py, grpcio, google_pasta, gast, absl-py, werkzeug, scikit-learn, markdown-it-py, astunparse, tensorboard, rich, keras, tensorflow\n",
      "\n",
      "   - --------------------------------------  1/31 [libclang]\n",
      "   - --------------------------------------  1/31 [libclang]\n",
      "   - --------------------------------------  1/31 [libclang]\n",
      "   -- -------------------------------------  2/31 [flatbuffers]\n",
      "   --- ------------------------------------  3/31 [wrapt]\n",
      "   ----- ----------------------------------  4/31 [wheel]\n",
      "   ----- ----------------------------------  4/31 [wheel]\n",
      "   ----- ----------------------------------  4/31 [wheel]\n",
      "   ------ ---------------------------------  5/31 [threadpoolctl]\n",
      "   ---------- -----------------------------  8/31 [setuptools]\n",
      "   ---------- -----------------------------  8/31 [setuptools]\n",
      "   ---------- -----------------------------  8/31 [setuptools]\n",
      "   ---------- -----------------------------  8/31 [setuptools]\n",
      "   ---------- -----------------------------  8/31 [setuptools]\n",
      "   ---------- -----------------------------  8/31 [setuptools]\n",
      "   ---------- -----------------------------  8/31 [setuptools]\n",
      "   ---------- -----------------------------  8/31 [setuptools]\n",
      "   ---------- -----------------------------  8/31 [setuptools]\n",
      "   ---------- -----------------------------  8/31 [setuptools]\n",
      "   ---------- -----------------------------  8/31 [setuptools]\n",
      "   ---------- -----------------------------  8/31 [setuptools]\n",
      "   ---------- -----------------------------  8/31 [setuptools]\n",
      "   ---------- -----------------------------  8/31 [setuptools]\n",
      "   ---------- -----------------------------  8/31 [setuptools]\n",
      "   ---------- -----------------------------  8/31 [setuptools]\n",
      "   ---------- -----------------------------  8/31 [setuptools]\n",
      "   ---------- -----------------------------  8/31 [setuptools]\n",
      "   ---------- -----------------------------  8/31 [setuptools]\n",
      "   ---------- -----------------------------  8/31 [setuptools]\n",
      "   ---------- -----------------------------  8/31 [setuptools]\n",
      "   ---------- -----------------------------  8/31 [setuptools]\n",
      "   ---------- -----------------------------  8/31 [setuptools]\n",
      "   ---------- -----------------------------  8/31 [setuptools]\n",
      "   ---------- -----------------------------  8/31 [setuptools]\n",
      "   ---------- -----------------------------  8/31 [setuptools]\n",
      "   ---------- -----------------------------  8/31 [setuptools]\n",
      "   ---------- -----------------------------  8/31 [setuptools]\n",
      "   ---------- -----------------------------  8/31 [setuptools]\n",
      "   ---------- -----------------------------  8/31 [setuptools]\n",
      "   ---------- -----------------------------  8/31 [setuptools]\n",
      "   ---------- -----------------------------  8/31 [setuptools]\n",
      "   ---------- -----------------------------  8/31 [setuptools]\n",
      "   ---------- -----------------------------  8/31 [setuptools]\n",
      "   ---------- -----------------------------  8/31 [setuptools]\n",
      "   ---------- -----------------------------  8/31 [setuptools]\n",
      "   ---------- -----------------------------  8/31 [setuptools]\n",
      "   ---------- -----------------------------  8/31 [setuptools]\n",
      "   ---------- -----------------------------  8/31 [setuptools]\n",
      "   ---------- -----------------------------  8/31 [setuptools]\n",
      "   ---------- -----------------------------  8/31 [setuptools]\n",
      "   ---------- -----------------------------  8/31 [setuptools]\n",
      "   ---------- -----------------------------  8/31 [setuptools]\n",
      "   ---------- -----------------------------  8/31 [setuptools]\n",
      "   ---------- -----------------------------  8/31 [setuptools]\n",
      "   ---------- -----------------------------  8/31 [setuptools]\n",
      "   ---------- -----------------------------  8/31 [setuptools]\n",
      "   ---------- -----------------------------  8/31 [setuptools]\n",
      "   ---------- -----------------------------  8/31 [setuptools]\n",
      "   ----------- ----------------------------  9/31 [scipy]\n",
      "   ----------- ----------------------------  9/31 [scipy]\n",
      "   ----------- ----------------------------  9/31 [scipy]\n",
      "   ----------- ----------------------------  9/31 [scipy]\n",
      "   ----------- ----------------------------  9/31 [scipy]\n",
      "   ----------- ----------------------------  9/31 [scipy]\n",
      "   ----------- ----------------------------  9/31 [scipy]\n",
      "   ----------- ----------------------------  9/31 [scipy]\n",
      "   ----------- ----------------------------  9/31 [scipy]\n",
      "   ----------- ----------------------------  9/31 [scipy]\n",
      "   ----------- ----------------------------  9/31 [scipy]\n",
      "   ----------- ----------------------------  9/31 [scipy]\n",
      "   ----------- ----------------------------  9/31 [scipy]\n",
      "   ----------- ----------------------------  9/31 [scipy]\n",
      "   ----------- ----------------------------  9/31 [scipy]\n",
      "   ----------- ----------------------------  9/31 [scipy]\n",
      "   ----------- ----------------------------  9/31 [scipy]\n",
      "   ----------- ----------------------------  9/31 [scipy]\n",
      "   ----------- ----------------------------  9/31 [scipy]\n",
      "   ----------- ----------------------------  9/31 [scipy]\n",
      "   ----------- ----------------------------  9/31 [scipy]\n",
      "   ----------- ----------------------------  9/31 [scipy]\n",
      "   ----------- ----------------------------  9/31 [scipy]\n",
      "   ----------- ----------------------------  9/31 [scipy]\n",
      "   ----------- ----------------------------  9/31 [scipy]\n",
      "   ----------- ----------------------------  9/31 [scipy]\n",
      "   ----------- ----------------------------  9/31 [scipy]\n",
      "   ----------- ----------------------------  9/31 [scipy]\n",
      "   ----------- ----------------------------  9/31 [scipy]\n",
      "   ----------- ----------------------------  9/31 [scipy]\n",
      "   ----------- ----------------------------  9/31 [scipy]\n",
      "   ----------- ----------------------------  9/31 [scipy]\n",
      "   ----------- ----------------------------  9/31 [scipy]\n",
      "   ----------- ----------------------------  9/31 [scipy]\n",
      "   ----------- ----------------------------  9/31 [scipy]\n",
      "   ----------- ----------------------------  9/31 [scipy]\n",
      "   ----------- ----------------------------  9/31 [scipy]\n",
      "   ----------- ----------------------------  9/31 [scipy]\n",
      "   ----------- ----------------------------  9/31 [scipy]\n",
      "   ----------- ----------------------------  9/31 [scipy]\n",
      "   ----------- ----------------------------  9/31 [scipy]\n",
      "   ----------- ----------------------------  9/31 [scipy]\n",
      "   ----------- ----------------------------  9/31 [scipy]\n",
      "   ----------- ----------------------------  9/31 [scipy]\n",
      "   ----------- ----------------------------  9/31 [scipy]\n",
      "   ----------- ----------------------------  9/31 [scipy]\n",
      "   ----------- ----------------------------  9/31 [scipy]\n",
      "   ----------- ----------------------------  9/31 [scipy]\n",
      "   ----------- ----------------------------  9/31 [scipy]\n",
      "   ----------- ----------------------------  9/31 [scipy]\n",
      "   ----------- ----------------------------  9/31 [scipy]\n",
      "   ----------- ----------------------------  9/31 [scipy]\n",
      "   ----------- ----------------------------  9/31 [scipy]\n",
      "   ----------- ----------------------------  9/31 [scipy]\n",
      "   ----------- ----------------------------  9/31 [scipy]\n",
      "   ----------- ----------------------------  9/31 [scipy]\n",
      "   ----------- ----------------------------  9/31 [scipy]\n",
      "   ----------- ----------------------------  9/31 [scipy]\n",
      "   ----------- ----------------------------  9/31 [scipy]\n",
      "   ----------- ----------------------------  9/31 [scipy]\n",
      "   ----------- ----------------------------  9/31 [scipy]\n",
      "   ----------- ----------------------------  9/31 [scipy]\n",
      "   ----------- ----------------------------  9/31 [scipy]\n",
      "   ----------- ----------------------------  9/31 [scipy]\n",
      "   ----------- ----------------------------  9/31 [scipy]\n",
      "   ----------- ----------------------------  9/31 [scipy]\n",
      "   ----------- ----------------------------  9/31 [scipy]\n",
      "   ----------- ----------------------------  9/31 [scipy]\n",
      "   ----------- ----------------------------  9/31 [scipy]\n",
      "   ----------- ----------------------------  9/31 [scipy]\n",
      "   ----------- ----------------------------  9/31 [scipy]\n",
      "   ----------- ----------------------------  9/31 [scipy]\n",
      "   ----------- ----------------------------  9/31 [scipy]\n",
      "   ----------- ----------------------------  9/31 [scipy]\n",
      "   ----------- ----------------------------  9/31 [scipy]\n",
      "   ----------- ----------------------------  9/31 [scipy]\n",
      "   ----------- ----------------------------  9/31 [scipy]\n",
      "   ----------- ----------------------------  9/31 [scipy]\n",
      "   ----------- ----------------------------  9/31 [scipy]\n",
      "   ----------- ----------------------------  9/31 [scipy]\n",
      "   ----------- ----------------------------  9/31 [scipy]\n",
      "   ----------- ----------------------------  9/31 [scipy]\n",
      "   ----------- ----------------------------  9/31 [scipy]\n",
      "   ----------- ----------------------------  9/31 [scipy]\n",
      "   ----------- ----------------------------  9/31 [scipy]\n",
      "   ----------- ----------------------------  9/31 [scipy]\n",
      "   ----------- ----------------------------  9/31 [scipy]\n",
      "   ----------- ----------------------------  9/31 [scipy]\n",
      "   ----------- ----------------------------  9/31 [scipy]\n",
      "   ----------- ----------------------------  9/31 [scipy]\n",
      "   ----------- ----------------------------  9/31 [scipy]\n",
      "   ----------- ----------------------------  9/31 [scipy]\n",
      "   ----------- ----------------------------  9/31 [scipy]\n",
      "   ----------- ----------------------------  9/31 [scipy]\n",
      "   ----------- ----------------------------  9/31 [scipy]\n",
      "   ----------- ----------------------------  9/31 [scipy]\n",
      "   ----------- ----------------------------  9/31 [scipy]\n",
      "   ----------- ----------------------------  9/31 [scipy]\n",
      "   ----------- ----------------------------  9/31 [scipy]\n",
      "   ----------- ----------------------------  9/31 [scipy]\n",
      "   ----------- ----------------------------  9/31 [scipy]\n",
      "   ----------- ----------------------------  9/31 [scipy]\n",
      "   ----------- ----------------------------  9/31 [scipy]\n",
      "   ----------- ----------------------------  9/31 [scipy]\n",
      "   ----------- ----------------------------  9/31 [scipy]\n",
      "   ----------- ----------------------------  9/31 [scipy]\n",
      "   ----------- ----------------------------  9/31 [scipy]\n",
      "   ----------- ----------------------------  9/31 [scipy]\n",
      "   ----------- ----------------------------  9/31 [scipy]\n",
      "   ----------- ----------------------------  9/31 [scipy]\n",
      "   ----------- ----------------------------  9/31 [scipy]\n",
      "   ----------- ----------------------------  9/31 [scipy]\n",
      "   ----------- ----------------------------  9/31 [scipy]\n",
      "   ----------- ----------------------------  9/31 [scipy]\n",
      "   ----------- ----------------------------  9/31 [scipy]\n",
      "   ----------- ----------------------------  9/31 [scipy]\n",
      "   ----------- ----------------------------  9/31 [scipy]\n",
      "   ----------- ----------------------------  9/31 [scipy]\n",
      "   ----------- ----------------------------  9/31 [scipy]\n",
      "   ----------- ----------------------------  9/31 [scipy]\n",
      "   ----------- ----------------------------  9/31 [scipy]\n",
      "   ----------- ----------------------------  9/31 [scipy]\n",
      "   ----------- ----------------------------  9/31 [scipy]\n",
      "   ----------- ----------------------------  9/31 [scipy]\n",
      "   ----------- ----------------------------  9/31 [scipy]\n",
      "   ----------- ----------------------------  9/31 [scipy]\n",
      "   ----------- ----------------------------  9/31 [scipy]\n",
      "   ----------- ----------------------------  9/31 [scipy]\n",
      "   ----------- ----------------------------  9/31 [scipy]\n",
      "   ----------- ----------------------------  9/31 [scipy]\n",
      "   ----------- ----------------------------  9/31 [scipy]\n",
      "   ----------- ----------------------------  9/31 [scipy]\n",
      "   ----------- ----------------------------  9/31 [scipy]\n",
      "   ----------- ----------------------------  9/31 [scipy]\n",
      "   ----------- ----------------------------  9/31 [scipy]\n",
      "   ----------- ----------------------------  9/31 [scipy]\n",
      "   ----------- ----------------------------  9/31 [scipy]\n",
      "   ----------- ----------------------------  9/31 [scipy]\n",
      "   ----------- ----------------------------  9/31 [scipy]\n",
      "   ----------- ----------------------------  9/31 [scipy]\n",
      "   ----------- ----------------------------  9/31 [scipy]\n",
      "   ----------- ----------------------------  9/31 [scipy]\n",
      "   ----------- ----------------------------  9/31 [scipy]\n",
      "   ----------- ----------------------------  9/31 [scipy]\n",
      "   ----------- ----------------------------  9/31 [scipy]\n",
      "   ----------- ----------------------------  9/31 [scipy]\n",
      "   ----------- ----------------------------  9/31 [scipy]\n",
      "   ----------- ----------------------------  9/31 [scipy]\n",
      "   ----------- ----------------------------  9/31 [scipy]\n",
      "   ----------- ----------------------------  9/31 [scipy]\n",
      "   ----------- ----------------------------  9/31 [scipy]\n",
      "   ----------- ----------------------------  9/31 [scipy]\n",
      "   ----------- ----------------------------  9/31 [scipy]\n",
      "   ----------- ----------------------------  9/31 [scipy]\n",
      "   ----------- ----------------------------  9/31 [scipy]\n",
      "   ----------- ----------------------------  9/31 [scipy]\n",
      "   ----------- ----------------------------  9/31 [scipy]\n",
      "   ------------ --------------------------- 10/31 [protobuf]\n",
      "   ------------ --------------------------- 10/31 [protobuf]\n",
      "   ------------ --------------------------- 10/31 [protobuf]\n",
      "   ------------ --------------------------- 10/31 [protobuf]\n",
      "   ------------ --------------------------- 10/31 [protobuf]\n",
      "   ------------ --------------------------- 10/31 [protobuf]\n",
      "   ------------ --------------------------- 10/31 [protobuf]\n",
      "   ------------ --------------------------- 10/31 [protobuf]\n",
      "   ------------ --------------------------- 10/31 [protobuf]\n",
      "   -------------- ------------------------- 11/31 [optree]\n",
      "   -------------- ------------------------- 11/31 [optree]\n",
      "   -------------- ------------------------- 11/31 [optree]\n",
      "   --------------- ------------------------ 12/31 [opt_einsum]\n",
      "   --------------- ------------------------ 12/31 [opt_einsum]\n",
      "   ---------------- ----------------------- 13/31 [ml_dtypes]\n",
      "   ------------------ --------------------- 14/31 [mdurl]\n",
      "   -------------------- ------------------- 16/31 [markdown]\n",
      "   -------------------- ------------------- 16/31 [markdown]\n",
      "   -------------------- ------------------- 16/31 [markdown]\n",
      "   -------------------- ------------------- 16/31 [markdown]\n",
      "   -------------------- ------------------- 16/31 [markdown]\n",
      "   --------------------- ------------------ 17/31 [joblib]\n",
      "   --------------------- ------------------ 17/31 [joblib]\n",
      "   --------------------- ------------------ 17/31 [joblib]\n",
      "   --------------------- ------------------ 17/31 [joblib]\n",
      "   --------------------- ------------------ 17/31 [joblib]\n",
      "   --------------------- ------------------ 17/31 [joblib]\n",
      "   --------------------- ------------------ 17/31 [joblib]\n",
      "   --------------------- ------------------ 17/31 [joblib]\n",
      "   --------------------- ------------------ 17/31 [joblib]\n",
      "   --------------------- ------------------ 17/31 [joblib]\n",
      "   ----------------------- ---------------- 18/31 [h5py]\n",
      "   ----------------------- ---------------- 18/31 [h5py]\n",
      "   ----------------------- ---------------- 18/31 [h5py]\n",
      "   ----------------------- ---------------- 18/31 [h5py]\n",
      "   ----------------------- ---------------- 18/31 [h5py]\n",
      "   ----------------------- ---------------- 18/31 [h5py]\n",
      "   ----------------------- ---------------- 18/31 [h5py]\n",
      "   ------------------------ --------------- 19/31 [grpcio]\n",
      "   ------------------------ --------------- 19/31 [grpcio]\n",
      "   ------------------------ --------------- 19/31 [grpcio]\n",
      "   ------------------------ --------------- 19/31 [grpcio]\n",
      "   ------------------------ --------------- 19/31 [grpcio]\n",
      "   ------------------------ --------------- 19/31 [grpcio]\n",
      "   ------------------------ --------------- 19/31 [grpcio]\n",
      "   ------------------------ --------------- 19/31 [grpcio]\n",
      "   ------------------------- -------------- 20/31 [google_pasta]\n",
      "   ------------------------- -------------- 20/31 [google_pasta]\n",
      "   ------------------------- -------------- 20/31 [google_pasta]\n",
      "   --------------------------- ------------ 21/31 [gast]\n",
      "   ---------------------------- ----------- 22/31 [absl-py]\n",
      "   ---------------------------- ----------- 22/31 [absl-py]\n",
      "   ---------------------------- ----------- 22/31 [absl-py]\n",
      "   ----------------------------- ---------- 23/31 [werkzeug]\n",
      "   ----------------------------- ---------- 23/31 [werkzeug]\n",
      "   ----------------------------- ---------- 23/31 [werkzeug]\n",
      "   ----------------------------- ---------- 23/31 [werkzeug]\n",
      "   ----------------------------- ---------- 23/31 [werkzeug]\n",
      "   ----------------------------- ---------- 23/31 [werkzeug]\n",
      "   ----------------------------- ---------- 23/31 [werkzeug]\n",
      "   ----------------------------- ---------- 23/31 [werkzeug]\n",
      "   ----------------------------- ---------- 23/31 [werkzeug]\n",
      "   ------------------------------ --------- 24/31 [scikit-learn]\n",
      "   ------------------------------ --------- 24/31 [scikit-learn]\n",
      "   ------------------------------ --------- 24/31 [scikit-learn]\n",
      "   ------------------------------ --------- 24/31 [scikit-learn]\n",
      "   ------------------------------ --------- 24/31 [scikit-learn]\n",
      "   ------------------------------ --------- 24/31 [scikit-learn]\n",
      "   ------------------------------ --------- 24/31 [scikit-learn]\n",
      "   ------------------------------ --------- 24/31 [scikit-learn]\n",
      "   ------------------------------ --------- 24/31 [scikit-learn]\n",
      "   ------------------------------ --------- 24/31 [scikit-learn]\n",
      "   ------------------------------ --------- 24/31 [scikit-learn]\n",
      "   ------------------------------ --------- 24/31 [scikit-learn]\n",
      "   ------------------------------ --------- 24/31 [scikit-learn]\n",
      "   ------------------------------ --------- 24/31 [scikit-learn]\n",
      "   ------------------------------ --------- 24/31 [scikit-learn]\n",
      "   ------------------------------ --------- 24/31 [scikit-learn]\n",
      "   ------------------------------ --------- 24/31 [scikit-learn]\n",
      "   ------------------------------ --------- 24/31 [scikit-learn]\n",
      "   ------------------------------ --------- 24/31 [scikit-learn]\n",
      "   ------------------------------ --------- 24/31 [scikit-learn]\n",
      "   ------------------------------ --------- 24/31 [scikit-learn]\n",
      "   ------------------------------ --------- 24/31 [scikit-learn]\n",
      "   ------------------------------ --------- 24/31 [scikit-learn]\n",
      "   ------------------------------ --------- 24/31 [scikit-learn]\n",
      "   ------------------------------ --------- 24/31 [scikit-learn]\n",
      "   ------------------------------ --------- 24/31 [scikit-learn]\n",
      "   ------------------------------ --------- 24/31 [scikit-learn]\n",
      "   ------------------------------ --------- 24/31 [scikit-learn]\n",
      "   ------------------------------ --------- 24/31 [scikit-learn]\n",
      "   ------------------------------ --------- 24/31 [scikit-learn]\n",
      "   ------------------------------ --------- 24/31 [scikit-learn]\n",
      "   ------------------------------ --------- 24/31 [scikit-learn]\n",
      "   ------------------------------ --------- 24/31 [scikit-learn]\n",
      "   ------------------------------ --------- 24/31 [scikit-learn]\n",
      "   ------------------------------ --------- 24/31 [scikit-learn]\n",
      "   ------------------------------ --------- 24/31 [scikit-learn]\n",
      "   ------------------------------ --------- 24/31 [scikit-learn]\n",
      "   ------------------------------ --------- 24/31 [scikit-learn]\n",
      "   ------------------------------ --------- 24/31 [scikit-learn]\n",
      "   ------------------------------ --------- 24/31 [scikit-learn]\n",
      "   ------------------------------ --------- 24/31 [scikit-learn]\n",
      "   ------------------------------ --------- 24/31 [scikit-learn]\n",
      "   ------------------------------ --------- 24/31 [scikit-learn]\n",
      "   ------------------------------ --------- 24/31 [scikit-learn]\n",
      "   ------------------------------ --------- 24/31 [scikit-learn]\n",
      "   ------------------------------ --------- 24/31 [scikit-learn]\n",
      "   ------------------------------ --------- 24/31 [scikit-learn]\n",
      "   ------------------------------ --------- 24/31 [scikit-learn]\n",
      "   ------------------------------ --------- 24/31 [scikit-learn]\n",
      "   ------------------------------ --------- 24/31 [scikit-learn]\n",
      "   ------------------------------ --------- 24/31 [scikit-learn]\n",
      "   ------------------------------ --------- 24/31 [scikit-learn]\n",
      "   ------------------------------ --------- 24/31 [scikit-learn]\n",
      "   ------------------------------ --------- 24/31 [scikit-learn]\n",
      "   ------------------------------ --------- 24/31 [scikit-learn]\n",
      "   ------------------------------ --------- 24/31 [scikit-learn]\n",
      "   ------------------------------ --------- 24/31 [scikit-learn]\n",
      "   ------------------------------ --------- 24/31 [scikit-learn]\n",
      "   ------------------------------ --------- 24/31 [scikit-learn]\n",
      "   ------------------------------ --------- 24/31 [scikit-learn]\n",
      "   ------------------------------ --------- 24/31 [scikit-learn]\n",
      "   ------------------------------ --------- 24/31 [scikit-learn]\n",
      "   ------------------------------ --------- 24/31 [scikit-learn]\n",
      "   ------------------------------ --------- 24/31 [scikit-learn]\n",
      "   ------------------------------ --------- 24/31 [scikit-learn]\n",
      "   ------------------------------ --------- 24/31 [scikit-learn]\n",
      "   ------------------------------ --------- 24/31 [scikit-learn]\n",
      "   ------------------------------ --------- 24/31 [scikit-learn]\n",
      "   ------------------------------ --------- 24/31 [scikit-learn]\n",
      "   ------------------------------ --------- 24/31 [scikit-learn]\n",
      "   ------------------------------ --------- 24/31 [scikit-learn]\n",
      "   ------------------------------ --------- 24/31 [scikit-learn]\n",
      "   ------------------------------ --------- 24/31 [scikit-learn]\n",
      "   ------------------------------ --------- 24/31 [scikit-learn]\n",
      "   ------------------------------ --------- 24/31 [scikit-learn]\n",
      "   ------------------------------ --------- 24/31 [scikit-learn]\n",
      "   ------------------------------ --------- 24/31 [scikit-learn]\n",
      "   ------------------------------ --------- 24/31 [scikit-learn]\n",
      "   ------------------------------ --------- 24/31 [scikit-learn]\n",
      "   ------------------------------ --------- 24/31 [scikit-learn]\n",
      "   ------------------------------ --------- 24/31 [scikit-learn]\n",
      "   ------------------------------ --------- 24/31 [scikit-learn]\n",
      "   ------------------------------ --------- 24/31 [scikit-learn]\n",
      "   ------------------------------ --------- 24/31 [scikit-learn]\n",
      "   ------------------------------ --------- 24/31 [scikit-learn]\n",
      "   ------------------------------ --------- 24/31 [scikit-learn]\n",
      "   ------------------------------ --------- 24/31 [scikit-learn]\n",
      "   ------------------------------ --------- 24/31 [scikit-learn]\n",
      "   ------------------------------ --------- 24/31 [scikit-learn]\n",
      "   ------------------------------ --------- 24/31 [scikit-learn]\n",
      "   ------------------------------ --------- 24/31 [scikit-learn]\n",
      "   ------------------------------ --------- 24/31 [scikit-learn]\n",
      "   ------------------------------ --------- 24/31 [scikit-learn]\n",
      "   ------------------------------ --------- 24/31 [scikit-learn]\n",
      "   ------------------------------ --------- 24/31 [scikit-learn]\n",
      "   ------------------------------ --------- 24/31 [scikit-learn]\n",
      "   ------------------------------ --------- 24/31 [scikit-learn]\n",
      "   ------------------------------ --------- 24/31 [scikit-learn]\n",
      "   -------------------------------- ------- 25/31 [markdown-it-py]\n",
      "   -------------------------------- ------- 25/31 [markdown-it-py]\n",
      "   -------------------------------- ------- 25/31 [markdown-it-py]\n",
      "   -------------------------------- ------- 25/31 [markdown-it-py]\n",
      "   -------------------------------- ------- 25/31 [markdown-it-py]\n",
      "   -------------------------------- ------- 25/31 [markdown-it-py]\n",
      "   -------------------------------- ------- 25/31 [markdown-it-py]\n",
      "   -------------------------------- ------- 25/31 [markdown-it-py]\n",
      "   -------------------------------- ------- 25/31 [markdown-it-py]\n",
      "   --------------------------------- ------ 26/31 [astunparse]\n",
      "   ---------------------------------- ----- 27/31 [tensorboard]\n",
      "   ---------------------------------- ----- 27/31 [tensorboard]\n",
      "   ---------------------------------- ----- 27/31 [tensorboard]\n",
      "   ---------------------------------- ----- 27/31 [tensorboard]\n",
      "   ---------------------------------- ----- 27/31 [tensorboard]\n",
      "   ---------------------------------- ----- 27/31 [tensorboard]\n",
      "   ---------------------------------- ----- 27/31 [tensorboard]\n",
      "   ---------------------------------- ----- 27/31 [tensorboard]\n",
      "   ---------------------------------- ----- 27/31 [tensorboard]\n",
      "   ---------------------------------- ----- 27/31 [tensorboard]\n",
      "   ---------------------------------- ----- 27/31 [tensorboard]\n",
      "   ---------------------------------- ----- 27/31 [tensorboard]\n",
      "   ---------------------------------- ----- 27/31 [tensorboard]\n",
      "   ---------------------------------- ----- 27/31 [tensorboard]\n",
      "   ---------------------------------- ----- 27/31 [tensorboard]\n",
      "   ---------------------------------- ----- 27/31 [tensorboard]\n",
      "   ---------------------------------- ----- 27/31 [tensorboard]\n",
      "   ---------------------------------- ----- 27/31 [tensorboard]\n",
      "   ---------------------------------- ----- 27/31 [tensorboard]\n",
      "   ---------------------------------- ----- 27/31 [tensorboard]\n",
      "   ---------------------------------- ----- 27/31 [tensorboard]\n",
      "   ---------------------------------- ----- 27/31 [tensorboard]\n",
      "   ---------------------------------- ----- 27/31 [tensorboard]\n",
      "   ---------------------------------- ----- 27/31 [tensorboard]\n",
      "   ---------------------------------- ----- 27/31 [tensorboard]\n",
      "   ---------------------------------- ----- 27/31 [tensorboard]\n",
      "   ---------------------------------- ----- 27/31 [tensorboard]\n",
      "   ---------------------------------- ----- 27/31 [tensorboard]\n",
      "   ---------------------------------- ----- 27/31 [tensorboard]\n",
      "   ---------------------------------- ----- 27/31 [tensorboard]\n",
      "   ---------------------------------- ----- 27/31 [tensorboard]\n",
      "   ---------------------------------- ----- 27/31 [tensorboard]\n",
      "   ------------------------------------ --- 28/31 [rich]\n",
      "   ------------------------------------ --- 28/31 [rich]\n",
      "   ------------------------------------ --- 28/31 [rich]\n",
      "   ------------------------------------ --- 28/31 [rich]\n",
      "   ------------------------------------ --- 28/31 [rich]\n",
      "   ------------------------------------ --- 28/31 [rich]\n",
      "   ------------------------------------ --- 28/31 [rich]\n",
      "   ------------------------------------ --- 28/31 [rich]\n",
      "   ------------------------------------ --- 28/31 [rich]\n",
      "   ------------------------------------ --- 28/31 [rich]\n",
      "   ------------------------------------ --- 28/31 [rich]\n",
      "   ------------------------------------ --- 28/31 [rich]\n",
      "   ------------------------------------- -- 29/31 [keras]\n",
      "   ------------------------------------- -- 29/31 [keras]\n",
      "   ------------------------------------- -- 29/31 [keras]\n",
      "   ------------------------------------- -- 29/31 [keras]\n",
      "   ------------------------------------- -- 29/31 [keras]\n",
      "   ------------------------------------- -- 29/31 [keras]\n",
      "   ------------------------------------- -- 29/31 [keras]\n",
      "   ------------------------------------- -- 29/31 [keras]\n",
      "   ------------------------------------- -- 29/31 [keras]\n",
      "   ------------------------------------- -- 29/31 [keras]\n",
      "   ------------------------------------- -- 29/31 [keras]\n",
      "   ------------------------------------- -- 29/31 [keras]\n",
      "   ------------------------------------- -- 29/31 [keras]\n",
      "   ------------------------------------- -- 29/31 [keras]\n",
      "   ------------------------------------- -- 29/31 [keras]\n",
      "   ------------------------------------- -- 29/31 [keras]\n",
      "   ------------------------------------- -- 29/31 [keras]\n",
      "   ------------------------------------- -- 29/31 [keras]\n",
      "   ------------------------------------- -- 29/31 [keras]\n",
      "   ------------------------------------- -- 29/31 [keras]\n",
      "   ------------------------------------- -- 29/31 [keras]\n",
      "   ------------------------------------- -- 29/31 [keras]\n",
      "   ------------------------------------- -- 29/31 [keras]\n",
      "   ------------------------------------- -- 29/31 [keras]\n",
      "   ------------------------------------- -- 29/31 [keras]\n",
      "   ------------------------------------- -- 29/31 [keras]\n",
      "   ------------------------------------- -- 29/31 [keras]\n",
      "   ------------------------------------- -- 29/31 [keras]\n",
      "   ------------------------------------- -- 29/31 [keras]\n",
      "   ------------------------------------- -- 29/31 [keras]\n",
      "   ------------------------------------- -- 29/31 [keras]\n",
      "   ------------------------------------- -- 29/31 [keras]\n",
      "   ------------------------------------- -- 29/31 [keras]\n",
      "   ------------------------------------- -- 29/31 [keras]\n",
      "   ------------------------------------- -- 29/31 [keras]\n",
      "   ------------------------------------- -- 29/31 [keras]\n",
      "   ------------------------------------- -- 29/31 [keras]\n",
      "   ------------------------------------- -- 29/31 [keras]\n",
      "   ------------------------------------- -- 29/31 [keras]\n",
      "   ------------------------------------- -- 29/31 [keras]\n",
      "   ------------------------------------- -- 29/31 [keras]\n",
      "   ------------------------------------- -- 29/31 [keras]\n",
      "   ------------------------------------- -- 29/31 [keras]\n",
      "   ------------------------------------- -- 29/31 [keras]\n",
      "   ------------------------------------- -- 29/31 [keras]\n",
      "   ------------------------------------- -- 29/31 [keras]\n",
      "   ------------------------------------- -- 29/31 [keras]\n",
      "   ------------------------------------- -- 29/31 [keras]\n",
      "   ------------------------------------- -- 29/31 [keras]\n",
      "   ------------------------------------- -- 29/31 [keras]\n",
      "   ------------------------------------- -- 29/31 [keras]\n",
      "   ------------------------------------- -- 29/31 [keras]\n",
      "   ------------------------------------- -- 29/31 [keras]\n",
      "   ------------------------------------- -- 29/31 [keras]\n",
      "   ------------------------------------- -- 29/31 [keras]\n",
      "   ------------------------------------- -- 29/31 [keras]\n",
      "   ------------------------------------- -- 29/31 [keras]\n",
      "   ------------------------------------- -- 29/31 [keras]\n",
      "   ------------------------------------- -- 29/31 [keras]\n",
      "   ------------------------------------- -- 29/31 [keras]\n",
      "   ------------------------------------- -- 29/31 [keras]\n",
      "   ------------------------------------- -- 29/31 [keras]\n",
      "   ------------------------------------- -- 29/31 [keras]\n",
      "   ------------------------------------- -- 29/31 [keras]\n",
      "   ------------------------------------- -- 29/31 [keras]\n",
      "   ------------------------------------- -- 29/31 [keras]\n",
      "   ------------------------------------- -- 29/31 [keras]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   -------------------------------------- - 30/31 [tensorflow]\n",
      "   ---------------------------------------- 31/31 [tensorflow]\n",
      "\n",
      "Successfully installed MarkupSafe-3.0.2 absl-py-2.3.1 astunparse-1.6.3 flatbuffers-25.2.10 gast-0.6.0 google_pasta-0.2.0 grpcio-1.74.0 h5py-3.14.0 joblib-1.5.2 keras-3.11.3 libclang-18.1.1 markdown-3.9 markdown-it-py-4.0.0 mdurl-0.1.2 ml_dtypes-0.5.3 namex-0.1.0 opt_einsum-3.4.0 optree-0.17.0 protobuf-6.32.1 rich-14.1.0 scikit-learn-1.7.2 scipy-1.16.2 setuptools-80.9.0 tensorboard-2.20.0 tensorboard-data-server-0.7.2 tensorflow-2.20.0 termcolor-3.1.0 threadpoolctl-3.6.0 werkzeug-3.1.3 wheel-0.45.1 wrapt-1.17.3\n"
     ]
    }
   ],
   "source": [
    "# # Python 3.13 실행 경로 확인\n",
    "# !which python\n",
    "\n",
    "# # 라이브러리 설치 (Python 3.13 전용)\n",
    "# !C:/Users/EL044/AppData/Local/Programs/Python/Python313/python.exe -m pip install --upgrade pip\n",
    "# !C:/Users/EL044/AppData/Local/Programs/Python/Python313/python.exe -m pip install numpy pandas scikit-learn tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "57e2fef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras import layers, models, callbacks\n",
    "\n",
    "FEATS = [\n",
    "    'payload.size','payload.distinct_size',\n",
    "    'f_commits_n','f_commits_n_distinct','f_commits_avg_msg_len','f_commits_max_msg_len',\n",
    "    'f_issue_labels_n','f_pr_labels_n','f_payload.issue.assignees_n',\n",
    "    'f_payload.pull_request.assignees_n','f_payload.pull_request.requested_reviewers_n',\n",
    "    'f_payload.pull_request.head.repo.topics_n','f_payload.pull_request.base.repo.topics_n',\n",
    "    'f_release_assets_n','f_release_assets_total_size','f_pages_n',\n",
    "    'f_release_mentions_n','f_app_events_n'\n",
    "]\n",
    "TIME_COL = 'created_at'\n",
    "\n",
    "def prepare_hourly(df):\n",
    "    d = df.copy()\n",
    "    d[TIME_COL] = pd.to_datetime(d[TIME_COL], utc=True, errors='coerce')\n",
    "    d = d.dropna(subset=[TIME_COL]).sort_values(TIME_COL)\n",
    "    num_feats = [c for c in FEATS if c in d.columns and pd.api.types.is_numeric_dtype(d[c])]\n",
    "    d = d[[TIME_COL] + num_feats].copy()\n",
    "    d['hour'] = d[TIME_COL].dt.floor('H')\n",
    "    hourly = d.groupby('hour', as_index=False)[num_feats].sum()\n",
    "    for c in num_feats:\n",
    "        hourly[c] = np.log1p(hourly[c].clip(lower=0))\n",
    "    return hourly.set_index('hour'), num_feats\n",
    "\n",
    "def make_sequences(X, win=32, horizon=0):\n",
    "    seqs = []\n",
    "    for i in range(len(X) - win - horizon + 1):\n",
    "        seqs.append(X[i:i+win])\n",
    "    return np.array(seqs, dtype=np.float32)\n",
    "\n",
    "def build_lstm_autoencoder(timesteps, n_feats, bottleneck=32):\n",
    "    inputs = layers.Input(shape=(timesteps, n_feats))\n",
    "    x = layers.LSTM(64, return_sequences=True)(inputs)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "    z = layers.LSTM(bottleneck, return_sequences=False)(x)\n",
    "    x = layers.RepeatVector(timesteps)(z)\n",
    "    x = layers.LSTM(64, return_sequences=True)(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "    outputs = layers.TimeDistributed(layers.Dense(n_feats))(x)\n",
    "    model = models.Model(inputs, outputs)\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    return model\n",
    "\n",
    "def run_anomaly_lstm(df, q=0.995, epochs=20, batch=128, *,\n",
    "                     freq='H', window=None, window_duration='1H'):\n",
    "    \"\"\"\n",
    "    freq: 리샘플 간격 ('H', '5min', '1min' 등)\n",
    "    window_duration: 총 윈도 길이 (기본 1시간, '1H')\n",
    "    window: 스텝 수를 직접 주고 싶으면 지정(우선순위 높음)\n",
    "    \"\"\"\n",
    "    # 1) 시간 집계 준비(우선 1시간 집계로 만든 뒤, freq로 리샘플)\n",
    "    hourly, feats = prepare_hourly(df)\n",
    "    if hourly.empty:\n",
    "        raise ValueError(\"시간 집계 결과가 비어 있습니다. created_at/숫자 피처를 확인하세요.\")\n",
    "\n",
    "    # 2) 원하는 간격으로 리샘플\n",
    "    if freq != 'H':\n",
    "        hourly = hourly.resample(freq).sum().fillna(0)\n",
    "\n",
    "    feats = [c for c in feats if c in hourly.columns]\n",
    "    if not feats:\n",
    "        raise ValueError(\"사용 가능한 숫자 피처가 없습니다.\")\n",
    "\n",
    "    # 3) 윈도 스텝 자동 계산(총 길이 1시간)\n",
    "    if window is None:\n",
    "        steps = int(pd.to_timedelta(window_duration) / pd.to_timedelta(freq))\n",
    "        window = max(2, steps)  # 최소 2 스텝 보장\n",
    "    # 데이터 길이에 맞춰 안전 축소\n",
    "    T = len(hourly)\n",
    "    if T < 4:\n",
    "        raise ValueError(f\"시간 버킷이 너무 적습니다(T={T}). 더 긴 기간 사용 또는 freq를 더 촘촘히 지정.\")\n",
    "    if T <= window:\n",
    "        window = max(2, T - 1)\n",
    "\n",
    "    # 4) 스케일링 + 시퀀스화\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(hourly[feats].values)\n",
    "    Xseq = make_sequences(X, win=window)\n",
    "    N = len(Xseq)\n",
    "    val_split = 0.1 if N >= 20 else 0.0\n",
    "    batch = max(1, min(batch, N))\n",
    "\n",
    "    # 5) 모델 학습\n",
    "    model = build_lstm_autoencoder(window, len(feats), bottleneck=32)\n",
    "    es = callbacks.EarlyStopping(monitor='val_loss' if val_split>0 else 'loss',\n",
    "                                 patience=3, restore_best_weights=True)\n",
    "    hist = model.fit(\n",
    "        Xseq, Xseq,\n",
    "        validation_split=val_split,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch,\n",
    "        callbacks=[es],\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # 6) 이상도 산출\n",
    "    Xhat = model.predict(Xseq, verbose=0)\n",
    "    recon_err = ((Xseq - Xhat)**2).mean(axis=(1,2))\n",
    "    thr = np.quantile(recon_err, q if N > 10 else min(q, 0.99))\n",
    "    y_pred = (recon_err >= thr).astype(int)\n",
    "\n",
    "    # 7) 타임스탬프 매핑\n",
    "    idx = hourly.index.values\n",
    "    t_end = idx[window-1 : len(idx)]\n",
    "    out = pd.DataFrame({\n",
    "        'ts_end': t_end[:len(recon_err)],\n",
    "        'recon_err': recon_err,\n",
    "        'is_anomaly': y_pred\n",
    "    }).set_index('ts_end')\n",
    "\n",
    "    return out, hist, thr, feats, scaler, model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "7488531d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\342806638.py:22: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  d['hour'] = d[TIME_COL].dt.floor('H')\n",
      "C:\\Users\\EL044\\AppData\\Local\\Temp\\ipykernel_30436\\342806638.py:69: FutureWarning: 'H' is deprecated and will be removed in a future version. Please use 'h' instead of 'H'.\n",
      "  steps = int(pd.to_timedelta(window_duration) / pd.to_timedelta(freq))\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "시간 버킷이 너무 적습니다(T=1). 더 긴 기간 사용 또는 freq를 더 촘촘히 지정.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[92]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      7\u001b[39m mask = (df_1h[\u001b[33m'\u001b[39m\u001b[33mcreated_at\u001b[39m\u001b[33m'\u001b[39m] >= \u001b[33m'\u001b[39m\u001b[33m2024-01-01 00:00:00+00:00\u001b[39m\u001b[33m'\u001b[39m) & (df_1h[\u001b[33m'\u001b[39m\u001b[33mcreated_at\u001b[39m\u001b[33m'\u001b[39m] < \u001b[33m'\u001b[39m\u001b[33m2024-01-02 00:00:00+00:00\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      9\u001b[39m df_1h = df_1h[mask]\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m results_1h, hist_1h, thr_1h, feats_1h, scaler_1h, model_1h = \u001b[43mrun_anomaly_lstm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdf_1h\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfreq\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m1min\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwindow\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwindow_duration\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m1H\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m12\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mq\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.995\u001b[39;49m\n\u001b[32m     13\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[88]\u001b[39m\u001b[32m, line 74\u001b[39m, in \u001b[36mrun_anomaly_lstm\u001b[39m\u001b[34m(df, q, epochs, batch, freq, window, window_duration)\u001b[39m\n\u001b[32m     72\u001b[39m T = \u001b[38;5;28mlen\u001b[39m(hourly)\n\u001b[32m     73\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m T < \u001b[32m4\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m74\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m시간 버킷이 너무 적습니다(T=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mT\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m). 더 긴 기간 사용 또는 freq를 더 촘촘히 지정.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     75\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m T <= window:\n\u001b[32m     76\u001b[39m     window = \u001b[38;5;28mmax\u001b[39m(\u001b[32m2\u001b[39m, T - \u001b[32m1\u001b[39m)\n",
      "\u001b[31mValueError\u001b[39m: 시간 버킷이 너무 적습니다(T=1). 더 긴 기간 사용 또는 freq를 더 촘촘히 지정."
     ]
    }
   ],
   "source": [
    "df_1h = df.copy()\n",
    "\n",
    "# 기존 코드 (시간 범위가 너무 좁음)\n",
    "mask = (df_1h['created_at'] >= '2024-01-01 10:00:00+00:00') & (df_1h['created_at'] < '2024-01-01 11:00:00+00:00')\n",
    "\n",
    "# 수정된 코드 (시간 범위를 하루 전체로 확장)\n",
    "mask = (df_1h['created_at'] >= '2024-01-01 00:00:00+00:00') & (df_1h['created_at'] < '2024-01-02 00:00:00+00:00')\n",
    "\n",
    "df_1h = df_1h[mask]\n",
    "\n",
    "results_1h, hist_1h, thr_1h, feats_1h, scaler_1h, model_1h = run_anomaly_lstm(\n",
    "    df_1h, freq='1min', window=None, window_duration='1H', epochs=12, q=0.995\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d04f4f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e398ca02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd                         # 넘파이/판다스 기본\n",
    "from sklearn.preprocessing import StandardScaler         # 표준화 스케일러(평균0/분산1)\n",
    "from tensorflow.keras import layers, models, callbacks   # Keras 레이어/모델/콜백\n",
    "\n",
    "# 0) 입력: df (열은 스크린샷의 21개), created_at 포함\n",
    "# df = pd.read_csv(\"cleaned_data.csv.gz\")  # 예시 로딩 코드(사용 시 주석 해제)\n",
    "\n",
    "FEATS = ['payload.size','payload.distinct_size','payload.ref',  # 사용할 피처 이름(문자면 아래에서 자동 제외)\n",
    "         'f_commits_n','f_commits_n_distinct','f_commits_avg_msg_len','f_commits_max_msg_len',\n",
    "         'f_issue_labels_n','f_pr_labels_n','f_payload.issue.assignees_n',\n",
    "         'f_payload.pull_request.assignees_n','f_payload.pull_request.requested_reviewers_n',\n",
    "         'f_payload.pull_request.head.repo.topics_n','f_payload.pull_request.base.repo.topics_n',\n",
    "         'f_release_assets_n','f_release_assets_total_size','f_pages_n',\n",
    "         'f_release_mentions_n','f_app_events_n']                # 카운트/사이즈/길이 위주 피처\n",
    "TIME_COL = 'created_at'                                         # 시간 컬럼 이름\n",
    "\n",
    "# 1) 시간 정렬 + 숫자만 사용 (payload.ref가 문자열이면 제거)\n",
    "def prepare_hourly(df):                                         # 시간당 집계용 전처리 함수 정의\n",
    "    d = df.copy()                                               # 원본 보호를 위한 복사\n",
    "    d[TIME_COL] = pd.to_datetime(d[TIME_COL], utc=True, errors='coerce')  # created_at을 UTC 타임스탬프로 변환\n",
    "    d = d.dropna(subset=[TIME_COL]).sort_values(TIME_COL)       # 시간 결측 제거 후 시간 기준 정렬\n",
    "\n",
    "    # 숫자형만 취사선택\n",
    "    num_feats = [c for c in FEATS if c in d.columns and pd.api.types.is_numeric_dtype(d[c])]  # 숫자형 피처만 추림\n",
    "    d = d[[TIME_COL] + num_feats].copy()                        # 시간 + 숫자 피처만 남김\n",
    "\n",
    "    # 시간당(sum) 집계\n",
    "    d['hour'] = d[TIME_COL].dt.floor('H')                       # 시간을 시간단위로 내림(버킷팅)\n",
    "    hourly = d.groupby('hour', as_index=False)[num_feats].sum() # 같은 시각 버킷끼리 합산\n",
    "\n",
    "    # log1p 안정화\n",
    "    for c in num_feats:                                         # 각 피처에 대해\n",
    "        hourly[c] = np.log1p(hourly[c].clip(lower=0))           # 음수 방지 후 log1p로 스케일 안정화\n",
    "\n",
    "    return hourly.set_index('hour'), num_feats                  # 인덱스를 시간으로, 사용 피처 리스트 반환\n",
    "\n",
    "# 2) 시퀀스 생성 (슬라이딩 윈도우)\n",
    "def make_sequences(X, win=32, horizon=0):                       # 슬라이딩 윈도우로 3D 시퀀스 생성\n",
    "    # horizon=0이면 입력=출력(오토인코더용)\n",
    "    seqs = []                                                   # 누적 리스트\n",
    "    for i in range(len(X) - win - horizon + 1):                 # 시작 인덱스 범위\n",
    "        seqs.append(X[i:i+win])                                 # 길이 win 만큼 잘라 시퀀스 추가\n",
    "    return np.array(seqs, dtype=np.float32)                     # (N, T, F) 텐서 반환\n",
    "\n",
    "# 3) LSTM 오토인코더 구성\n",
    "def build_lstm_autoencoder(timesteps, n_feats, bottleneck=32):  # LSTM AE 모델 생성 함수\n",
    "    inputs = layers.Input(shape=(timesteps, n_feats))           # 입력: (시간길이, 피처수)\n",
    "    x = layers.LSTM(64, return_sequences=True)(inputs)          # 인코더 LSTM(은닉 64, 시퀀스 반환)\n",
    "    x = layers.Dropout(0.2)(x)                                  # 드롭아웃으로 과적합 방지\n",
    "    z = layers.LSTM(bottleneck, return_sequences=False)(x)      # 병목층(bottleneck) LSTM(시퀀스 미반환)\n",
    "    x = layers.RepeatVector(timesteps)(z)                       # 디코더를 위해 시간차원으로 반복\n",
    "    x = layers.LSTM(64, return_sequences=True)(x)               # 디코더 LSTM\n",
    "    x = layers.Dropout(0.2)(x)                                  # 드롭아웃\n",
    "    outputs = layers.TimeDistributed(layers.Dense(n_feats))(x)  # 매 시점마다 피처 수만큼 복원\n",
    "    model = models.Model(inputs, outputs)                       # 모델 구성\n",
    "    model.compile(optimizer='adam', loss='mse')                 # 최적화/손실: Adam + MSE(재구성 오차)\n",
    "    return model                                                # 완성 모델 반환\n",
    "\n",
    "# ===== MAIN =====\n",
    "def run_anomaly_lstm(df, window=32, q=0.995, epochs=20, batch=128):  # 메인 파이프라인 함수\n",
    "    hourly, feats = prepare_hourly(df)                           # 시간당 집계 + 유효 피처 목록 획득\n",
    "    scaler = StandardScaler()                                    # 표준화 스케일러 생성\n",
    "    X = scaler.fit_transform(hourly[feats].values)               # 피처 표준화(학습 데이터로 적합/변환)\n",
    "    Xseq = make_sequences(X, win=window)                         # (N, T, F) 시퀀스로 변환\n",
    "\n",
    "    model = build_lstm_autoencoder(window, len(feats), bottleneck=32)  # LSTM AE 모델 생성\n",
    "    es = callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)  # 조기종료 콜백\n",
    "    hist = model.fit(                                            # 모델 학습 시작\n",
    "        Xseq, Xseq,                                              # 오토인코더: 입력=정답\n",
    "        validation_split=0.1,                                    # 10% 검증 분할\n",
    "        epochs=epochs,                                           # 에폭 수\n",
    "        batch_size=batch,                                        # 배치 크기\n",
    "        callbacks=[es],                                          # 콜백 등록(조기종료)\n",
    "        verbose=1                                                # 로그 출력\n",
    "    )\n",
    "\n",
    "    # 복원오차(시퀀스별) → 마지막 타임스텝에 매핑\n",
    "    Xhat = model.predict(Xseq, verbose=0)                        # 시퀀스 복원값 예측\n",
    "    recon_err = ((Xseq - Xhat)**2).mean(axis=(1,2))              # 시퀀스별 MSE(시간/피처 평균)\n",
    "\n",
    "    # 임계값: 상위 q-quantile\n",
    "    thr = np.quantile(recon_err, q)                              # 상위 q 분위수를 임계값으로 설정\n",
    "    y_pred = (recon_err >= thr).astype(int)                      # 임계 이상이면 1(이상치), 아니면 0\n",
    "\n",
    "    # 타임스탬프 매핑 (각 시퀀스의 마지막 시간)\n",
    "    idx = hourly.index.values                                    # 시간 인덱스 배열\n",
    "    t_end = idx[window-1 : len(idx)]                             # 각 시퀀스의 끝 시각(길이 N)\n",
    "    out = pd.DataFrame({                                         # 결과 데이터프레임 생성\n",
    "        'ts_end': t_end[:len(recon_err)],                        # 시퀀스 종료 시각\n",
    "        'recon_err': recon_err,                                  # 재구성 오차\n",
    "        'is_anomaly': y_pred                                     # 이상 여부(0/1)\n",
    "    }).set_index('ts_end')                                       # 시각을 인덱스로 설정\n",
    "\n",
    "    return out, hist, thr, feats, scaler, model                  # 결과/학습기록/임계/피처/스케일러/모델 반환\n",
    "def run_anomaly_lstm(df, window=32, q=0.995, epochs=20, batch=128, freq='H'):\n",
    "    \"\"\"\n",
    "    freq: 시간 집계 단위 ('H'=1시간, '30min', '15min' 등으로 늘리면 샘플↑)\n",
    "    \"\"\"\n",
    "    hourly, feats = prepare_hourly(df)        # (T, F) - 기존 함수 그대로 사용\n",
    "    if hourly.empty:\n",
    "        raise ValueError(\"시간 집계 결과가 비어 있습니다. created_at 또는 숫자 피처를 확인하세요.\")\n",
    "\n",
    "    # 필요 시 집계 재샘플링(더 촘촘한 버킷으로)\n",
    "    if freq != 'H':\n",
    "        # prepare_hourly가 hour 인덱스로 반환하므로, 원하는 freq로 리샘플 후 0 채움\n",
    "        hourly = hourly.resample(freq).sum().fillna(0)\n",
    "\n",
    "    # 숫자 피처 검증\n",
    "    feats = [c for c in feats if c in hourly.columns]\n",
    "    if len(feats) == 0:\n",
    "        raise ValueError(\"사용 가능한 숫자 피처가 없습니다. FEATS와 실제 컬럼을 확인하세요.\")\n",
    "\n",
    "    # 표준화\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(hourly[feats].values)   # (T, F)\n",
    "\n",
    "    # 윈도우 자동 조정: 시퀀스 개수 N = T - window + 1\n",
    "    T = len(hourly)\n",
    "    if T < 4:\n",
    "        raise ValueError(f\"시간 버킷이 너무 적습니다(T={T}). 더 긴 기간을 사용하거나 freq를 줄이세요.\")\n",
    "    if T <= window:\n",
    "        window = max(4, min(16, T - 1))  # 최소 4, 최대 16 사이에서 안전 축소\n",
    "        # 그래도 T - window + 1 < 1이면 한 번 더 축소\n",
    "        if T - window + 1 < 1:\n",
    "            window = max(2, T - 1)\n",
    "\n",
    "    # 시퀀스 생성\n",
    "    Xseq = make_sequences(X, win=window)            # (N, T', F)\n",
    "    N = len(Xseq)\n",
    "    if N < 2:\n",
    "        # 검증 분할 없이 단일 학습만 수행\n",
    "        val_split = 0.0\n",
    "    else:\n",
    "        val_split = 0.1 if N >= 20 else 0.0        # 샘플 적으면 검증 생략\n",
    "\n",
    "    # 모델 구성\n",
    "    model = build_lstm_autoencoder(window, len(feats), bottleneck=32)\n",
    "    es = callbacks.EarlyStopping(monitor='val_loss' if val_split>0 else 'loss',\n",
    "                                 patience=3, restore_best_weights=True)\n",
    "\n",
    "    # 배치 크기 안전화\n",
    "    batch = max(1, min(batch, N))\n",
    "\n",
    "    # 학습\n",
    "    hist = model.fit(\n",
    "        Xseq, Xseq,\n",
    "        validation_split=val_split,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch,\n",
    "        callbacks=[es],\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # 예측/오차\n",
    "    Xhat = model.predict(Xseq, verbose=0)\n",
    "    recon_err = ((Xseq - Xhat)**2).mean(axis=(1,2))\n",
    "\n",
    "    # 임계값\n",
    "    thr = np.quantile(recon_err, q if N > 10 else min(q, 0.99))  # 샘플 적을 때 과도한 상위 분위수 방지\n",
    "    y_pred = (recon_err >= thr).astype(int)                      # 임계 이상이면 1(이상치), 아니면 0\n",
    "\n",
    "    # 타임스탬프 매핑 (각 시퀀스의 마지막 시간)\n",
    "    idx = hourly.index.values                                    # 시간 인덱스 배열\n",
    "    t_end = idx[window-1 : len(idx)]                             # 각 시퀀스의 끝 시각(길이 N)\n",
    "    out = pd.DataFrame({                                         # 결과 데이터프레임 생성\n",
    "        'ts_end': t_end[:len(recon_err)],                        # 시퀀스 종료 시각\n",
    "        'recon_err': recon_err,                                  # 재구성 오차\n",
    "        'is_anomaly': y_pred                                     # 이상 여부(0/1)\n",
    "    }).set_index('ts_end')                                       # 시각을 인덱스로 설정\n",
    "\n",
    "# 사용 예시\n",
    "# results, hist, thr, feats, scaler, model = run_anomaly_lstm(df, window=32, q=0.995, epochs=20)\n",
    "# print(\"임계값:\", thr)\n",
    "# results.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "5d93278a",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "run_anomaly_lstm() got an unexpected keyword argument 'freq'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[87]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# ② LSTM 오토인코더 학습/탐지 (5분 집계 + 작은 윈도)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m results_1h, hist_1h, thr_1h, feats_1h, scaler_1h, model_1h = \u001b[43mrun_anomaly_lstm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mwindow\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m         \u001b[49m\u001b[38;5;66;43;03m# 포인트가 적으니 짧게\u001b[39;49;00m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mq\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.995\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m          \u001b[49m\u001b[38;5;66;43;03m# 복원오차 상위 0.5%를 이상치로\u001b[39;49;00m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m15\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m64\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfreq\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m5min\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m       \u001b[49m\u001b[38;5;66;43;03m# 5분 버킷으로 포인트 수 확보\u001b[39;49;00m\n\u001b[32m      9\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m임계값(1h):\u001b[39m\u001b[33m\"\u001b[39m, thr_1h)\n\u001b[32m     12\u001b[39m display(results_1h.head())       \u001b[38;5;66;03m# ts_end, recon_err, is_anomaly(0/1)\u001b[39;00m\n",
      "\u001b[31mTypeError\u001b[39m: run_anomaly_lstm() got an unexpected keyword argument 'freq'"
     ]
    }
   ],
   "source": [
    "\n",
    "# ② LSTM 오토인코더 학습/탐지 (5분 집계 + 작은 윈도)\n",
    "results_1h, hist_1h, thr_1h, feats_1h, scaler_1h, model_1h = run_anomaly_lstm(\n",
    "    df,\n",
    "    window=8,         # 포인트가 적으니 짧게\n",
    "    q=0.995,          # 복원오차 상위 0.5%를 이상치로\n",
    "    epochs=15,\n",
    "    batch=64,\n",
    "    freq='5min'       # 5분 버킷으로 포인트 수 확보\n",
    ")\n",
    "\n",
    "print(\"임계값(1h):\", thr_1h)\n",
    "display(results_1h.head())       # ts_end, recon_err, is_anomaly(0/1)\n",
    "print(\"사용 피처:\", feats_1h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c674419",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

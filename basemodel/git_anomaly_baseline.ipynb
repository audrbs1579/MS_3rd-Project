{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40b8cae6",
   "metadata": {},
   "source": [
    "\n",
    "# Git Anomaly Baseline (Week-by-Week, with Checkpoints)\n",
    "\n",
    "- **Scope**: Git-only features (no developer-behavior baselines).\n",
    "- **Loop**: Download 1 week → Extract features → Normalize → Weak label → Train → Metrics → Clean raw → Next week.\n",
    "- **Checkpoints**: Raw → Silver (features) → Gold (normalized + labels) → Model → Metrics.\n",
    "- **Progress**: `tqdm` bars with `ncols=30`.\n",
    "- **Outputs**: Precision, Recall, ROC-AUC, PR-AUC per week.\n",
    "- **Note**: Replace the download function and `DATA_SOURCE_CONFIG` with your paths/logic.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed33cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === 0. Imports & Config ===\n",
    "import os, sys, json, shutil, glob, math, gc\n",
    "from datetime import datetime, timedelta\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import IsolationForest, RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    precision_score, recall_score, roc_auc_score, average_precision_score,\n",
    "    precision_recall_curve, roc_curve, auc\n",
    ")\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "import joblib\n",
    "\n",
    "# Display options\n",
    "pd.set_option('display.max_columns', 100)\n",
    "\n",
    "# === Configuration (edit as needed) ===\n",
    "BASE_DIR = Path('./git_anomaly_runs').resolve()\n",
    "BASE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Where to pull git logs from (YOU will fill this in)\n",
    "DATA_SOURCE_CONFIG = {\n",
    "    \"type\": \"local_git_archives\",  # e.g., 'gh_archive', 'git_logs'\n",
    "    \"source_path\": \"/replace/with/your/path\",  # TODO: set after you share paths\n",
    "    # Additional credentials/params as needed\n",
    "}\n",
    "\n",
    "START_DATE = datetime(2024, 1, 1)   # inclusive\n",
    "NUM_WEEKS = 2                       # change this as needed\n",
    "WEEK_SPAN_DAYS = 7                  # 1-week slices\n",
    "\n",
    "CHECKPOINT_KEEP = {\n",
    "    \"raw\": False,        # False: delete raw after processing\n",
    "    \"silver\": True,      # Keep engineered features\n",
    "    \"gold\": True,        # Keep normalized + labels\n",
    "    \"models\": True,      # Keep trained models\n",
    "    \"metrics\": True      # Keep metrics JSON/CSV\n",
    "}\n",
    "\n",
    "# Weak labeling thresholds on normalized (0~1) features\n",
    "LOW_Q = 0.1\n",
    "HIGH_Q = 0.9\n",
    "LABEL_ANY = True   # True: label=1 if any feature is <=LOW_Q or >=HIGH_Q\n",
    "LABEL_K = 2        # if LABEL_ANY is False, require at least K features out-of-band\n",
    "\n",
    "# Features to compute from Git-only signals (commit-level)\n",
    "# NOTE: This pipeline expects a commit-level table; adjust parsing if needed.\n",
    "GIT_FEATURE_COLUMNS = [\n",
    "    \"lines_added\", \"lines_deleted\", \"files_changed\",\n",
    "    \"churn\", \"is_binary_commit\", \"avg_line_len\", \"ext_entropy\"\n",
    "]\n",
    "\n",
    "# Model choices (baseline)\n",
    "USE_ISOFOREST = False      # Optional unsupervised baseline\n",
    "USE_LOGISTIC = True        # Weak-label supervised baseline (probabilistic output)\n",
    "USE_RF = False             # Alternative baseline\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "TEST_SIZE = 0.3\n",
    "\n",
    "# tqdm width\n",
    "TQDM_NCOLS = 30\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b852c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === 1. Helpers ===\n",
    "\n",
    "def week_ranges(start_date: datetime, num_weeks: int, span_days: int = 7):\n",
    "    cur = start_date\n",
    "    for _ in range(num_weeks):\n",
    "        end = cur + timedelta(days=span_days)\n",
    "        yield cur, end\n",
    "        cur = end\n",
    "\n",
    "def ensure_dirs(base: Path, week_id: str):\n",
    "    d = {\n",
    "        \"root\": base / week_id,\n",
    "        \"raw\": base / week_id / \"raw\",\n",
    "        \"silver\": base / week_id / \"silver\",\n",
    "        \"gold\": base / week_id / \"gold\",\n",
    "        \"models\": base / week_id / \"models\",\n",
    "        \"metrics\": base / week_id / \"metrics\",\n",
    "        \"state\": base / week_id / \"state\"\n",
    "    }\n",
    "    for v in d.values():\n",
    "        v.mkdir(parents=True, exist_ok=True)\n",
    "    return d\n",
    "\n",
    "def save_json(path: Path, data: dict):\n",
    "    path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with open(path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "def load_json(path: Path):\n",
    "    if not path.exists():\n",
    "        return None\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def cleanup_folder(path: Path):\n",
    "    if path.exists():\n",
    "        shutil.rmtree(path, ignore_errors=True)\n",
    "\n",
    "def memory_cleanup():\n",
    "    gc.collect()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9090e520",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === 2. Data Acquisition ===\n",
    "# You should replace `download_week_data` with your actual downloader/reader.\n",
    "# As a fallback, this function will generate synthetic commit-level data if no data is found.\n",
    "\n",
    "def download_week_data(start_dt: datetime, end_dt: datetime, raw_dir: Path, cfg: dict, tqdm_ncols: int = 30):\n",
    "    # TODO: Replace this with real download / parse of git logs into a CSV/Parquet\n",
    "    # Expected output file: raw_dir / 'commits.parquet'\n",
    "    raw_dir.mkdir(parents=True, exist_ok=True)\n",
    "    out_fp = raw_dir / 'commits.parquet'\n",
    "    \n",
    "    # Example: detect if a pre-existing file is present\n",
    "    existing = sorted(raw_dir.glob('*.parquet'))\n",
    "    if existing:\n",
    "        return existing[0]\n",
    "    \n",
    "    # Synthetic fallback for demo\n",
    "    rng = np.random.RandomState(123)\n",
    "    n = 1200  # approx one week of commits across repos (tune later)\n",
    "    # Git-only commit features (no identity/behavior baselines)\n",
    "    df = pd.DataFrame({\n",
    "        \"commit_id\": [f\"c{i:06d}\" for i in range(n)],\n",
    "        \"ts\": pd.date_range(start_dt, periods=n, freq=\"H\").astype(str),\n",
    "        \"lines_added\": rng.lognormal(mean=3.0, sigma=0.8, size=n).astype(int),\n",
    "        \"lines_deleted\": rng.lognormal(mean=2.5, sigma=0.9, size=n).astype(int),\n",
    "        \"files_changed\": rng.randint(1, 20, size=n),\n",
    "        \"binary_files_changed\": rng.binomial(1, 0.07, size=n),\n",
    "        \"avg_line_len\": rng.normal(loc=45, scale=12, size=n).clip(5, 120),\n",
    "        \"ext_entropy\": rng.beta(a=2.0, b=5.0, size=n) * 4.0  # 0~4\n",
    "    })\n",
    "    # churn\n",
    "    df[\"churn\"] = df[\"lines_added\"] + df[\"lines_deleted\"]\n",
    "    # binary commit if >=1 binary file\n",
    "    df[\"is_binary_commit\"] = (df[\"binary_files_changed\"] > 0).astype(int)\n",
    "\n",
    "    df.to_parquet(out_fp, index=False)\n",
    "    return out_fp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b849f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === 3. Feature Engineering (Git-only) ===\n",
    "\n",
    "def make_git_features(raw_fp: Path, silver_dir: Path, tqdm_ncols: int = 30):\n",
    "    df = pd.read_parquet(raw_fp)\n",
    "    # Ensure required columns\n",
    "    base_cols = [\n",
    "        \"lines_added\", \"lines_deleted\", \"files_changed\",\n",
    "        \"churn\", \"is_binary_commit\", \"avg_line_len\", \"ext_entropy\"\n",
    "    ]\n",
    "    for c in base_cols:\n",
    "        if c not in df.columns:\n",
    "            raise ValueError(f\"Missing required column: {c}\")\n",
    "    feats = df[base_cols].copy()\n",
    "    # Add any simple derived features if needed later\n",
    "    silver_fp = silver_dir / \"features.parquet\"\n",
    "    feats.to_parquet(silver_fp, index=False)\n",
    "    return silver_fp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e44e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === 4. Normalization & Weak Labeling ===\n",
    "\n",
    "def normalize_and_label(silver_fp: Path, gold_dir: Path, low_q=0.1, high_q=0.9,\n",
    "                        label_any=True, k=2, scaler_type=\"minmax\", tqdm_ncols: int = 30):\n",
    "    X = pd.read_parquet(silver_fp)\n",
    "    cols = list(X.columns)\n",
    "    \n",
    "    if scaler_type == \"robust\":\n",
    "        scaler = RobustScaler()\n",
    "    else:\n",
    "        scaler = MinMaxScaler()\n",
    "    X_scaled = pd.DataFrame(scaler.fit_transform(X), columns=cols)\n",
    "    \n",
    "    # Weak labeling\n",
    "    low_mask = (X_scaled <= low_q)\n",
    "    high_mask = (X_scaled >= high_q)\n",
    "    out_of_band = (low_mask | high_mask).astype(int)\n",
    "    oob_count = out_of_band.sum(axis=1)\n",
    "    if label_any:\n",
    "        y = (oob_count >= 1).astype(int)\n",
    "    else:\n",
    "        y = (oob_count >= k).astype(int)\n",
    "    \n",
    "    gold_fp = gold_dir / \"gold.parquet\"\n",
    "    X_scaled.assign(label=y.values).to_parquet(gold_fp, index=False)\n",
    "    \n",
    "    # Save scaler\n",
    "    joblib.dump(scaler, gold_dir / \"scaler.joblib\")\n",
    "    return gold_fp, cols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16cf0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === 5. Modeling & Metrics ===\n",
    "\n",
    "def train_and_evaluate(gold_fp: Path, models_dir: Path, metrics_dir: Path,\n",
    "                       use_isoforest=False, use_logistic=True, use_rf=False,\n",
    "                       random_state=42, test_size=0.3, tqdm_ncols: int = 30):\n",
    "    df = pd.read_parquet(gold_fp)\n",
    "    X = df.drop(columns=[\"label\"]).values\n",
    "    y = df[\"label\"].values.astype(int)\n",
    "    \n",
    "    # Train/test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=random_state, stratify=y\n",
    "    )\n",
    "    \n",
    "    metrics = {}\n",
    "    \n",
    "    if use_isoforest:\n",
    "        iso = IsolationForest(\n",
    "            n_estimators=200, max_samples=\"auto\", contamination=0.1, random_state=random_state\n",
    "        )\n",
    "        iso.fit(X_train)\n",
    "        # decision_function: higher -> more normal; we'll invert to anomaly score\n",
    "        iso_scores = -iso.decision_function(X_test)\n",
    "        # To compute classification metrics, choose a threshold at top 10% anomalies\n",
    "        thresh = np.quantile(iso_scores, 0.9)\n",
    "        y_pred_iso = (iso_scores >= thresh).astype(int)\n",
    "        metrics[\"isoforest\"] = {\n",
    "            \"precision\": float(precision_score(y_test, y_pred_iso, zero_division=0)),\n",
    "            \"recall\": float(recall_score(y_test, y_pred_iso, zero_division=0)),\n",
    "            \"roc_auc\": float(roc_auc_score(y_test, iso_scores)),\n",
    "            \"pr_auc\": float(auc(*precision_recall_curve(y_test, iso_scores)[1::-1]))\n",
    "        }\n",
    "        joblib.dump(iso, models_dir / \"isoforest.joblib\")\n",
    "    \n",
    "    if use_logistic:\n",
    "        # Handle class imbalance with class weights\n",
    "        classes = np.unique(y_train)\n",
    "        cw = compute_class_weight(class_weight=\"balanced\", classes=classes, y=y_train)\n",
    "        class_weight = {int(c): float(w) for c, w in zip(classes, cw)}\n",
    "        \n",
    "        logreg = LogisticRegression(\n",
    "            max_iter=200, n_jobs=None, class_weight=class_weight, random_state=random_state\n",
    "        )\n",
    "        logreg.fit(X_train, y_train)\n",
    "        prob = logreg.predict_proba(X_test)[:, 1]\n",
    "        y_pred = (prob >= 0.5).astype(int)\n",
    "        \n",
    "        metrics[\"logistic_regression\"] = {\n",
    "            \"precision\": float(precision_score(y_test, y_pred, zero_division=0)),\n",
    "            \"recall\": float(recall_score(y_test, y_pred, zero_division=0)),\n",
    "            \"roc_auc\": float(roc_auc_score(y_test, prob)),\n",
    "            \"pr_auc\": float(average_precision_score(y_test, prob))\n",
    "        }\n",
    "        joblib.dump(logreg, models_dir / \"logreg.joblib\")\n",
    "    \n",
    "    if use_rf:\n",
    "        rf = RandomForestClassifier(\n",
    "            n_estimators=300, max_depth=None, n_jobs=-1, random_state=random_state, class_weight=\"balanced_subsample\"\n",
    "        )\n",
    "        rf.fit(X_train, y_train)\n",
    "        prob = rf.predict_proba(X_test)[:, 1]\n",
    "        y_pred = (prob >= 0.5).astype(int)\n",
    "        metrics[\"random_forest\"] = {\n",
    "            \"precision\": float(precision_score(y_test, y_pred, zero_division=0)),\n",
    "            \"recall\": float(recall_score(y_test, y_pred, zero_division=0)),\n",
    "            \"roc_auc\": float(roc_auc_score(y_test, prob)),\n",
    "            \"pr_auc\": float(average_precision_score(y_test, prob))\n",
    "        }\n",
    "        joblib.dump(rf, models_dir / \"random_forest.joblib\")\n",
    "    \n",
    "    # Save metrics\n",
    "    save_json(metrics_dir / \"metrics.json\", metrics)\n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cfff98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === 6. Orchestration: Weekly loop with checkpoints & cleanup ===\n",
    "\n",
    "all_weeks_metrics = []\n",
    "\n",
    "for i, (ws, we) in enumerate(tqdm(week_ranges(START_DATE, NUM_WEEKS, WEEK_SPAN_DAYS), total=NUM_WEEKS, ncols=TQDM_NCOLS, desc=\"Weeks\")):\n",
    "    week_id = f\"week_{ws.strftime('%Y%m%d')}_{we.strftime('%Y%m%d')}\"\n",
    "    dirs = ensure_dirs(BASE_DIR, week_id)\n",
    "    \n",
    "    # State file to allow resuming\n",
    "    state_fp = dirs[\"state\"] / \"state.json\"\n",
    "    state = load_json(state_fp) or {\"stage\": \"init\", \"week_id\": week_id, \"ws\": ws.isoformat(), \"we\": we.isoformat()}\n",
    "    \n",
    "    try:\n",
    "        # 1) Download\n",
    "        if state[\"stage\"] == \"init\":\n",
    "            tqdm.write(f\"[{week_id}] Downloading raw data...\")\n",
    "            raw_fp = download_week_data(ws, we, dirs[\"raw\"], DATA_SOURCE_CONFIG, tqdm_ncols=TQDM_NCOLS)\n",
    "            state[\"stage\"] = \"downloaded\"\n",
    "            state[\"raw_fp\"] = str(raw_fp)\n",
    "            save_json(state_fp, state)\n",
    "        \n",
    "        # 2) Feature engineering (git-only)\n",
    "        if state[\"stage\"] == \"downloaded\":\n",
    "            tqdm.write(f\"[{week_id}] Feature engineering...\")\n",
    "            silver_fp = make_git_features(Path(state[\"raw_fp\"]), dirs[\"silver\"], tqdm_ncols=TQDM_NCOLS)\n",
    "            state[\"stage\"] = \"silver_done\"\n",
    "            state[\"silver_fp\"] = str(silver_fp)\n",
    "            save_json(state_fp, state)\n",
    "        \n",
    "        # 3) Normalize & weak label\n",
    "        if state[\"stage\"] == \"silver_done\":\n",
    "            tqdm.write(f\"[{week_id}] Normalize & weak label...\")\n",
    "            gold_fp, cols = normalize_and_label(\n",
    "                Path(state[\"silver_fp\"]), dirs[\"gold\"],\n",
    "                low_q=LOW_Q, high_q=HIGH_Q,\n",
    "                label_any=LABEL_ANY, k=LABEL_K,\n",
    "                scaler_type=\"minmax\", tqdm_ncols=TQDM_NCOLS\n",
    "            )\n",
    "            state[\"stage\"] = \"gold_done\"\n",
    "            state[\"gold_fp\"] = str(gold_fp)\n",
    "            state[\"feature_cols\"] = cols\n",
    "            save_json(state_fp, state)\n",
    "        \n",
    "        # 4) Train & evaluate\n",
    "        if state[\"stage\"] == \"gold_done\":\n",
    "            tqdm.write(f\"[{week_id}] Train & evaluate...\")\n",
    "            metrics = train_and_evaluate(\n",
    "                Path(state[\"gold_fp\"]), dirs[\"models\"], dirs[\"metrics\"],\n",
    "                use_isoforest=USE_ISOFOREST, use_logistic=USE_LOGISTIC, use_rf=USE_RF,\n",
    "                random_state=RANDOM_STATE, test_size=TEST_SIZE, tqdm_ncols=TQDM_NCOLS\n",
    "            )\n",
    "            state[\"stage\"] = \"trained\"\n",
    "            state[\"metrics\"] = metrics\n",
    "            save_json(state_fp, state)\n",
    "            all_weeks_metrics.append({\"week_id\": week_id, **{(k+'_'+m): v for k, vals in metrics.items() for m, v in vals.items()}})\n",
    "        \n",
    "        # 5) Cleanup raw (optional)\n",
    "        if state[\"stage\"] == \"trained\":\n",
    "            if not CHECKPOINT_KEEP.get(\"raw\", False):\n",
    "                tqdm.write(f\"[{week_id}] Cleanup raw dir...\")\n",
    "                cleanup_folder(dirs[\"raw\"])\n",
    "            state[\"stage\"] = \"done\"\n",
    "            save_json(state_fp, state)\n",
    "            tqdm.write(f\"[{week_id}] Done.\")\n",
    "        \n",
    "        memory_cleanup()\n",
    "    \n",
    "    except Exception as e:\n",
    "        tqdm.write(f\"[{week_id}] ERROR: {e}\")\n",
    "        raise\n",
    "\n",
    "# Summary table for all weeks\n",
    "summary_df = pd.DataFrame(all_weeks_metrics)\n",
    "display(summary_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9204301a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === 7. Print last-week metrics (Precision, Recall, ROC-AUC, PR-AUC) ===\n",
    "\n",
    "def flatten_metrics(metrics_dict):\n",
    "    rows = []\n",
    "    for model_name, vals in metrics_dict.items():\n",
    "        row = {\"model\": model_name}\n",
    "        row.update(vals)\n",
    "        rows.append(row)\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "if 'state' in locals() and state.get(\"metrics\"):\n",
    "    dfm = flatten_metrics(state[\"metrics\"])\n",
    "    print(\"Last processed week metrics:\")\n",
    "    display(dfm)\n",
    "else:\n",
    "    print(\"No metrics found yet.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f2bd02",
   "metadata": {},
   "source": [
    "\n",
    "## 🔧 What you should edit\n",
    "- `DATA_SOURCE_CONFIG[\"source_path\"]` to your Git archive or log root.\n",
    "- Implement your own `download_week_data()` to actually read/parse weekly data into **`raw/commits.parquet`**.\n",
    "- Adjust `NUM_WEEKS`, `CHECKPOINT_KEEP`, and model flags (`USE_LOGISTIC`, `USE_ISOFOREST`, `USE_RF`) as needed.\n",
    "- The weak labeling thresholds are controlled by `LOW_Q` / `HIGH_Q` and `LABEL_ANY` / `LABEL_K`.\n",
    "\n",
    "## ✅ Expected file structure per week\n",
    "```\n",
    "git_anomaly_runs/\n",
    "  week_YYYYMMDD_YYYYMMDD/\n",
    "    raw/        # (deleted if CHECKPOINT_KEEP['raw']=False)\n",
    "    silver/     # features.parquet\n",
    "    gold/       # gold.parquet + scaler.joblib\n",
    "    models/     # model files\n",
    "    metrics/    # metrics.json\n",
    "    state/      # state.json\n",
    "```\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38f5145a",
   "metadata": {},
   "source": [
    "# 03) 모델 학습(체크포인트) & 저장 / 재사용 추론\n",
    "- AutoEncoder(MSE 재구성 오차) 기반 비지도 학습.\n",
    "- 학습 중 매 에폭 체크포인트 저장, 최저 val-loss 기준 best 모델 저장.\n",
    "- 같은 모델을 재사용해 다른 주차 데이터에 대해 추론(스코어 산출) 가능."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0f7638",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "BASE_DIR = r\"C:\\Users\\EL040\\Desktop\\MS_3rd-Project\\basemodel\"\n",
    "TRAIN_SPLIT = \"train\"   # 학습에 쓸 split\n",
    "TEST_SPLIT  = \"test\"    # 추론(평가)에 쓸 split (동일 주차 반복 시 바꾸면 됨)\n",
    "EPOCHS = 20\n",
    "BATCH = 1024\n",
    "LR = 1e-3\n",
    "VAL_RATIO = 0.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9846aed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from common import get_paths, train_autoencoder, score_anomaly, load_scalers\n",
    "\n",
    "paths = get_paths(BASE_DIR)\n",
    "model_dir = paths[\"model_dir\"]\n",
    "ckpt_dir = paths[\"ckpt_dir\"]\n",
    "\n",
    "# Load TRAIN features\n",
    "train_feat_path = os.path.join(paths[\"data_train_feat\"], \"features.parquet\")\n",
    "train_df = pd.read_parquet(train_feat_path)\n",
    "X_train = train_df.values.astype(\"float32\")\n",
    "print(\"Train features:\", X_train.shape)\n",
    "\n",
    "# Train model with checkpoints\n",
    "best_model_path, last_ckpt_path = train_autoencoder(\n",
    "    X=X_train,\n",
    "    model_dir=model_dir,\n",
    "    ckpt_dir=ckpt_dir,\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH,\n",
    "    lr=LR,\n",
    "    val_ratio=VAL_RATIO,\n",
    "    tqdm_ncols=30,\n",
    ")\n",
    "print(\"Best model saved at:\", best_model_path)\n",
    "print(\"Last checkpoint:\", last_ckpt_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f405ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ----- 재사용: 다른 데이터셋(예: TEST_SPLIT)의 스코어 산출 -----\n",
    "test_feat_dir = paths[\"data_test_feat\"]\n",
    "test_feat_path = os.path.join(test_feat_dir, \"features.parquet\")\n",
    "if os.path.exists(test_feat_path):\n",
    "    test_df = pd.read_parquet(test_feat_path)\n",
    "    X_test = test_df.values.astype(\"float32\")\n",
    "    print(\"Test features:\", X_test.shape)\n",
    "\n",
    "    scores = score_anomaly(best_model_path, X_test, tqdm_ncols=30)\n",
    "    out_csv = os.path.join(test_feat_dir, \"anomaly_scores.csv\")\n",
    "    pd.DataFrame({\"anomaly_score\": scores}).to_csv(out_csv, index=False)\n",
    "    print(\"Saved test anomaly scores to:\", out_csv)\n",
    "else:\n",
    "    print(\"No test features found. You can generate them with notebook 02 for TEST split.\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
